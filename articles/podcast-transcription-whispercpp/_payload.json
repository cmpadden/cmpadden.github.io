[{"data":1,"prerenderedAt":471},["ShallowReactive",2],{"/articles/podcast-transcription-whispercpp":3},{"id":4,"title":5,"body":6,"categories":444,"date":446,"description":447,"extension":448,"img":449,"meta":450,"navigation":159,"path":465,"seo":466,"stem":467,"tags":468,"__hash__":470},"content/articles/podcast-transcription-whispercpp.md","Easily Transcribe Podcasts with Whisper.cpp",{"type":7,"value":8,"toc":439},"minimal",[9,33,38,60,122,128,230,237,243,319,322,424,427,435],[10,11,12,13,20,21,26,27,32],"p",{},"If you've ever had the need to transcribe a podcast, lecture, or some other audio recording, it turns out it's surprisingly easy with the extremely impressive ",[14,15,19],"a",{"href":16,"rel":17},"https://github.com/ggerganov/whisper.cpp",[18],"nofollow","whisper.cpp"," project. This high-performance fork of ",[14,22,25],{"href":23,"rel":24},"https://github.com/openai/whisper",[18],"OpenAI's Whisper"," can run on all sorts of hardware -- including my M1 Mac Mini. Let's walk through an example from start-to-finish of transcribing an episode of the ",[14,28,31],{"href":29,"rel":30},"https://podcasts.apple.com/us/podcast/alter-everything/id1356137854",[18],"Alter Everything"," podcast.",[34,35,37],"h2",{"id":36},"obtain-audio-files","Obtain Audio File(s)",[10,39,40,41,45,46,49,50,52,53,55,56,59],{},"First, let's get the ",[42,43,44],"code",{},"wav"," file from YouTube using the ",[42,47,48],{},"youtube-dl"," utility. It should be noted that ",[42,51,19],{}," expects ",[42,54,44],{}," filetypes, and this utility defaults to ",[42,57,58],{},"mp3",".",[61,62,67],"pre",{"className":63,"code":64,"language":65,"meta":66,"style":66},"language-sh shiki shiki-themes github-dark"," $ youtube-dl \\\n    --extract-audio \\\n    --audio-format wav \\\n    --output podcast.wav \\\n    \"https://www.youtube.com/watch?v=CoUN690wSYQ\"\n","sh","",[42,68,69,86,94,105,116],{"__ignoreMap":66},[70,71,74,78,82],"span",{"class":72,"line":73},"line",1,[70,75,77],{"class":76},"svObZ"," $",[70,79,81],{"class":80},"sU2Wk"," youtube-dl",[70,83,85],{"class":84},"sDLfK"," \\\n",[70,87,89,92],{"class":72,"line":88},2,[70,90,91],{"class":84},"    --extract-audio",[70,93,85],{"class":84},[70,95,97,100,103],{"class":72,"line":96},3,[70,98,99],{"class":84},"    --audio-format",[70,101,102],{"class":80}," wav",[70,104,85],{"class":84},[70,106,108,111,114],{"class":72,"line":107},4,[70,109,110],{"class":84},"    --output",[70,112,113],{"class":80}," podcast.wav",[70,115,85],{"class":84},[70,117,119],{"class":72,"line":118},5,[70,120,121],{"class":80},"    \"https://www.youtube.com/watch?v=CoUN690wSYQ\"\n",[10,123,124,125,127],{},"This file has a 44.1 kHz sample rate, and ",[42,126,19],{}," expects 16 kHz, so let's go ahead and convert that.",[61,129,131],{"className":63,"code":130,"language":65,"meta":66,"style":66}," $ file podcast.wav\npodcast.wav: RIFF (little-endian) data, WAVE audio, Microsoft PCM, 16 bit, stereo 44100 Hz\n\n $ ffmpeg -i podcast.wav -ar 16000 podcast-16khz.wav\n\n $ file podcast-16khz.wav\npodcast-16khz.wav: RIFF (little-endian) data, WAVE audio, Microsoft PCM, 16 bit, stereo 16000 Hz\n\n# NOTE: it looks like it's possible to specify this conversion as a post-process as a\n# flag to the `youtube-dl` command -- I will explore this further next time...\n# youtube-dl --extract-audio --audio-quality 0 --audio-format mp3 --postprocessor-args \"-ar 44100\" %dl%\n",[42,132,133,143,155,161,182,186,195,206,211,218,224],{"__ignoreMap":66},[70,134,135,137,140],{"class":72,"line":73},[70,136,77],{"class":76},[70,138,139],{"class":80}," file",[70,141,142],{"class":80}," podcast.wav\n",[70,144,145,148,151],{"class":72,"line":88},[70,146,147],{"class":76},"podcast.wav:",[70,149,150],{"class":80}," RIFF",[70,152,154],{"class":153},"s95oV"," (little-endian) data, WAVE audio, Microsoft PCM, 16 bit, stereo 44100 Hz\n",[70,156,157],{"class":72,"line":96},[70,158,160],{"emptyLinePlaceholder":159},true,"\n",[70,162,163,165,168,171,173,176,179],{"class":72,"line":107},[70,164,77],{"class":76},[70,166,167],{"class":80}," ffmpeg",[70,169,170],{"class":84}," -i",[70,172,113],{"class":80},[70,174,175],{"class":84}," -ar",[70,177,178],{"class":84}," 16000",[70,180,181],{"class":80}," podcast-16khz.wav\n",[70,183,184],{"class":72,"line":118},[70,185,160],{"emptyLinePlaceholder":159},[70,187,189,191,193],{"class":72,"line":188},6,[70,190,77],{"class":76},[70,192,139],{"class":80},[70,194,181],{"class":80},[70,196,198,201,203],{"class":72,"line":197},7,[70,199,200],{"class":76},"podcast-16khz.wav:",[70,202,150],{"class":80},[70,204,205],{"class":153}," (little-endian) data, WAVE audio, Microsoft PCM, 16 bit, stereo 16000 Hz\n",[70,207,209],{"class":72,"line":208},8,[70,210,160],{"emptyLinePlaceholder":159},[70,212,214],{"class":72,"line":213},9,[70,215,217],{"class":216},"sAwPA","# NOTE: it looks like it's possible to specify this conversion as a post-process as a\n",[70,219,221],{"class":72,"line":220},10,[70,222,223],{"class":216},"# flag to the `youtube-dl` command -- I will explore this further next time...\n",[70,225,227],{"class":72,"line":226},11,[70,228,229],{"class":216},"# youtube-dl --extract-audio --audio-quality 0 --audio-format mp3 --postprocessor-args \"-ar 44100\" %dl%\n",[34,231,233,234,236],{"id":232},"build-whispercpp-transcribe-audio","Build ",[42,235,19],{}," & Transcribe Audio",[10,238,239,240,242],{},"Then, let's get the latest version of ",[42,241,19],{},", download the English Whisper model, and build the example.",[61,244,246],{"className":63,"code":245,"language":65,"meta":66,"style":66},"# Clone the `whisper.cpp` repository\n $ git clone --depth 1 git@github.com:ggerganov/whisper.cpp && cd whisper.cpp\n\n# Download the English Whisper model in `ggml` format\n $ bash ./models/download-ggml-model.sh base.en\n\n# Build the main example\n $ make\n",[42,247,248,253,281,285,290,303,307,312],{"__ignoreMap":66},[70,249,250],{"class":72,"line":73},[70,251,252],{"class":216},"# Clone the `whisper.cpp` repository\n",[70,254,255,257,260,263,266,269,272,275,278],{"class":72,"line":88},[70,256,77],{"class":76},[70,258,259],{"class":80}," git",[70,261,262],{"class":80}," clone",[70,264,265],{"class":84}," --depth",[70,267,268],{"class":84}," 1",[70,270,271],{"class":80}," git@github.com:ggerganov/whisper.cpp",[70,273,274],{"class":153}," && ",[70,276,277],{"class":84},"cd",[70,279,280],{"class":80}," whisper.cpp\n",[70,282,283],{"class":72,"line":96},[70,284,160],{"emptyLinePlaceholder":159},[70,286,287],{"class":72,"line":107},[70,288,289],{"class":216},"# Download the English Whisper model in `ggml` format\n",[70,291,292,294,297,300],{"class":72,"line":118},[70,293,77],{"class":76},[70,295,296],{"class":80}," bash",[70,298,299],{"class":80}," ./models/download-ggml-model.sh",[70,301,302],{"class":80}," base.en\n",[70,304,305],{"class":72,"line":188},[70,306,160],{"emptyLinePlaceholder":159},[70,308,309],{"class":72,"line":197},[70,310,311],{"class":216},"# Build the main example\n",[70,313,314,316],{"class":72,"line":208},[70,315,77],{"class":76},[70,317,318],{"class":80}," make\n",[10,320,321],{},"And finally, let's transcribe that podcast!",[61,323,325],{"className":63,"code":324,"language":65,"meta":66,"style":66}," $ ./main \\\n    -m ~/workspace/whisper.cpp/models/ggml-base.en.bin \\\n    -f ~/Downloads/podcast-16khz.wav \\\n    --output-vtt \\\n    --output-file out\n\n# whisper_print_timings:     load time =   114.71 ms\n# whisper_print_timings:     fallbacks =   0 p /   0 h\n# whisper_print_timings:      mel time =   692.20 ms\n# whisper_print_timings:   sample time = 22278.10 ms / 27893 runs (    0.80 ms per run)\n# whisper_print_timings:   encode time = 10000.75 ms /    55 runs (  181.83 ms per run)\n# whisper_print_timings:   decode time =   331.77 ms /    54 runs (    6.14 ms per run)\n# whisper_print_timings:   batchd time = 45236.73 ms / 27566 runs (    1.64 ms per run)\n# whisper_print_timings:   prompt time =  1921.90 ms / 11832 runs (    0.16 ms per run)\n# whisper_print_timings:    total time = 80709.54 ms\n",[42,326,327,336,346,356,363,371,375,380,385,390,395,400,406,412,418],{"__ignoreMap":66},[70,328,329,331,334],{"class":72,"line":73},[70,330,77],{"class":76},[70,332,333],{"class":80}," ./main",[70,335,85],{"class":84},[70,337,338,341,344],{"class":72,"line":88},[70,339,340],{"class":84},"    -m",[70,342,343],{"class":80}," ~/workspace/whisper.cpp/models/ggml-base.en.bin",[70,345,85],{"class":84},[70,347,348,351,354],{"class":72,"line":96},[70,349,350],{"class":84},"    -f",[70,352,353],{"class":80}," ~/Downloads/podcast-16khz.wav",[70,355,85],{"class":84},[70,357,358,361],{"class":72,"line":107},[70,359,360],{"class":84},"    --output-vtt",[70,362,85],{"class":84},[70,364,365,368],{"class":72,"line":118},[70,366,367],{"class":84},"    --output-file",[70,369,370],{"class":80}," out\n",[70,372,373],{"class":72,"line":188},[70,374,160],{"emptyLinePlaceholder":159},[70,376,377],{"class":72,"line":197},[70,378,379],{"class":216},"# whisper_print_timings:     load time =   114.71 ms\n",[70,381,382],{"class":72,"line":208},[70,383,384],{"class":216},"# whisper_print_timings:     fallbacks =   0 p /   0 h\n",[70,386,387],{"class":72,"line":213},[70,388,389],{"class":216},"# whisper_print_timings:      mel time =   692.20 ms\n",[70,391,392],{"class":72,"line":220},[70,393,394],{"class":216},"# whisper_print_timings:   sample time = 22278.10 ms / 27893 runs (    0.80 ms per run)\n",[70,396,397],{"class":72,"line":226},[70,398,399],{"class":216},"# whisper_print_timings:   encode time = 10000.75 ms /    55 runs (  181.83 ms per run)\n",[70,401,403],{"class":72,"line":402},12,[70,404,405],{"class":216},"# whisper_print_timings:   decode time =   331.77 ms /    54 runs (    6.14 ms per run)\n",[70,407,409],{"class":72,"line":408},13,[70,410,411],{"class":216},"# whisper_print_timings:   batchd time = 45236.73 ms / 27566 runs (    1.64 ms per run)\n",[70,413,415],{"class":72,"line":414},14,[70,416,417],{"class":216},"# whisper_print_timings:   prompt time =  1921.90 ms / 11832 runs (    0.16 ms per run)\n",[70,419,421],{"class":72,"line":420},15,[70,422,423],{"class":216},"# whisper_print_timings:    total time = 80709.54 ms\n",[10,425,426],{},"A full podcast transcribed in ~80 seconds on an M1 Mac Mini -- not too bad!",[61,428,433],{"className":429,"code":431,"language":432},[430],"language-text","# out.vtt\n\n00:00:00.000 --> 00:00:06.480\n >> Hi everyone. We recently launched a short engagement feedback survey for the Alter Everything\n\n00:00:06.480 --> 00:00:11.360\n podcast. Click the link in the episode description wherever you're listening to let us know what\n\n00:00:11.360 --> 00:00:16.320\n you think and help us improve our show.\n\n00:00:16.320 --> 00:00:21.200\n Welcome to Alter Everything, a podcast about data science and analytics culture. I'm Megan\n\n00:00:21.200 --> 00:00:26.440\n Dibble and today I'm talking with Nick Schrock, CTO and founder of Dagster Labs. We discussed\n\n00:00:26.440 --> 00:00:31.560\n data engineering trends, challenges in the field, why he started his company, and what\n\n00:00:31.560 --> 00:00:38.960\n makes him excited about the future of data engineering. Let's get started.\n\n00:00:38.960 --> 00:00:42.720\n >> Hi, Nick. It's great to have you on our show today. Thanks for being here.\n\n00:00:42.720 --> 00:00:43.920\n >> Thanks for having me.\n\n00:00:43.920 --> 00:00:48.280\n >> Yeah. Could you start off by giving an introduction to yourself for our listeners?\n\n00:00:48.280 --> 00:00:52.920\n >> Sure. My name is Nick Schrock. I'm the CTO and founder of Dagster Labs. There's the\n\n00:00:52.920 --> 00:00:59.520\n company behind Dagster, which is a data orchestration framework. Prior to doing this, I was an engineer\n\n00:00:59.520 --> 00:01:05.960\n at Facebook from 2009, 2017. While I was there, I found a team called product infrastructure\n\n00:01:05.960 --> 00:01:09.800\n whose goal was to make our application developers more efficient and productive, and a bunch\n\n00:01:09.800 --> 00:01:13.840\n of open source work came out of that actually, one of which was React, which I had nothing\n\n00:01:13.840 --> 00:01:18.040\n to do with, but actually the CEO of Dagster Labs co-created and I personally co-created\n\n00:01:18.040 --> 00:01:22.640\n GraphQL. So as I like to say, Pete and I were present at the creation of the full hipster\n\n00:01:22.640 --> 00:01:28.680\n stack. I moved on to Facebook in 2017, figuring out what to do next, and this data engineering\n\n00:01:28.680 --> 00:01:32.960\n and data orchestration problem really got me hooked actually quite soon after I left,\n\n00:01:32.960 --> 00:01:36.280\n and the rest is history. I'm sure we'll get into that more.\n","text",[42,434,431],{"__ignoreMap":66},[436,437,438],"style",{},"html pre.shiki code .svObZ, html code.shiki .svObZ{--shiki-default:#B392F0}html pre.shiki code .sU2Wk, html code.shiki .sU2Wk{--shiki-default:#9ECBFF}html pre.shiki code .sDLfK, html code.shiki .sDLfK{--shiki-default:#79B8FF}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html pre.shiki code .s95oV, html code.shiki .s95oV{--shiki-default:#E1E4E8}html pre.shiki code .sAwPA, html code.shiki .sAwPA{--shiki-default:#6A737D}",{"title":66,"searchDepth":88,"depth":88,"links":440},[441,442],{"id":36,"depth":88,"text":37},{"id":232,"depth":88,"text":443},"Build whisper.cpp & Transcribe Audio",[445],"programming","2024-01-08T00:00:00.000Z","If you've ever had the need to transcribe a podcast, lecture, or some other audio recording, it turns out it's surprisingly easy with the extremely impressive whisper.cpp project. This high-performance fork of OpenAI's Whisper can run on all sorts of hardware -- including my M1 Mac Mini. Let's walk through an example from start-to-finish of transcribing an episode of the Alter Everything podcast.","md",null,{"draft":451,"excerpt":452},false,{"type":7,"value":453},[454],[10,455,12,456,20,459,26,462,32],{},[14,457,19],{"href":16,"rel":458},[18],[14,460,25],{"href":23,"rel":461},[18],[14,463,31],{"href":29,"rel":464},[18],"/articles/podcast-transcription-whispercpp",{"title":5,"description":447},"articles/podcast-transcription-whispercpp",[19,469],"ml","dpoewhF-VmtbgB6-bqensZsmSTOF_1e6euN8T-__Z1s",1760715690771]