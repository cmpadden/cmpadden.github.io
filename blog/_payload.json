[{"data":1,"prerenderedAt":6108},["ShallowReactive",2],{"articles":3},[4,168,245,1035,1339,1517,1943,2926,3557,3961,4040,4155,4270,4627,5009,5798,5929],{"id":5,"title":6,"body":7,"categories":151,"date":153,"description":13,"extension":154,"img":155,"meta":156,"navigation":161,"path":162,"seo":163,"stem":164,"tags":165,"__hash__":167},"content/blog/using-codex-for-education-at-dagster-labs.md","Using Codex for education at Dagster Labs",{"type":8,"value":9,"toc":143},"minimal",[10,14,22,27,36,39,48,59,62,66,69,72,75,78,81,87,95,99,102,105,111,120,124,127,130,133,137,140],[11,12,13],"p",{},"I recently had the opportunity to showcase how we use Codex for educational content at Dagster Labs which was featured on the OpenAI developer blog; you can find a full copy of that post below.",[11,15,16],{},[17,18,19],"a",{"href":19,"rel":20},"https://developers.openai.com/blog/codex-for-documentation-dagster",[21],"nofollow",[23,24,26],"h2",{"id":25},"overview","Overview",[11,28,29,30,35],{},"At ",[17,31,34],{"href":32,"rel":33},"https://dagster.io/",[21],"Dagster Labs",", we produce a lot of technical educational content for data engineers, machine learning engineers, and analysts to better understand how to use Dagster, an open source workflow orchestration framework. Because our users come from varied technical backgrounds, we’ve found it essential to meet each persona at the right technical depth.",[11,37,38],{},"In this post, I’ll share how we use OpenAI’s Codex to accelerate documentation, translate content across mediums, and even measure how complete our docs are.\nThe power of CONTRIBUTING.md files",[11,40,41,42,47],{},"To make it easier for our community members and internal engineers to contribute documentation, we overhauled our ",[17,43,46],{"href":44,"rel":45},"https://github.com/dagster-io/dagster/blob/3c2d36054f4014ca8316e533975a538d6eff62c4/docs/CONTRIBUTING.md",[21],"CONTRIBUTING.md"," file. To our surprise, we had inadvertently significantly improved the utility of Codex. It turns out there is serious value in clearly outlining the hierarchy, structure, and best practices for writing documentation in your code base. Both for humans and robots.",[49,50,55],"pre",{"className":51,"code":53,"language":54},[52],"language-text","# Contributing documentation\n\n## Content\n\n### Links\n\n#### Use full paths instead of relative links\n\nDocusaurus doesn't always render relative links correctly, which can result in users seeing intermittent 404s when accessing those links. Use full paths instead of relative links, like this:\n\n```\nFor more information, see \"[Defining assets](/guides/build/assets/defining-assets)\".\n```\n\ninstead of this:\n\n```\nFor more information, see \"[Defining assets](defining-assets)\".\n```\n\n#### Use non-trailing slash links to Dagster docs\n\ne.g. use `/guides/build/assets/defining-assets` instead of `/guides/build/assets/defining-assets/`.\n\n**Context:** Links to Dagster docs with trailing slashes automatically redirect to non-trailing slash links. While that's helpful for docs links we don't control, too many redirects on our own pages can confuse search engines and cause SEO issues.\n\n### API documentation\n\n...\n","text",[56,57,53],"code",{"__ignoreMap":58},"",[11,60,61],{},"Codex is only as good as the scaffolding you give it. A well-structured CONTRIBUTING.md becomes both documentation for humans and a map for AI.",[23,63,65],{"id":64},"codex-for-understanding","Codex for understanding",[11,67,68],{},"Beyond writing docs, Codex can act as an always-available code explainer. For developer advocates and technical writers, this has been invaluable. In open source projects, or projects with many engineers, it can often be difficult to stay up-to-date on all of the features being developed, and how they work. This is especially true for smaller teams of developer advocates and technical writers. We’ve found that some of the best assistance Codex provides is through explaining pull requests, or pointing it to a part of the codebase and asking for an explanation.",[11,70,71],{},"A tip we’ve found here is to leverage the gh command from within Codex to explain pull requests. Ask it to review the PR description and diff, summarize why the feature was implemented, and explain how it should be exposed to end users.\nThe power of the mono repo",[11,73,74],{},"This might be a controversial opinion, but I’m a big fan of mono repos. When context is key, having everything accessible in a single repository makes it so much easier to get access to what you need, and in the case of Codex, this means complete context: code, docs, and examples all in one place.",[11,76,77],{},"While some people have expressed concern about tools like Codex failing to scale with repositories, I’ve found this not to be the case. By making use of file references within Codex (@) you can give Codex the initial sub directory or file to start with before further exploration. And there are some serious benefits to having your framework code alongside your documentation in a single repository. This setup lets us prompt Codex to read framework code and draft initial documentation scaffolds that we can then refine.",[11,79,80],{},"Here’s an example where we prompted Codex to review an existing pull request, and add a section to the documentation on how exactly these environment variables are useful when configuring your deployment.",[49,82,85],{"className":83,"code":84,"language":54},[52],">_ You are using OpenAI Codex in ~/src/dagster\n\n To get started, describe a task or try one of these commands:\n\n /init - create an AGENTS.md file with instructions for Codex\n /status - show current session configuration and token usage\n /approvals - choose what Codex can do without approval\n /model - choose what model and reasoning effort to use\n\n▌ Review the changes made in pull request 32557 using `gh pr diff \u003Cnumber>`, review the environment\n▌ variables that were introduced and already exist for configuring the gRPC server, then update\n▌ docs/docs/deployment/oss/oss-instance-configuration.md  page to outline the configuration options.\n\n> I’ll fetch the diff for PR 32557 and scan for added/updated gRPC-related\n  environment variables, then cross-check with existing env var usage in the\n  repo.\n\n• Ran gh pr diff 32557 | sed -n '1,200p'\n\n• Ran gh pr diff 32557 | sed -n '200,400p'\n\n• Explored\n  └ Search DAGSTER_GRPC_[A-Z_]+ in dagster\n    Read api.py, code_server.py, oss-instance-configuration.md\n    Search DAGSTER_CODE_SERVER_[A-Z_]+\n    Read constants.py\n    Search DAGSTER_(REPOSITORY|SCHEDULE|SENSOR)_GRPC_TIMEOUT_SECONDS|\n           DAGSTER_GRPC_SHUTDOWN_GRACE_PERIOD in dagster\n    Read proxy_server_manager.py\n\n> Next, I’ll expand the gRPC servers section of the instance configuration docs\n  to include API gRPC server variables and communication timeouts/limits, keeping\n  style consisten\n\n  ...\n",[56,86,84],{"__ignoreMap":58},[11,88,89,90],{},"You can find the pull request that was produced by this session at ",[17,91,94],{"href":92,"rel":93},"https://github.com/dagster-io/dagster/pull/32558",[21],"dagster-io/dagster#32558",[23,96,98],{"id":97},"translating-between-content-mediums","Translating between content mediums",[11,100,101],{},"Different personas prefer different learning formats, but the underlying ideas are often the same. Because of that, we produce a variety of content mediums: blog posts, tutorials, online courses, YouTube videos, and more. The core content of these materials can often be the same, just presented differently depending on the target persona.",[11,103,104],{},"Codex works exceptionally well at translating between these mediums. For example, taking a tutorial and producing a transcript for a YouTube video. Or taking a low-level tutorial, and abstracting it slightly for a blog post. In the below screenshot you can find an example prompt used to take one of our example projects and produce a video transcript. This approach saves hours of rewriting while keeping our messaging consistent across channels.",[49,106,109],{"className":107,"code":108,"language":54},[52],">_ You are using OpenAI Codex in ~/src/dagster\n\n▌Review the example project: examples/docs_projects/project_dagster_modal_pipes\n▌and produce a video transcript to teach users the core Dagster and Modal concept\n▌covered. Break the transcript into sections, and include code snippets to be\n▌showcased in the video. The prose of the script should be fun but professional.\n▌Save this to MODAL_VIDEO_TRANSCRIPT.md.\n\n> I’m going to scan the example project to understand its structure and code\n  before drafting the video transcript.\n\n• Ran\n  └ bash -lc 'ls -la' bash -lc 'ls -la examples/docs_projects/\n        project_dagster_modal_pipes' bash -lc \"rg --files examples/docs_projects/\n        project_dagster_modal_pipes | sed -n '1,120p'\"\n\n• Explored\n  └ List project_dagster_modal_pipes\n    Search rg --files examples/docs_projects/project_dagster_modal_pipes\n    Read README.md, definitions.py, __init__.py, resources.py, constants.py,\n         feeds.py, pipeline_factory.py, summarize.py, config.py, transcribe.py,\n         hello_dagster.py, verify_cloud_mount.py\n\n• Added MODAL_VIDEO_TRANSCRIPT.md (+335 -0)\n",[56,110,108],{"__ignoreMap":58},[11,112,113,114,119],{},"See the full video transcript ",[17,115,118],{"href":116,"rel":117},"https://gist.github.com/cmpadden/a371c1300bdc42601a77b3eefb938483",[21],"here","!",[23,121,123],{"id":122},"evaluating-documentation-coverage","Evaluating documentation coverage",[11,125,126],{},"One of the more experimental ways we’re using Codex is as a proxy for human understanding.",[11,128,129],{},"By using documentation as the source-of-truth, and base context for Codex, we can have it generate code. For example, people often use Dagster for running and observing their dbt data models alongside other data processing code.",[11,131,132],{},"By prompting Codex to reference the documentation and produce the code for this project, we can then run a test suite on the resulting code to check that it operates as expected. If it works as expected we can assume that our documentation has adequate coverage of the required content. If Codex can generate working code purely from our documentation, it’s a strong signal that humans can as well which becomes an indirect measure of documentation completeness.",[23,134,136],{"id":135},"summary","Summary",[11,138,139],{},"All in all, the Dagster team has found Codex to be immensely helpful for creating, reviewing, and translating education content. It has enabled us to scale beyond our original capacity, helped us ensure that we have adequate documentation coverage as the framework evolves, and more importantly, it has made it so that we can more easily support our community.",[11,141,142],{},"Codex has underscored how important context and structure are. For us, that means refining our documentation architecture so both humans and AI can navigate it easily. This feedback loop, powered by AI, has improved both how we create content and how users generate framework code. As AI tools evolve, the line between documentation, code, and automation will blur. Teams that treat documentation as structured data will have a major advantage.",{"title":58,"searchDepth":144,"depth":144,"links":145},2,[146,147,148,149,150],{"id":25,"depth":144,"text":26},{"id":64,"depth":144,"text":65},{"id":97,"depth":144,"text":98},{"id":122,"depth":144,"text":123},{"id":135,"depth":144,"text":136},[152],"ai","2025-10-27T00:00:00.000Z","md",null,{"excerpt":157},{"type":8,"value":158},[159],[11,160,13],{},true,"/blog/using-codex-for-education-at-dagster-labs",{"title":6,"description":13},"blog/using-codex-for-education-at-dagster-labs",[152,166],"education","PVbFhQFbi6-6SdF_dUwjAfnQ5CS95NdClJqAN3KwFEE",{"id":169,"title":170,"body":171,"categories":231,"date":233,"description":175,"extension":154,"img":155,"meta":234,"navigation":161,"path":239,"seo":240,"stem":241,"tags":242,"__hash__":244},"content/blog/ai-the-context-engineer.md","An evolution of data engineering",{"type":8,"value":172,"toc":226},[173,176,180,183,186,190,193,206,209,213,220,223],[11,174,175],{},"With the advancements of LLM-based tooling, the responsibilities (and maybe even the title!) of data engineers are changing.",[23,177,179],{"id":178},"origin","Origin",[11,181,182],{},"Before we talk about the changes, let's reflect on the inception of data engineering.",[11,184,185],{},"The practice of data engineering, and the need for dedicated roles, was born out of complexity and the need for someone to manage it.\nWith an explosion in data volumes and an increase in tools to manage it, a domain-specific engineer was born with a specialized set of skills.\nSome of these engineers came from the world of database administration, others from software engineering, and some from analytics.\nAs the domain that they worked in evolved, so did their responsibilities and skill sets.",[23,187,189],{"id":188},"questions","Questions",[11,191,192],{},"While the tools and challenges that these engineers solved changed, the underlying need for their work remained the same: to support the answering of questions.",[194,195,196,200,203],"ul",{},[197,198,199],"li",{},"\"Why do I have no customers?\"",[197,201,202],{},"\"What is the significance of these protein structures?\"",[197,204,205],{},"\"What is the airspeed velocity of an unladen swallow?\"",[11,207,208],{},"The wrangling of data, storage, processing, and everything in between was done out of necessity so that you, or some stakeholder, could make sense of it.",[23,210,212],{"id":211},"context","Context",[11,214,215,216,219],{},"We're reaching another inflection point where the underlying tools are evolving.\nThis time, we're seeing an emergence of systems that can make sense of large volumes of data. However the new \"complexity\" is that these systems rely on carefully managed metadata, or ",[217,218,211],"em",{},".\nThis context can store how data is loaded, transformed, and queried.\nYou no longer have to write the tool-specific code to interface with various APIs, nor the queries to make sense of it.\nYou just have to ensure that the information is present and curated.",[11,221,222],{},"The new responsibility of this kind of engineer is to manage that context.",[11,224,225],{},"Some folks are speculating that we will see the rise of the \"context engineer\", but while it's uncertain what the title will be, it's clear that we are seeing a change in how data engineers operate, and an evolution in the responsibilities that they hold to support the answering of questions.",{"title":58,"searchDepth":144,"depth":144,"links":227},[228,229,230],{"id":178,"depth":144,"text":179},{"id":188,"depth":144,"text":189},{"id":211,"depth":144,"text":212},[232],"programming","2025-07-18T00:00:00.000Z",{"draft":161,"excerpt":235},{"type":8,"value":236},[237],[11,238,175],{},"/blog/ai-the-context-engineer",{"title":170,"description":175},"blog/ai-the-context-engineer",[152,243],"data","dEiPevv0DW622bbBYuDr0b2T9qWszLISwKrRf6yVxd8",{"id":246,"title":247,"body":248,"categories":1011,"date":1013,"description":1014,"extension":154,"img":155,"meta":1015,"navigation":161,"path":1027,"seo":1028,"stem":1029,"tags":1030,"__hash__":1034},"content/blog/nuxt-p5js-3d-models.md","Render three-dimensional models in NuxtContent with p5js",{"type":8,"value":249,"toc":1009},[250,267,280,379,386,391,402,408,425,431,1002,1005],[11,251,252,253,256,257,260,261,266],{},"Three-dimensional models, whether they be of the format ",[56,254,255],{},".obj"," or ",[56,258,259],{},".stl",", can be easily rendered in your Nuxt project by using the ",[17,262,265],{"href":263,"rel":264},"https://p5js.org/",[21],"p5js.org"," library.",[11,268,269,270,273,274,279],{},"I've been using p5 for a while now to tinker and explore generative art, some of which can be found in the ",[17,271,272],{"href":272},"/playground"," section of this website. To use it with Nuxt, a ",[17,275,278],{"href":276,"rel":277},"https://github.com/cmpadden/cmpadden.github.io/blob/70ba674acdbe80c4a41b510a9b54edcddb19f489/plugins/p5.client.js",[21],"client-side plugin"," was created like so:",[49,281,285],{"className":282,"code":283,"language":284,"meta":58,"style":58},"language-js shiki shiki-themes github-dark","// plugins/p5.client.js\nimport p5 from 'p5'\n\nexport default defineNuxtPlugin(() => {\n  return {\n    provide: {\n      p5, p5\n    }\n  }\n})\n","js",[56,286,287,296,313,319,341,349,355,361,367,373],{"__ignoreMap":58},[288,289,292],"span",{"class":290,"line":291},"line",1,[288,293,295],{"class":294},"sAwPA","// plugins/p5.client.js\n",[288,297,298,302,306,309],{"class":290,"line":144},[288,299,301],{"class":300},"snl16","import",[288,303,305],{"class":304},"s95oV"," p5 ",[288,307,308],{"class":300},"from",[288,310,312],{"class":311},"sU2Wk"," 'p5'\n",[288,314,316],{"class":290,"line":315},3,[288,317,318],{"emptyLinePlaceholder":161},"\n",[288,320,322,325,328,332,335,338],{"class":290,"line":321},4,[288,323,324],{"class":300},"export",[288,326,327],{"class":300}," default",[288,329,331],{"class":330},"svObZ"," defineNuxtPlugin",[288,333,334],{"class":304},"(() ",[288,336,337],{"class":300},"=>",[288,339,340],{"class":304}," {\n",[288,342,344,347],{"class":290,"line":343},5,[288,345,346],{"class":300},"  return",[288,348,340],{"class":304},[288,350,352],{"class":290,"line":351},6,[288,353,354],{"class":304},"    provide: {\n",[288,356,358],{"class":290,"line":357},7,[288,359,360],{"class":304},"      p5, p5\n",[288,362,364],{"class":290,"line":363},8,[288,365,366],{"class":304},"    }\n",[288,368,370],{"class":290,"line":369},9,[288,371,372],{"class":304},"  }\n",[288,374,376],{"class":290,"line":375},10,[288,377,378],{"class":304},"})\n",[11,380,381,382,385],{},"As I've been exploring 3d-printing lately, I wanted a way to showcase some of the models I've created directly on this website. So, the ",[56,383,384],{},"ModelPreview"," component was created, which you can see in use below.",[387,388],"model-preview",{":background-color":389,"path":390},"50","/models/eevee.stl",[11,392,393,394,397,398,401],{},"The Vue component was embedded in our markdown using the following syntax is used. The ",[56,395,396],{},"path"," prop with the location of the file we want to render; in this case, that file is served on the website as well in the ",[56,399,400],{},"public/models"," folder.",[49,403,406],{"className":404,"code":405,"language":54},[52],":ModelPreview{path=\"/models/eevee.stl\"}\n",[56,407,405],{"__ignoreMap":58},[11,409,410,411,414,415,418,419,424],{},"The component was registered globally by using the ",[56,412,413],{},"ModelPreview.global.vue"," filename so that it was accessible in our markdown. Alternatively, this could have been accomplished by placing the component in the ",[56,416,417],{},"components/content"," folder. However, I wanted to use this component in both markdown and Vue files. See the ",[17,420,423],{"href":421,"rel":422},"https://content.nuxt.com/usage/markdown#vue-components",[21],"NuxtContent"," documentation for more details.",[11,426,427,428,430],{},"The full source code for the ",[56,429,384],{}," component at the time of this writing can be found below. Not too bad!",[49,432,434],{"className":282,"code":433,"language":284,"meta":58,"style":58},"\u003Ctemplate>\n    \u003Cdiv id=\"canvas\" class=\"h-64\" />\n\u003C/template>\n\n\u003Cscript setup lang=\"ts\">\nconst { $p5 } = useNuxtApp();\n\nconst { path, backgroundColor = 100 } = defineProps \u003C { path: string, backgroundColor?: Number } > ()\n\nonMounted(() => {\nconsole.log(backgroundColor);\n    const sketch = (s) => {\n        const c = document.getElementById(\"canvas\");\n\n        const WIDTH = c.clientWidth;\n        const HEIGHT = c.clientHeight;\n\n        let model;\n        let angle;\n        let rotate = true;\n\n        s.preload = () => {\n            model = s.loadModel(path, true);\n        };\n\n        s.setup = () => {\n            s.createCanvas(WIDTH, HEIGHT, s.WEBGL);\n        };\n\n        s.mouseClicked = () => {\n            rotate = false; // disable object rotation on click\n        };\n\n        s.draw = () => {\n            s.background(backgroundColor);\n            s.lights();\n\n            if (rotate) {\n                angle = s.frameCount * 0.005;\n            }\n            s.rotateX(angle);\n            s.rotateY(angle);\n            s.orbitControl();\n\n            s.model(model);\n        };\n    };\n\n    new $p5(sketch, \"canvas\");\n});\n\u003C/script>\n",[56,435,436,448,476,485,489,509,514,518,538,542,547,559,585,610,615,628,641,646,655,663,679,684,702,724,730,735,751,779,784,789,805,822,827,832,848,858,869,874,883,902,908,919,929,939,944,955,960,966,971,987,993],{"__ignoreMap":58},[288,437,438,441,445],{"class":290,"line":291},[288,439,440],{"class":304},"\u003C",[288,442,444],{"class":443},"s4JwU","template",[288,446,447],{"class":304},">\n",[288,449,450,453,456,459,462,465,468,470,473],{"class":290,"line":144},[288,451,452],{"class":304},"    \u003C",[288,454,455],{"class":443},"div",[288,457,458],{"class":330}," id",[288,460,461],{"class":300},"=",[288,463,464],{"class":311},"\"canvas\"",[288,466,467],{"class":330}," class",[288,469,461],{"class":300},[288,471,472],{"class":311},"\"h-64\"",[288,474,475],{"class":304}," />\n",[288,477,478,481,483],{"class":290,"line":315},[288,479,480],{"class":304},"\u003C/",[288,482,444],{"class":443},[288,484,447],{"class":304},[288,486,487],{"class":290,"line":321},[288,488,318],{"emptyLinePlaceholder":161},[288,490,491,493,496,499,502,504,507],{"class":290,"line":343},[288,492,440],{"class":304},[288,494,495],{"class":443},"script",[288,497,498],{"class":330}," setup",[288,500,501],{"class":330}," lang",[288,503,461],{"class":300},[288,505,506],{"class":311},"\"ts\"",[288,508,447],{"class":304},[288,510,511],{"class":290,"line":351},[288,512,513],{"class":304},"const { $p5 } = useNuxtApp();\n",[288,515,516],{"class":290,"line":357},[288,517,318],{"emptyLinePlaceholder":161},[288,519,520,523,525,529,532,535],{"class":290,"line":363},[288,521,522],{"class":304},"const { path, backgroundColor ",[288,524,461],{"class":300},[288,526,528],{"class":527},"sDLfK"," 100",[288,530,531],{"class":304}," } = defineProps \u003C { path: string, backgroundColor",[288,533,534],{"class":300},"?:",[288,536,537],{"class":304}," Number } > ()\n",[288,539,540],{"class":290,"line":369},[288,541,318],{"emptyLinePlaceholder":161},[288,543,544],{"class":290,"line":375},[288,545,546],{"class":304},"onMounted(() => {\n",[288,548,550,553,556],{"class":290,"line":549},11,[288,551,552],{"class":304},"console.",[288,554,555],{"class":330},"log",[288,557,558],{"class":304},"(backgroundColor);\n",[288,560,562,565,568,571,574,578,581,583],{"class":290,"line":561},12,[288,563,564],{"class":304},"    const ",[288,566,567],{"class":330},"sketch",[288,569,570],{"class":300}," =",[288,572,573],{"class":304}," (",[288,575,577],{"class":576},"s9osk","s",[288,579,580],{"class":304},") ",[288,582,337],{"class":300},[288,584,340],{"class":304},[288,586,588,591,594,596,599,602,605,607],{"class":290,"line":587},13,[288,589,590],{"class":300},"        const",[288,592,593],{"class":527}," c",[288,595,570],{"class":300},[288,597,598],{"class":304}," document.",[288,600,601],{"class":330},"getElementById",[288,603,604],{"class":304},"(",[288,606,464],{"class":311},[288,608,609],{"class":304},");\n",[288,611,613],{"class":290,"line":612},14,[288,614,318],{"emptyLinePlaceholder":161},[288,616,618,620,623,625],{"class":290,"line":617},15,[288,619,590],{"class":300},[288,621,622],{"class":527}," WIDTH",[288,624,570],{"class":300},[288,626,627],{"class":304}," c.clientWidth;\n",[288,629,631,633,636,638],{"class":290,"line":630},16,[288,632,590],{"class":300},[288,634,635],{"class":527}," HEIGHT",[288,637,570],{"class":300},[288,639,640],{"class":304}," c.clientHeight;\n",[288,642,644],{"class":290,"line":643},17,[288,645,318],{"emptyLinePlaceholder":161},[288,647,649,652],{"class":290,"line":648},18,[288,650,651],{"class":300},"        let",[288,653,654],{"class":304}," model;\n",[288,656,658,660],{"class":290,"line":657},19,[288,659,651],{"class":300},[288,661,662],{"class":304}," angle;\n",[288,664,666,668,671,673,676],{"class":290,"line":665},20,[288,667,651],{"class":300},[288,669,670],{"class":304}," rotate ",[288,672,461],{"class":300},[288,674,675],{"class":527}," true",[288,677,678],{"class":304},";\n",[288,680,682],{"class":290,"line":681},21,[288,683,318],{"emptyLinePlaceholder":161},[288,685,687,690,693,695,698,700],{"class":290,"line":686},22,[288,688,689],{"class":304},"        s.",[288,691,692],{"class":330},"preload",[288,694,570],{"class":300},[288,696,697],{"class":304}," () ",[288,699,337],{"class":300},[288,701,340],{"class":304},[288,703,705,708,710,713,716,719,722],{"class":290,"line":704},23,[288,706,707],{"class":304},"            model ",[288,709,461],{"class":300},[288,711,712],{"class":304}," s.",[288,714,715],{"class":330},"loadModel",[288,717,718],{"class":304},"(path, ",[288,720,721],{"class":527},"true",[288,723,609],{"class":304},[288,725,727],{"class":290,"line":726},24,[288,728,729],{"class":304},"        };\n",[288,731,733],{"class":290,"line":732},25,[288,734,318],{"emptyLinePlaceholder":161},[288,736,738,740,743,745,747,749],{"class":290,"line":737},26,[288,739,689],{"class":304},[288,741,742],{"class":330},"setup",[288,744,570],{"class":300},[288,746,697],{"class":304},[288,748,337],{"class":300},[288,750,340],{"class":304},[288,752,754,757,760,762,765,768,771,774,777],{"class":290,"line":753},27,[288,755,756],{"class":304},"            s.",[288,758,759],{"class":330},"createCanvas",[288,761,604],{"class":304},[288,763,764],{"class":527},"WIDTH",[288,766,767],{"class":304},", ",[288,769,770],{"class":527},"HEIGHT",[288,772,773],{"class":304},", s.",[288,775,776],{"class":527},"WEBGL",[288,778,609],{"class":304},[288,780,782],{"class":290,"line":781},28,[288,783,729],{"class":304},[288,785,787],{"class":290,"line":786},29,[288,788,318],{"emptyLinePlaceholder":161},[288,790,792,794,797,799,801,803],{"class":290,"line":791},30,[288,793,689],{"class":304},[288,795,796],{"class":330},"mouseClicked",[288,798,570],{"class":300},[288,800,697],{"class":304},[288,802,337],{"class":300},[288,804,340],{"class":304},[288,806,808,811,813,816,819],{"class":290,"line":807},31,[288,809,810],{"class":304},"            rotate ",[288,812,461],{"class":300},[288,814,815],{"class":527}," false",[288,817,818],{"class":304},"; ",[288,820,821],{"class":294},"// disable object rotation on click\n",[288,823,825],{"class":290,"line":824},32,[288,826,729],{"class":304},[288,828,830],{"class":290,"line":829},33,[288,831,318],{"emptyLinePlaceholder":161},[288,833,835,837,840,842,844,846],{"class":290,"line":834},34,[288,836,689],{"class":304},[288,838,839],{"class":330},"draw",[288,841,570],{"class":300},[288,843,697],{"class":304},[288,845,337],{"class":300},[288,847,340],{"class":304},[288,849,851,853,856],{"class":290,"line":850},35,[288,852,756],{"class":304},[288,854,855],{"class":330},"background",[288,857,558],{"class":304},[288,859,861,863,866],{"class":290,"line":860},36,[288,862,756],{"class":304},[288,864,865],{"class":330},"lights",[288,867,868],{"class":304},"();\n",[288,870,872],{"class":290,"line":871},37,[288,873,318],{"emptyLinePlaceholder":161},[288,875,877,880],{"class":290,"line":876},38,[288,878,879],{"class":300},"            if",[288,881,882],{"class":304}," (rotate) {\n",[288,884,886,889,891,894,897,900],{"class":290,"line":885},39,[288,887,888],{"class":304},"                angle ",[288,890,461],{"class":300},[288,892,893],{"class":304}," s.frameCount ",[288,895,896],{"class":300},"*",[288,898,899],{"class":527}," 0.005",[288,901,678],{"class":304},[288,903,905],{"class":290,"line":904},40,[288,906,907],{"class":304},"            }\n",[288,909,911,913,916],{"class":290,"line":910},41,[288,912,756],{"class":304},[288,914,915],{"class":330},"rotateX",[288,917,918],{"class":304},"(angle);\n",[288,920,922,924,927],{"class":290,"line":921},42,[288,923,756],{"class":304},[288,925,926],{"class":330},"rotateY",[288,928,918],{"class":304},[288,930,932,934,937],{"class":290,"line":931},43,[288,933,756],{"class":304},[288,935,936],{"class":330},"orbitControl",[288,938,868],{"class":304},[288,940,942],{"class":290,"line":941},44,[288,943,318],{"emptyLinePlaceholder":161},[288,945,947,949,952],{"class":290,"line":946},45,[288,948,756],{"class":304},[288,950,951],{"class":330},"model",[288,953,954],{"class":304},"(model);\n",[288,956,958],{"class":290,"line":957},46,[288,959,729],{"class":304},[288,961,963],{"class":290,"line":962},47,[288,964,965],{"class":304},"    };\n",[288,967,969],{"class":290,"line":968},48,[288,970,318],{"emptyLinePlaceholder":161},[288,972,974,977,980,983,985],{"class":290,"line":973},49,[288,975,976],{"class":300},"    new",[288,978,979],{"class":330}," $p5",[288,981,982],{"class":304},"(sketch, ",[288,984,464],{"class":311},[288,986,609],{"class":304},[288,988,990],{"class":290,"line":989},50,[288,991,992],{"class":304},"});\n",[288,994,996,998,1000],{"class":290,"line":995},51,[288,997,480],{"class":304},[288,999,495],{"class":443},[288,1001,447],{"class":304},[11,1003,1004],{},"Looking forward to sharing more models soon!",[1006,1007,1008],"style",{},"html pre.shiki code .sAwPA, html code.shiki .sAwPA{--shiki-default:#6A737D}html pre.shiki code .snl16, html code.shiki .snl16{--shiki-default:#F97583}html pre.shiki code .s95oV, html code.shiki .s95oV{--shiki-default:#E1E4E8}html pre.shiki code .sU2Wk, html code.shiki .sU2Wk{--shiki-default:#9ECBFF}html pre.shiki code .svObZ, html code.shiki .svObZ{--shiki-default:#B392F0}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html pre.shiki code .s4JwU, html code.shiki .s4JwU{--shiki-default:#85E89D}html pre.shiki code .sDLfK, html code.shiki .sDLfK{--shiki-default:#79B8FF}html pre.shiki code .s9osk, html code.shiki .s9osk{--shiki-default:#FFAB70}",{"title":58,"searchDepth":144,"depth":144,"links":1010},[],[1012],"examples","2024-12-31T00:00:00.000Z","Three-dimensional models, whether they be of the format .obj or .stl, can be easily rendered in your Nuxt project by using the p5js.org library.",{"excerpt":1016},{"type":8,"value":1017},[1018],[11,1019,252,1020,256,1022,260,1024,266],{},[56,1021,255],{},[56,1023,259],{},[17,1025,265],{"href":263,"rel":1026},[21],"/blog/nuxt-p5js-3d-models",{"title":247,"description":1014},"blog/nuxt-p5js-3d-models",[1031,1032,1033],"nuxt","p5js","3d","nm72UN02fo4OUbSag8-ak2qKtNSaiVLPcfWORLpNWCE",{"id":1036,"title":1037,"body":1038,"categories":1316,"date":1319,"description":1320,"extension":154,"img":155,"meta":1321,"navigation":161,"path":1332,"seo":1333,"stem":1334,"tags":1335,"__hash__":1338},"content/blog/ssh-ed25519-sk-yubikey.md","Configuring a YubiKey for use with OpenSSH",{"type":8,"value":1039,"toc":1314},[1040,1052,1061,1067,1076,1100,1103,1129,1136,1156,1159,1237,1244,1301,1311],[11,1041,1042,1047,1048,1051],{},[17,1043,1046],{"href":1044,"rel":1045},"https://www.yubico.com/",[21],"YubiKey's"," are a convenient way to introduce a physical form of two factor authentication into ones workflow. They support a variety of protocols, but in this guide we will walk through how to configure a YubiKey for use with OpenSSH via the \"new\" ",[56,1049,1050],{},"ed25519-sk"," key type that supports FIDO compliant hardware keys.",[11,1053,1054,1055,1060],{},"In ",[17,1056,1059],{"href":1057,"rel":1058},"https://www.openssh.com/txt/release-8.2",[21],"release 8.2 of OpenSSH"," support for FIDO devices was added with public key types \"ecdsa-sk\" and \"ed25519-sk\" (-sk standing for \"security key\"). This key type is supported by YubiKey's with firmware version 5.2.3 or higher.",[1062,1063,1064],"blockquote",{},[11,1065,1066],{},"This release adds support for FIDO/U2F hardware authenticators to OpenSSH. U2F/FIDO are open standards for inexpensive two-factor authentication hardware that are widely used for website authentication.  In OpenSSH FIDO devices are supported by new public key types \"ecdsa-sk\" and \"ed25519-sk\", along with corresponding certificate types.",[11,1068,1069,1070,1075],{},"Let's get started by installing the latest version of OpenSSH via ",[17,1071,1074],{"href":1072,"rel":1073},"https://brew.sh/",[21],"Homebrew",", along with the YubiKey Manager (ykman) CLI. The version of OpenSSH included with macOS is not compatible.",[49,1077,1081],{"className":1078,"code":1079,"language":1080,"meta":58,"style":58},"language-sh shiki shiki-themes github-dark","$ brew install openssh ykman\n","sh",[56,1082,1083],{"__ignoreMap":58},[288,1084,1085,1088,1091,1094,1097],{"class":290,"line":291},[288,1086,1087],{"class":330},"$",[288,1089,1090],{"class":311}," brew",[288,1092,1093],{"class":311}," install",[288,1095,1096],{"class":311}," openssh",[288,1098,1099],{"class":311}," ykman\n",[11,1101,1102],{},"Then, let's confirm that our YubiKey has a firmware that is greater than 5.2.3:",[49,1104,1106],{"className":1078,"code":1105,"language":1080,"meta":58,"style":58},"$ ykman list\nYubiKey 5Ci (5.4.3) [OTP+FIDO+CCID]\n",[56,1107,1108,1118],{"__ignoreMap":58},[288,1109,1110,1112,1115],{"class":290,"line":291},[288,1111,1087],{"class":330},[288,1113,1114],{"class":311}," ykman",[288,1116,1117],{"class":311}," list\n",[288,1119,1120,1123,1126],{"class":290,"line":144},[288,1121,1122],{"class":330},"YubiKey",[288,1124,1125],{"class":311}," 5Ci",[288,1127,1128],{"class":304}," (5.4.3) [OTP+FIDO+CCID]\n",[11,1130,1131,1132,1135],{},"Next, we'll go ahead and enable a pin on our device via the ",[56,1133,1134],{},"change-pin"," command, as this a requirement for our use.",[49,1137,1139],{"className":1078,"code":1138,"language":1080,"meta":58,"style":58},"$ ykman fido access change-pin\n",[56,1140,1141],{"__ignoreMap":58},[288,1142,1143,1145,1147,1150,1153],{"class":290,"line":291},[288,1144,1087],{"class":330},[288,1146,1114],{"class":311},[288,1148,1149],{"class":311}," fido",[288,1151,1152],{"class":311}," access",[288,1154,1155],{"class":311}," change-pin\n",[11,1157,1158],{},"And last, we'll generate the key on our device!",[49,1160,1162],{"className":1078,"code":1161,"language":1080,"meta":58,"style":58},"$ ssh-keygen -t ed25519-sk -O resident\nGenerating public/private ed25519-sk key pair.\nYou may need to touch your authenticator to authorize key generation.\n...\n",[56,1163,1164,1183,1199,1232],{"__ignoreMap":58},[288,1165,1166,1168,1171,1174,1177,1180],{"class":290,"line":291},[288,1167,1087],{"class":330},[288,1169,1170],{"class":311}," ssh-keygen",[288,1172,1173],{"class":527}," -t",[288,1175,1176],{"class":311}," ed25519-sk",[288,1178,1179],{"class":527}," -O",[288,1181,1182],{"class":311}," resident\n",[288,1184,1185,1188,1191,1193,1196],{"class":290,"line":144},[288,1186,1187],{"class":330},"Generating",[288,1189,1190],{"class":311}," public/private",[288,1192,1176],{"class":311},[288,1194,1195],{"class":311}," key",[288,1197,1198],{"class":311}," pair.\n",[288,1200,1201,1204,1207,1210,1213,1216,1219,1222,1224,1227,1229],{"class":290,"line":315},[288,1202,1203],{"class":330},"You",[288,1205,1206],{"class":311}," may",[288,1208,1209],{"class":311}," need",[288,1211,1212],{"class":311}," to",[288,1214,1215],{"class":311}," touch",[288,1217,1218],{"class":311}," your",[288,1220,1221],{"class":311}," authenticator",[288,1223,1212],{"class":311},[288,1225,1226],{"class":311}," authorize",[288,1228,1195],{"class":311},[288,1230,1231],{"class":311}," generation.\n",[288,1233,1234],{"class":290,"line":321},[288,1235,1236],{"class":527},"...\n",[11,1238,1239,1240,1243],{},"We specify ",[217,1241,1242],{},"resident"," to indicate that the key handle is to be stored on the YubiKey itself, since we will be using this device with multiple computers.",[49,1245,1249],{"className":1246,"code":1247,"language":1248,"meta":58,"style":58},"language-txt shiki shiki-themes github-dark","resident\n        Indicate that the key handle should be stored on the FIDO\n        authenticator itself.  This makes it easier to use the\n        authenticator on multiple computers.  Resident keys may be\n        supported on FIDO2 authenticators and typically require that a PIN\n        be set on the authenticator prior to generation.  Resident keys\n        may be loaded off the authenticator using ssh-add(1).  Storing\n        both parts of a key on a FIDO authenticator increases the\n        likelihood of an attacker being able to use a stolen authenticator\n        device.\n","txt",[56,1250,1251,1256,1261,1266,1271,1276,1281,1286,1291,1296],{"__ignoreMap":58},[288,1252,1253],{"class":290,"line":291},[288,1254,1255],{},"resident\n",[288,1257,1258],{"class":290,"line":144},[288,1259,1260],{},"        Indicate that the key handle should be stored on the FIDO\n",[288,1262,1263],{"class":290,"line":315},[288,1264,1265],{},"        authenticator itself.  This makes it easier to use the\n",[288,1267,1268],{"class":290,"line":321},[288,1269,1270],{},"        authenticator on multiple computers.  Resident keys may be\n",[288,1272,1273],{"class":290,"line":343},[288,1274,1275],{},"        supported on FIDO2 authenticators and typically require that a PIN\n",[288,1277,1278],{"class":290,"line":351},[288,1279,1280],{},"        be set on the authenticator prior to generation.  Resident keys\n",[288,1282,1283],{"class":290,"line":357},[288,1284,1285],{},"        may be loaded off the authenticator using ssh-add(1).  Storing\n",[288,1287,1288],{"class":290,"line":363},[288,1289,1290],{},"        both parts of a key on a FIDO authenticator increases the\n",[288,1292,1293],{"class":290,"line":369},[288,1294,1295],{},"        likelihood of an attacker being able to use a stolen authenticator\n",[288,1297,1298],{"class":290,"line":375},[288,1299,1300],{},"        device.\n",[11,1302,1303,1304,256,1307,1310],{},"And that's all it takes -- simple enough. Now, when interacting with ",[217,1305,1306],{},"ssh",[217,1308,1309],{},"git"," you will be prompted to touch the YubiKey to bring that little bit of physical 2FA.",[1006,1312,1313],{},"html pre.shiki code .svObZ, html code.shiki .svObZ{--shiki-default:#B392F0}html pre.shiki code .sU2Wk, html code.shiki .sU2Wk{--shiki-default:#9ECBFF}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html pre.shiki code .s95oV, html code.shiki .s95oV{--shiki-default:#E1E4E8}html pre.shiki code .sDLfK, html code.shiki .sDLfK{--shiki-default:#79B8FF}",{"title":58,"searchDepth":144,"depth":144,"links":1315},[],[1317,1318],"tooling","tips","2024-06-09T00:00:00.000Z","YubiKey's are a convenient way to introduce a physical form of two factor authentication into ones workflow. They support a variety of protocols, but in this guide we will walk through how to configure a YubiKey for use with OpenSSH via the \"new\" ed25519-sk key type that supports FIDO compliant hardware keys.",{"draft":1322,"excerpt":1323},false,{"type":8,"value":1324},[1325],[11,1326,1327,1047,1330,1051],{},[17,1328,1046],{"href":1044,"rel":1329},[21],[56,1331,1050],{},"/blog/ssh-ed25519-sk-yubikey",{"title":1037,"description":1320},"blog/ssh-ed25519-sk-yubikey",[1336,1337],"unix","configurations","CU-D4jtx__VMzdTNSwp6_IxMIA00voWzcgXERIMkEOo",{"id":1340,"title":1341,"body":1342,"categories":1495,"date":1496,"description":1497,"extension":154,"img":155,"meta":1498,"navigation":161,"path":1510,"seo":1511,"stem":1512,"tags":1513,"__hash__":1516},"content/blog/vim-fugitive-gpg-pinentry.md","Using pinentry-mac to sign commits from vim-fugitive",{"type":8,"value":1343,"toc":1491},[1344,1361,1365,1386,1390,1393,1411,1421,1427,1433,1452,1455,1486,1489],[11,1345,1346,1347,1352,1353,1356,1357,1360],{},"In order to sign git commits from within Vim using a plugin like ",[17,1348,1351],{"href":1349,"rel":1350},"https://github.com/tpope/vim-fugitive",[21],"tpope/vim-fugitive",", it is necessary to configure the ",[56,1354,1355],{},"gpg-agent"," to use a GUI based ",[56,1358,1359],{},"pinentry-program",".",[23,1362,1364],{"id":1363},"preface","Preface",[11,1366,1367,1368,1373,1374,1356,1376,1378,1379,1382,1383,1360],{},"The man, the myth, the legend, Timothy Popallopollis himself ",[17,1369,1372],{"href":1370,"rel":1371},"https://github.com/tpope/vim-fugitive/issues/846#issuecomment-253816577",[21],"recommends"," configuring your ",[56,1375,1355],{},[56,1377,1359],{},". On macOS this can be done quite by simply installing ",[56,1380,1381],{},"pinentry-mac",", and updating your ",[56,1384,1385],{},"gpg-agent.conf",[23,1387,1389],{"id":1388},"configuration","Configuration",[11,1391,1392],{},"First things first, let's install the pinentry program.",[49,1394,1398],{"className":1395,"code":1396,"language":1397,"meta":58,"style":58},"language-bash shiki shiki-themes github-dark","$ brew install pinentry-mac\n","bash",[56,1399,1400],{"__ignoreMap":58},[288,1401,1402,1404,1406,1408],{"class":290,"line":291},[288,1403,1087],{"class":330},[288,1405,1090],{"class":311},[288,1407,1093],{"class":311},[288,1409,1410],{"class":311}," pinentry-mac\n",[11,1412,1413,1414,1416,1417,1420],{},"Then, all we need to do is set the ",[56,1415,1359],{}," option in your ",[56,1418,1419],{},"~/.gnupg/gpg-agent.conf"," file.",[49,1422,1425],{"className":1423,"code":1424,"language":54},[52],"default-cache-ttl 600\nmax-cache-ttl 7200\npinentry-program /opt/homebrew/bin/pinentry-mac\n",[56,1426,1424],{"__ignoreMap":58},[11,1428,1429,1430,1360],{},"If your don't know the path to your pinentry program, you can throw down a quick ",[56,1431,1432],{},"which",[49,1434,1436],{"className":1395,"code":1435,"language":1397,"meta":58,"style":58},"$ which pinentry-mac\n/opt/homebrew/bin/pinentry-mac\n",[56,1437,1438,1447],{"__ignoreMap":58},[288,1439,1440,1442,1445],{"class":290,"line":291},[288,1441,1087],{"class":330},[288,1443,1444],{"class":311}," which",[288,1446,1410],{"class":311},[288,1448,1449],{"class":290,"line":144},[288,1450,1451],{"class":330},"/opt/homebrew/bin/pinentry-mac\n",[11,1453,1454],{},"Or use your Homebrew prefix.",[49,1456,1458],{"className":1395,"code":1457,"language":1397,"meta":58,"style":58},"$ echo $(brew --prefix)/bin/pinentry-mac\n/opt/homebrew/bin/pinentry-mac\n",[56,1459,1460,1482],{"__ignoreMap":58},[288,1461,1462,1464,1467,1470,1473,1476,1479],{"class":290,"line":291},[288,1463,1087],{"class":330},[288,1465,1466],{"class":311}," echo",[288,1468,1469],{"class":304}," $(",[288,1471,1472],{"class":330},"brew",[288,1474,1475],{"class":527}," --prefix",[288,1477,1478],{"class":304},")",[288,1480,1481],{"class":311},"/bin/pinentry-mac\n",[288,1483,1484],{"class":290,"line":144},[288,1485,1451],{"class":330},[11,1487,1488],{},"But that's all it takes. Now, you should be prompted to enter your gpg pin in an external window when signing commits from vim.",[1006,1490,1313],{},{"title":58,"searchDepth":144,"depth":144,"links":1492},[1493,1494],{"id":1363,"depth":144,"text":1364},{"id":1388,"depth":144,"text":1389},[1317,1318],"2024-05-11T00:00:00.000Z","In order to sign git commits from within Vim using a plugin like tpope/vim-fugitive, it is necessary to configure the gpg-agent to use a GUI based pinentry-program.",{"draft":1322,"excerpt":1499},{"type":8,"value":1500},[1501],[11,1502,1346,1503,1352,1506,1356,1508,1360],{},[17,1504,1351],{"href":1349,"rel":1505},[21],[56,1507,1355],{},[56,1509,1359],{},"/blog/vim-fugitive-gpg-pinentry",{"title":1341,"description":1497},"blog/vim-fugitive-gpg-pinentry",[1514,1515],"vim","tip","kIkGil0S243aUTnUKm-WtRqCNZ4m6n-DcGOh6v7yi8s",{"id":1518,"title":1519,"body":1520,"categories":1920,"date":1921,"description":1922,"extension":154,"img":155,"meta":1923,"navigation":161,"path":1937,"seo":1938,"stem":1939,"tags":1940,"__hash__":1942},"content/blog/podcast-transcription-whispercpp.md","Easily Transcribe Podcasts with Whisper.cpp",{"type":8,"value":1521,"toc":1915},[1522,1543,1547,1567,1615,1621,1713,1720,1726,1802,1805,1903,1906,1912],[11,1523,1524,1525,1530,1531,1536,1537,1542],{},"If you've ever had the need to transcribe a podcast, lecture, or some other audio recording, it turns out it's surprisingly easy with the extremely impressive ",[17,1526,1529],{"href":1527,"rel":1528},"https://github.com/ggerganov/whisper.cpp",[21],"whisper.cpp"," project. This high-performance fork of ",[17,1532,1535],{"href":1533,"rel":1534},"https://github.com/openai/whisper",[21],"OpenAI's Whisper"," can run on all sorts of hardware -- including my M1 Mac Mini. Let's walk through an example from start-to-finish of transcribing an episode of the ",[17,1538,1541],{"href":1539,"rel":1540},"https://podcasts.apple.com/us/podcast/alter-everything/id1356137854",[21],"Alter Everything"," podcast.",[23,1544,1546],{"id":1545},"obtain-audio-files","Obtain Audio File(s)",[11,1548,1549,1550,1553,1554,1557,1558,1560,1561,1563,1564,1360],{},"First, let's get the ",[56,1551,1552],{},"wav"," file from YouTube using the ",[56,1555,1556],{},"youtube-dl"," utility. It should be noted that ",[56,1559,1529],{}," expects ",[56,1562,1552],{}," filetypes, and this utility defaults to ",[56,1565,1566],{},"mp3",[49,1568,1570],{"className":1078,"code":1569,"language":1080,"meta":58,"style":58}," $ youtube-dl \\\n    --extract-audio \\\n    --audio-format wav \\\n    --output podcast.wav \\\n    \"https://www.youtube.com/watch?v=CoUN690wSYQ\"\n",[56,1571,1572,1583,1590,1600,1610],{"__ignoreMap":58},[288,1573,1574,1577,1580],{"class":290,"line":291},[288,1575,1576],{"class":330}," $",[288,1578,1579],{"class":311}," youtube-dl",[288,1581,1582],{"class":527}," \\\n",[288,1584,1585,1588],{"class":290,"line":144},[288,1586,1587],{"class":527},"    --extract-audio",[288,1589,1582],{"class":527},[288,1591,1592,1595,1598],{"class":290,"line":315},[288,1593,1594],{"class":527},"    --audio-format",[288,1596,1597],{"class":311}," wav",[288,1599,1582],{"class":527},[288,1601,1602,1605,1608],{"class":290,"line":321},[288,1603,1604],{"class":527},"    --output",[288,1606,1607],{"class":311}," podcast.wav",[288,1609,1582],{"class":527},[288,1611,1612],{"class":290,"line":343},[288,1613,1614],{"class":311},"    \"https://www.youtube.com/watch?v=CoUN690wSYQ\"\n",[11,1616,1617,1618,1620],{},"This file has a 44.1 kHz sample rate, and ",[56,1619,1529],{}," expects 16 kHz, so let's go ahead and convert that.",[49,1622,1624],{"className":1078,"code":1623,"language":1080,"meta":58,"style":58}," $ file podcast.wav\npodcast.wav: RIFF (little-endian) data, WAVE audio, Microsoft PCM, 16 bit, stereo 44100 Hz\n\n $ ffmpeg -i podcast.wav -ar 16000 podcast-16khz.wav\n\n $ file podcast-16khz.wav\npodcast-16khz.wav: RIFF (little-endian) data, WAVE audio, Microsoft PCM, 16 bit, stereo 16000 Hz\n\n# NOTE: it looks like it's possible to specify this conversion as a post-process as a\n# flag to the `youtube-dl` command -- I will explore this further next time...\n# youtube-dl --extract-audio --audio-quality 0 --audio-format mp3 --postprocessor-args \"-ar 44100\" %dl%\n",[56,1625,1626,1636,1647,1651,1672,1676,1684,1694,1698,1703,1708],{"__ignoreMap":58},[288,1627,1628,1630,1633],{"class":290,"line":291},[288,1629,1576],{"class":330},[288,1631,1632],{"class":311}," file",[288,1634,1635],{"class":311}," podcast.wav\n",[288,1637,1638,1641,1644],{"class":290,"line":144},[288,1639,1640],{"class":330},"podcast.wav:",[288,1642,1643],{"class":311}," RIFF",[288,1645,1646],{"class":304}," (little-endian) data, WAVE audio, Microsoft PCM, 16 bit, stereo 44100 Hz\n",[288,1648,1649],{"class":290,"line":315},[288,1650,318],{"emptyLinePlaceholder":161},[288,1652,1653,1655,1658,1661,1663,1666,1669],{"class":290,"line":321},[288,1654,1576],{"class":330},[288,1656,1657],{"class":311}," ffmpeg",[288,1659,1660],{"class":527}," -i",[288,1662,1607],{"class":311},[288,1664,1665],{"class":527}," -ar",[288,1667,1668],{"class":527}," 16000",[288,1670,1671],{"class":311}," podcast-16khz.wav\n",[288,1673,1674],{"class":290,"line":343},[288,1675,318],{"emptyLinePlaceholder":161},[288,1677,1678,1680,1682],{"class":290,"line":351},[288,1679,1576],{"class":330},[288,1681,1632],{"class":311},[288,1683,1671],{"class":311},[288,1685,1686,1689,1691],{"class":290,"line":357},[288,1687,1688],{"class":330},"podcast-16khz.wav:",[288,1690,1643],{"class":311},[288,1692,1693],{"class":304}," (little-endian) data, WAVE audio, Microsoft PCM, 16 bit, stereo 16000 Hz\n",[288,1695,1696],{"class":290,"line":363},[288,1697,318],{"emptyLinePlaceholder":161},[288,1699,1700],{"class":290,"line":369},[288,1701,1702],{"class":294},"# NOTE: it looks like it's possible to specify this conversion as a post-process as a\n",[288,1704,1705],{"class":290,"line":375},[288,1706,1707],{"class":294},"# flag to the `youtube-dl` command -- I will explore this further next time...\n",[288,1709,1710],{"class":290,"line":549},[288,1711,1712],{"class":294},"# youtube-dl --extract-audio --audio-quality 0 --audio-format mp3 --postprocessor-args \"-ar 44100\" %dl%\n",[23,1714,1716,1717,1719],{"id":1715},"build-whispercpp-transcribe-audio","Build ",[56,1718,1529],{}," & Transcribe Audio",[11,1721,1722,1723,1725],{},"Then, let's get the latest version of ",[56,1724,1529],{},", download the English Whisper model, and build the example.",[49,1727,1729],{"className":1078,"code":1728,"language":1080,"meta":58,"style":58},"# Clone the `whisper.cpp` repository\n $ git clone --depth 1 git@github.com:ggerganov/whisper.cpp && cd whisper.cpp\n\n# Download the English Whisper model in `ggml` format\n $ bash ./models/download-ggml-model.sh base.en\n\n# Build the main example\n $ make\n",[56,1730,1731,1736,1764,1768,1773,1786,1790,1795],{"__ignoreMap":58},[288,1732,1733],{"class":290,"line":291},[288,1734,1735],{"class":294},"# Clone the `whisper.cpp` repository\n",[288,1737,1738,1740,1743,1746,1749,1752,1755,1758,1761],{"class":290,"line":144},[288,1739,1576],{"class":330},[288,1741,1742],{"class":311}," git",[288,1744,1745],{"class":311}," clone",[288,1747,1748],{"class":527}," --depth",[288,1750,1751],{"class":527}," 1",[288,1753,1754],{"class":311}," git@github.com:ggerganov/whisper.cpp",[288,1756,1757],{"class":304}," && ",[288,1759,1760],{"class":527},"cd",[288,1762,1763],{"class":311}," whisper.cpp\n",[288,1765,1766],{"class":290,"line":315},[288,1767,318],{"emptyLinePlaceholder":161},[288,1769,1770],{"class":290,"line":321},[288,1771,1772],{"class":294},"# Download the English Whisper model in `ggml` format\n",[288,1774,1775,1777,1780,1783],{"class":290,"line":343},[288,1776,1576],{"class":330},[288,1778,1779],{"class":311}," bash",[288,1781,1782],{"class":311}," ./models/download-ggml-model.sh",[288,1784,1785],{"class":311}," base.en\n",[288,1787,1788],{"class":290,"line":351},[288,1789,318],{"emptyLinePlaceholder":161},[288,1791,1792],{"class":290,"line":357},[288,1793,1794],{"class":294},"# Build the main example\n",[288,1796,1797,1799],{"class":290,"line":363},[288,1798,1576],{"class":330},[288,1800,1801],{"class":311}," make\n",[11,1803,1804],{},"And finally, let's transcribe that podcast!",[49,1806,1808],{"className":1078,"code":1807,"language":1080,"meta":58,"style":58}," $ ./main \\\n    -m ~/workspace/whisper.cpp/models/ggml-base.en.bin \\\n    -f ~/Downloads/podcast-16khz.wav \\\n    --output-vtt \\\n    --output-file out\n\n# whisper_print_timings:     load time =   114.71 ms\n# whisper_print_timings:     fallbacks =   0 p /   0 h\n# whisper_print_timings:      mel time =   692.20 ms\n# whisper_print_timings:   sample time = 22278.10 ms / 27893 runs (    0.80 ms per run)\n# whisper_print_timings:   encode time = 10000.75 ms /    55 runs (  181.83 ms per run)\n# whisper_print_timings:   decode time =   331.77 ms /    54 runs (    6.14 ms per run)\n# whisper_print_timings:   batchd time = 45236.73 ms / 27566 runs (    1.64 ms per run)\n# whisper_print_timings:   prompt time =  1921.90 ms / 11832 runs (    0.16 ms per run)\n# whisper_print_timings:    total time = 80709.54 ms\n",[56,1809,1810,1819,1829,1839,1846,1854,1858,1863,1868,1873,1878,1883,1888,1893,1898],{"__ignoreMap":58},[288,1811,1812,1814,1817],{"class":290,"line":291},[288,1813,1576],{"class":330},[288,1815,1816],{"class":311}," ./main",[288,1818,1582],{"class":527},[288,1820,1821,1824,1827],{"class":290,"line":144},[288,1822,1823],{"class":527},"    -m",[288,1825,1826],{"class":311}," ~/workspace/whisper.cpp/models/ggml-base.en.bin",[288,1828,1582],{"class":527},[288,1830,1831,1834,1837],{"class":290,"line":315},[288,1832,1833],{"class":527},"    -f",[288,1835,1836],{"class":311}," ~/Downloads/podcast-16khz.wav",[288,1838,1582],{"class":527},[288,1840,1841,1844],{"class":290,"line":321},[288,1842,1843],{"class":527},"    --output-vtt",[288,1845,1582],{"class":527},[288,1847,1848,1851],{"class":290,"line":343},[288,1849,1850],{"class":527},"    --output-file",[288,1852,1853],{"class":311}," out\n",[288,1855,1856],{"class":290,"line":351},[288,1857,318],{"emptyLinePlaceholder":161},[288,1859,1860],{"class":290,"line":357},[288,1861,1862],{"class":294},"# whisper_print_timings:     load time =   114.71 ms\n",[288,1864,1865],{"class":290,"line":363},[288,1866,1867],{"class":294},"# whisper_print_timings:     fallbacks =   0 p /   0 h\n",[288,1869,1870],{"class":290,"line":369},[288,1871,1872],{"class":294},"# whisper_print_timings:      mel time =   692.20 ms\n",[288,1874,1875],{"class":290,"line":375},[288,1876,1877],{"class":294},"# whisper_print_timings:   sample time = 22278.10 ms / 27893 runs (    0.80 ms per run)\n",[288,1879,1880],{"class":290,"line":549},[288,1881,1882],{"class":294},"# whisper_print_timings:   encode time = 10000.75 ms /    55 runs (  181.83 ms per run)\n",[288,1884,1885],{"class":290,"line":561},[288,1886,1887],{"class":294},"# whisper_print_timings:   decode time =   331.77 ms /    54 runs (    6.14 ms per run)\n",[288,1889,1890],{"class":290,"line":587},[288,1891,1892],{"class":294},"# whisper_print_timings:   batchd time = 45236.73 ms / 27566 runs (    1.64 ms per run)\n",[288,1894,1895],{"class":290,"line":612},[288,1896,1897],{"class":294},"# whisper_print_timings:   prompt time =  1921.90 ms / 11832 runs (    0.16 ms per run)\n",[288,1899,1900],{"class":290,"line":617},[288,1901,1902],{"class":294},"# whisper_print_timings:    total time = 80709.54 ms\n",[11,1904,1905],{},"A full podcast transcribed in ~80 seconds on an M1 Mac Mini -- not too bad!",[49,1907,1910],{"className":1908,"code":1909,"language":54},[52],"# out.vtt\n\n00:00:00.000 --> 00:00:06.480\n >> Hi everyone. We recently launched a short engagement feedback survey for the Alter Everything\n\n00:00:06.480 --> 00:00:11.360\n podcast. Click the link in the episode description wherever you're listening to let us know what\n\n00:00:11.360 --> 00:00:16.320\n you think and help us improve our show.\n\n00:00:16.320 --> 00:00:21.200\n Welcome to Alter Everything, a podcast about data science and analytics culture. I'm Megan\n\n00:00:21.200 --> 00:00:26.440\n Dibble and today I'm talking with Nick Schrock, CTO and founder of Dagster Labs. We discussed\n\n00:00:26.440 --> 00:00:31.560\n data engineering trends, challenges in the field, why he started his company, and what\n\n00:00:31.560 --> 00:00:38.960\n makes him excited about the future of data engineering. Let's get started.\n\n00:00:38.960 --> 00:00:42.720\n >> Hi, Nick. It's great to have you on our show today. Thanks for being here.\n\n00:00:42.720 --> 00:00:43.920\n >> Thanks for having me.\n\n00:00:43.920 --> 00:00:48.280\n >> Yeah. Could you start off by giving an introduction to yourself for our listeners?\n\n00:00:48.280 --> 00:00:52.920\n >> Sure. My name is Nick Schrock. I'm the CTO and founder of Dagster Labs. There's the\n\n00:00:52.920 --> 00:00:59.520\n company behind Dagster, which is a data orchestration framework. Prior to doing this, I was an engineer\n\n00:00:59.520 --> 00:01:05.960\n at Facebook from 2009, 2017. While I was there, I found a team called product infrastructure\n\n00:01:05.960 --> 00:01:09.800\n whose goal was to make our application developers more efficient and productive, and a bunch\n\n00:01:09.800 --> 00:01:13.840\n of open source work came out of that actually, one of which was React, which I had nothing\n\n00:01:13.840 --> 00:01:18.040\n to do with, but actually the CEO of Dagster Labs co-created and I personally co-created\n\n00:01:18.040 --> 00:01:22.640\n GraphQL. So as I like to say, Pete and I were present at the creation of the full hipster\n\n00:01:22.640 --> 00:01:28.680\n stack. I moved on to Facebook in 2017, figuring out what to do next, and this data engineering\n\n00:01:28.680 --> 00:01:32.960\n and data orchestration problem really got me hooked actually quite soon after I left,\n\n00:01:32.960 --> 00:01:36.280\n and the rest is history. I'm sure we'll get into that more.\n",[56,1911,1909],{"__ignoreMap":58},[1006,1913,1914],{},"html pre.shiki code .svObZ, html code.shiki .svObZ{--shiki-default:#B392F0}html pre.shiki code .sU2Wk, html code.shiki .sU2Wk{--shiki-default:#9ECBFF}html pre.shiki code .sDLfK, html code.shiki .sDLfK{--shiki-default:#79B8FF}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html pre.shiki code .s95oV, html code.shiki .s95oV{--shiki-default:#E1E4E8}html pre.shiki code .sAwPA, html code.shiki .sAwPA{--shiki-default:#6A737D}",{"title":58,"searchDepth":144,"depth":144,"links":1916},[1917,1918],{"id":1545,"depth":144,"text":1546},{"id":1715,"depth":144,"text":1919},"Build whisper.cpp & Transcribe Audio",[232],"2024-01-08T00:00:00.000Z","If you've ever had the need to transcribe a podcast, lecture, or some other audio recording, it turns out it's surprisingly easy with the extremely impressive whisper.cpp project. This high-performance fork of OpenAI's Whisper can run on all sorts of hardware -- including my M1 Mac Mini. Let's walk through an example from start-to-finish of transcribing an episode of the Alter Everything podcast.",{"draft":1322,"excerpt":1924},{"type":8,"value":1925},[1926],[11,1927,1524,1928,1530,1931,1536,1934,1542],{},[17,1929,1529],{"href":1527,"rel":1930},[21],[17,1932,1535],{"href":1533,"rel":1933},[21],[17,1935,1541],{"href":1539,"rel":1936},[21],"/blog/podcast-transcription-whispercpp",{"title":1519,"description":1922},"blog/podcast-transcription-whispercpp",[1529,1941],"ml","1p8wAc0piZjElJZbTA_kVXNb--AFv2AHN6Qfd7I6X8A",{"id":1944,"title":1945,"body":1946,"categories":2908,"date":2909,"description":2910,"extension":154,"img":155,"meta":2911,"navigation":161,"path":2920,"seo":2921,"stem":2922,"tags":2923,"__hash__":2925},"content/blog/nuxt-content-rss-feed.md","How To Add an RSS Feed to a Nuxt Website",{"type":8,"value":1947,"toc":2903},[1948,1957,1959,1974,1978,1987,2008,2018,2035,2546,2565,2607,2611,2618,2621,2637,2643,2852,2860,2900],[11,1949,1950,1951,1956],{},"If you are a user of ",[17,1952,1955],{"href":1953,"rel":1954},"https://content.nuxt.com/",[21],"Nuxt Content"," and you wish to configure an RSS feed for your website, it's a surprisingly straight forward process! In this article, we will walk through the code changes required to host an RSS feed for both a statically generated, and Universal Nuxt application.",[23,1958,1364],{"id":1363},[11,1960,1961,1962,1967,1968,1973],{},"In version 2 of Nuxt, the community module, ",[17,1963,1966],{"href":1964,"rel":1965},"https://github.com/nuxt-community/feed-module",[21],"nuxt-community/feed-module"," was a popular choice for adding an RSS feed to your website. However, there has been an unresolved ",[17,1969,1972],{"href":1970,"rel":1971},"https://github.com/nuxt-community/feed-module/issues/106",[21],"open issue"," since April 1st, 2022 to add support for Nuxt v3. Thankfully, implementing this feature without a module is relatively straight forward.",[23,1975,1977],{"id":1976},"instructions","Instructions",[11,1979,1980,1981,1986],{},"First, install the ",[17,1982,1985],{"href":1983,"rel":1984},"https://www.npmjs.com/package/feed",[21],"feed"," library into your project:",[49,1988,1992],{"className":1989,"code":1990,"language":1991,"meta":58,"style":58},"language-shell shiki shiki-themes github-dark","npm i -D feed\n","shell",[56,1993,1994],{"__ignoreMap":58},[288,1995,1996,1999,2002,2005],{"class":290,"line":291},[288,1997,1998],{"class":330},"npm",[288,2000,2001],{"class":311}," i",[288,2003,2004],{"class":527}," -D",[288,2006,2007],{"class":311}," feed\n",[11,2009,2010,2011,2014,2015,1360],{},"Then, create a ",[56,2012,2013],{},"server/"," folder in your project if it does not already exist, and create a file named ",[56,2016,2017],{},"server/routes/atom.ts",[11,2019,2020,2021,2023,2024,2026,2027,2030,2031,2034],{},"Here, we will leverage the ",[56,2022,1985],{}," library and construct an XML representation of our Nuxt content. As you can see, we first define our ",[56,2025,1985],{}," with metadata associated with our RSS feed. This will be used by RSS readers to provide context to the end user. Then, we query our Nuxt content with ",[56,2028,2029],{},"serverQueryContent"," and append a ",[56,2032,2033],{},"feed.addItem"," for each article.",[49,2036,2040],{"className":2037,"code":2038,"language":2039,"meta":58,"style":58},"language-ts shiki shiki-themes github-dark","import { serverQueryContent } from '#content/server';\nimport { Feed } from 'feed';\n\nconst BASE_URL = \"https://mywebsite.com\"\nconst AUTHOR_NAME = \"Firstname Lastname\"\n\nexport default defineEventHandler(async (event) => {\n\n    const feed = new Feed({\n      title: \"My Title\",\n      description: \"My Description\",\n      id: BASE_URL,\n      link: BASE_URL,\n      language: \"en\",\n      image: `${BASE_URL}/images/placeholder.png`,\n      favicon: `${BASE_URL}/favicon.ico`,\n      copyright: `All rights reserved ${new Date().getFullYear()}, ${AUTHOR_NAME}`,\n      updated: new Date(),\n      generator: \"Nuxt static site generation + Feed for Node.js\",\n      feedLinks: {\n        atom: `${BASE_URL}/atom`\n      },\n      author: {\n        name: AUTHOR_NAME,\n      }\n    });\n\n    const articles = await serverQueryContent(event).find();\n\n    articles.forEach((article) => {\n      feed.addItem({\n        title: article.title ? article.title : \"Missing Title\",\n        id: article._path,\n        link: `${BASE_URL}${article._path}`,\n        description: article.description,\n        author: [\n          {\n            name: AUTHOR_NAME,\n          },\n        ],\n        date: new Date(article.date),\n        image: article.cover_image ? `${BASE_URL}/${article.cover_image}` : undefined\n      });\n    });\n\n    return feed.atom1();\n});\n","ts",[56,2041,2042,2056,2070,2074,2087,2099,2103,2128,2132,2151,2162,2172,2182,2191,2201,2216,2230,2264,2276,2286,2291,2303,2308,2313,2322,2327,2332,2336,2359,2363,2383,2393,2412,2417,2440,2445,2450,2455,2464,2469,2474,2486,2516,2521,2525,2529,2542],{"__ignoreMap":58},[288,2043,2044,2046,2049,2051,2054],{"class":290,"line":291},[288,2045,301],{"class":300},[288,2047,2048],{"class":304}," { serverQueryContent } ",[288,2050,308],{"class":300},[288,2052,2053],{"class":311}," '#content/server'",[288,2055,678],{"class":304},[288,2057,2058,2060,2063,2065,2068],{"class":290,"line":144},[288,2059,301],{"class":300},[288,2061,2062],{"class":304}," { Feed } ",[288,2064,308],{"class":300},[288,2066,2067],{"class":311}," 'feed'",[288,2069,678],{"class":304},[288,2071,2072],{"class":290,"line":315},[288,2073,318],{"emptyLinePlaceholder":161},[288,2075,2076,2079,2082,2084],{"class":290,"line":321},[288,2077,2078],{"class":300},"const",[288,2080,2081],{"class":527}," BASE_URL",[288,2083,570],{"class":300},[288,2085,2086],{"class":311}," \"https://mywebsite.com\"\n",[288,2088,2089,2091,2094,2096],{"class":290,"line":343},[288,2090,2078],{"class":300},[288,2092,2093],{"class":527}," AUTHOR_NAME",[288,2095,570],{"class":300},[288,2097,2098],{"class":311}," \"Firstname Lastname\"\n",[288,2100,2101],{"class":290,"line":351},[288,2102,318],{"emptyLinePlaceholder":161},[288,2104,2105,2107,2109,2112,2114,2117,2119,2122,2124,2126],{"class":290,"line":357},[288,2106,324],{"class":300},[288,2108,327],{"class":300},[288,2110,2111],{"class":330}," defineEventHandler",[288,2113,604],{"class":304},[288,2115,2116],{"class":300},"async",[288,2118,573],{"class":304},[288,2120,2121],{"class":576},"event",[288,2123,580],{"class":304},[288,2125,337],{"class":300},[288,2127,340],{"class":304},[288,2129,2130],{"class":290,"line":363},[288,2131,318],{"emptyLinePlaceholder":161},[288,2133,2134,2137,2140,2142,2145,2148],{"class":290,"line":369},[288,2135,2136],{"class":300},"    const",[288,2138,2139],{"class":527}," feed",[288,2141,570],{"class":300},[288,2143,2144],{"class":300}," new",[288,2146,2147],{"class":330}," Feed",[288,2149,2150],{"class":304},"({\n",[288,2152,2153,2156,2159],{"class":290,"line":375},[288,2154,2155],{"class":304},"      title: ",[288,2157,2158],{"class":311},"\"My Title\"",[288,2160,2161],{"class":304},",\n",[288,2163,2164,2167,2170],{"class":290,"line":549},[288,2165,2166],{"class":304},"      description: ",[288,2168,2169],{"class":311},"\"My Description\"",[288,2171,2161],{"class":304},[288,2173,2174,2177,2180],{"class":290,"line":561},[288,2175,2176],{"class":304},"      id: ",[288,2178,2179],{"class":527},"BASE_URL",[288,2181,2161],{"class":304},[288,2183,2184,2187,2189],{"class":290,"line":587},[288,2185,2186],{"class":304},"      link: ",[288,2188,2179],{"class":527},[288,2190,2161],{"class":304},[288,2192,2193,2196,2199],{"class":290,"line":612},[288,2194,2195],{"class":304},"      language: ",[288,2197,2198],{"class":311},"\"en\"",[288,2200,2161],{"class":304},[288,2202,2203,2206,2209,2211,2214],{"class":290,"line":617},[288,2204,2205],{"class":304},"      image: ",[288,2207,2208],{"class":311},"`${",[288,2210,2179],{"class":527},[288,2212,2213],{"class":311},"}/images/placeholder.png`",[288,2215,2161],{"class":304},[288,2217,2218,2221,2223,2225,2228],{"class":290,"line":630},[288,2219,2220],{"class":304},"      favicon: ",[288,2222,2208],{"class":311},[288,2224,2179],{"class":527},[288,2226,2227],{"class":311},"}/favicon.ico`",[288,2229,2161],{"class":304},[288,2231,2232,2235,2238,2241,2244,2247,2250,2253,2256,2259,2262],{"class":290,"line":643},[288,2233,2234],{"class":304},"      copyright: ",[288,2236,2237],{"class":311},"`All rights reserved ${",[288,2239,2240],{"class":300},"new",[288,2242,2243],{"class":330}," Date",[288,2245,2246],{"class":311},"().",[288,2248,2249],{"class":330},"getFullYear",[288,2251,2252],{"class":311},"()",[288,2254,2255],{"class":311},"}, ${",[288,2257,2258],{"class":527},"AUTHOR_NAME",[288,2260,2261],{"class":311},"}`",[288,2263,2161],{"class":304},[288,2265,2266,2269,2271,2273],{"class":290,"line":648},[288,2267,2268],{"class":304},"      updated: ",[288,2270,2240],{"class":300},[288,2272,2243],{"class":330},[288,2274,2275],{"class":304},"(),\n",[288,2277,2278,2281,2284],{"class":290,"line":657},[288,2279,2280],{"class":304},"      generator: ",[288,2282,2283],{"class":311},"\"Nuxt static site generation + Feed for Node.js\"",[288,2285,2161],{"class":304},[288,2287,2288],{"class":290,"line":665},[288,2289,2290],{"class":304},"      feedLinks: {\n",[288,2292,2293,2296,2298,2300],{"class":290,"line":681},[288,2294,2295],{"class":304},"        atom: ",[288,2297,2208],{"class":311},[288,2299,2179],{"class":527},[288,2301,2302],{"class":311},"}/atom`\n",[288,2304,2305],{"class":290,"line":686},[288,2306,2307],{"class":304},"      },\n",[288,2309,2310],{"class":290,"line":704},[288,2311,2312],{"class":304},"      author: {\n",[288,2314,2315,2318,2320],{"class":290,"line":726},[288,2316,2317],{"class":304},"        name: ",[288,2319,2258],{"class":527},[288,2321,2161],{"class":304},[288,2323,2324],{"class":290,"line":732},[288,2325,2326],{"class":304},"      }\n",[288,2328,2329],{"class":290,"line":737},[288,2330,2331],{"class":304},"    });\n",[288,2333,2334],{"class":290,"line":753},[288,2335,318],{"emptyLinePlaceholder":161},[288,2337,2338,2340,2343,2345,2348,2351,2354,2357],{"class":290,"line":781},[288,2339,2136],{"class":300},[288,2341,2342],{"class":527}," articles",[288,2344,570],{"class":300},[288,2346,2347],{"class":300}," await",[288,2349,2350],{"class":330}," serverQueryContent",[288,2352,2353],{"class":304},"(event).",[288,2355,2356],{"class":330},"find",[288,2358,868],{"class":304},[288,2360,2361],{"class":290,"line":786},[288,2362,318],{"emptyLinePlaceholder":161},[288,2364,2365,2368,2371,2374,2377,2379,2381],{"class":290,"line":791},[288,2366,2367],{"class":304},"    articles.",[288,2369,2370],{"class":330},"forEach",[288,2372,2373],{"class":304},"((",[288,2375,2376],{"class":576},"article",[288,2378,580],{"class":304},[288,2380,337],{"class":300},[288,2382,340],{"class":304},[288,2384,2385,2388,2391],{"class":290,"line":807},[288,2386,2387],{"class":304},"      feed.",[288,2389,2390],{"class":330},"addItem",[288,2392,2150],{"class":304},[288,2394,2395,2398,2401,2404,2407,2410],{"class":290,"line":824},[288,2396,2397],{"class":304},"        title: article.title ",[288,2399,2400],{"class":300},"?",[288,2402,2403],{"class":304}," article.title ",[288,2405,2406],{"class":300},":",[288,2408,2409],{"class":311}," \"Missing Title\"",[288,2411,2161],{"class":304},[288,2413,2414],{"class":290,"line":829},[288,2415,2416],{"class":304},"        id: article._path,\n",[288,2418,2419,2422,2424,2426,2429,2431,2433,2436,2438],{"class":290,"line":834},[288,2420,2421],{"class":304},"        link: ",[288,2423,2208],{"class":311},[288,2425,2179],{"class":527},[288,2427,2428],{"class":311},"}${",[288,2430,2376],{"class":304},[288,2432,1360],{"class":311},[288,2434,2435],{"class":304},"_path",[288,2437,2261],{"class":311},[288,2439,2161],{"class":304},[288,2441,2442],{"class":290,"line":850},[288,2443,2444],{"class":304},"        description: article.description,\n",[288,2446,2447],{"class":290,"line":860},[288,2448,2449],{"class":304},"        author: [\n",[288,2451,2452],{"class":290,"line":871},[288,2453,2454],{"class":304},"          {\n",[288,2456,2457,2460,2462],{"class":290,"line":876},[288,2458,2459],{"class":304},"            name: ",[288,2461,2258],{"class":527},[288,2463,2161],{"class":304},[288,2465,2466],{"class":290,"line":885},[288,2467,2468],{"class":304},"          },\n",[288,2470,2471],{"class":290,"line":904},[288,2472,2473],{"class":304},"        ],\n",[288,2475,2476,2479,2481,2483],{"class":290,"line":910},[288,2477,2478],{"class":304},"        date: ",[288,2480,2240],{"class":300},[288,2482,2243],{"class":330},[288,2484,2485],{"class":304},"(article.date),\n",[288,2487,2488,2491,2493,2496,2498,2501,2503,2505,2508,2510,2513],{"class":290,"line":921},[288,2489,2490],{"class":304},"        image: article.cover_image ",[288,2492,2400],{"class":300},[288,2494,2495],{"class":311}," `${",[288,2497,2179],{"class":527},[288,2499,2500],{"class":311},"}/${",[288,2502,2376],{"class":304},[288,2504,1360],{"class":311},[288,2506,2507],{"class":304},"cover_image",[288,2509,2261],{"class":311},[288,2511,2512],{"class":300}," :",[288,2514,2515],{"class":527}," undefined\n",[288,2517,2518],{"class":290,"line":931},[288,2519,2520],{"class":304},"      });\n",[288,2522,2523],{"class":290,"line":941},[288,2524,2331],{"class":304},[288,2526,2527],{"class":290,"line":946},[288,2528,318],{"emptyLinePlaceholder":161},[288,2530,2531,2534,2537,2540],{"class":290,"line":957},[288,2532,2533],{"class":300},"    return",[288,2535,2536],{"class":304}," feed.",[288,2538,2539],{"class":330},"atom1",[288,2541,868],{"class":304},[288,2543,2544],{"class":290,"line":962},[288,2545,992],{"class":304},[11,2547,2548,2549,2552,2553,2556,2557,2560,2561,2564],{},"And that's just about it! Except, if you are statically generating your website with the ",[56,2550,2551],{},"nuxt generate"," command, you will need to configure this server-side route to be pre-rendered on site generation.  This is as simple as adding a ",[56,2554,2555],{},"nitro"," ",[56,2558,2559],{},"prerender"," definition in your ",[56,2562,2563],{},"nuxt.config.ts"," file, like so:",[49,2566,2568],{"className":2037,"code":2567,"language":2039,"meta":58,"style":58},"nitro: {\n  prerender: {\n    routes: ['/atom']\n  }\n}\n",[56,2569,2570,2577,2584,2598,2602],{"__ignoreMap":58},[288,2571,2572,2574],{"class":290,"line":291},[288,2573,2555],{"class":330},[288,2575,2576],{"class":304},": {\n",[288,2578,2579,2582],{"class":290,"line":144},[288,2580,2581],{"class":330},"  prerender",[288,2583,2576],{"class":304},[288,2585,2586,2589,2592,2595],{"class":290,"line":315},[288,2587,2588],{"class":330},"    routes",[288,2590,2591],{"class":304},": [",[288,2593,2594],{"class":311},"'/atom'",[288,2596,2597],{"class":304},"]\n",[288,2599,2600],{"class":290,"line":321},[288,2601,372],{"class":304},[288,2603,2604],{"class":290,"line":343},[288,2605,2606],{"class":304},"}\n",[23,2608,2610],{"id":2609},"bonus","Bonus",[11,2612,2613,2614,2617],{},"You may also be interested in adding a ",[56,2615,2616],{},"sitemap.xml"," to your website. This can be done in almost an identical fashion!",[11,2619,2620],{},"Install the dependency:",[49,2622,2624],{"className":1989,"code":2623,"language":1991,"meta":58,"style":58},"npm i -D sitemap\n",[56,2625,2626],{"__ignoreMap":58},[288,2627,2628,2630,2632,2634],{"class":290,"line":291},[288,2629,1998],{"class":330},[288,2631,2001],{"class":311},[288,2633,2004],{"class":527},[288,2635,2636],{"class":311}," sitemap\n",[11,2638,2639,2640,2406],{},"Create a route at ",[56,2641,2642],{},"server/routes/sitemap.xml.ts",[49,2644,2646],{"className":2037,"code":2645,"language":2039,"meta":58,"style":58},"import { serverQueryContent } from '#content/server';\nimport { SitemapStream, streamToPromise } from 'sitemap';\n\nexport default defineEventHandler(async (event) => {\n    const articles = await serverQueryContent(event).find();\n\n    const sitemap = new SitemapStream({ hostname: 'https://my-website.com/' });\n\n    // Add non nuxt content endpoints here\n    sitemap.write({ url: '/' });\n    sitemap.write({ url: '/blog' });\n\n    // Dynamically generate routes for Nuxt markdown content\n    articles.forEach((article) => sitemap.write({ url: article._path, changefreq: 'monthly' }));\n    sitemap.end();\n\n    return (await streamToPromise(sitemap));\n});\n",[56,2647,2648,2660,2674,2678,2700,2718,2722,2745,2749,2754,2770,2783,2787,2792,2820,2829,2833,2848],{"__ignoreMap":58},[288,2649,2650,2652,2654,2656,2658],{"class":290,"line":291},[288,2651,301],{"class":300},[288,2653,2048],{"class":304},[288,2655,308],{"class":300},[288,2657,2053],{"class":311},[288,2659,678],{"class":304},[288,2661,2662,2664,2667,2669,2672],{"class":290,"line":144},[288,2663,301],{"class":300},[288,2665,2666],{"class":304}," { SitemapStream, streamToPromise } ",[288,2668,308],{"class":300},[288,2670,2671],{"class":311}," 'sitemap'",[288,2673,678],{"class":304},[288,2675,2676],{"class":290,"line":315},[288,2677,318],{"emptyLinePlaceholder":161},[288,2679,2680,2682,2684,2686,2688,2690,2692,2694,2696,2698],{"class":290,"line":321},[288,2681,324],{"class":300},[288,2683,327],{"class":300},[288,2685,2111],{"class":330},[288,2687,604],{"class":304},[288,2689,2116],{"class":300},[288,2691,573],{"class":304},[288,2693,2121],{"class":576},[288,2695,580],{"class":304},[288,2697,337],{"class":300},[288,2699,340],{"class":304},[288,2701,2702,2704,2706,2708,2710,2712,2714,2716],{"class":290,"line":343},[288,2703,2136],{"class":300},[288,2705,2342],{"class":527},[288,2707,570],{"class":300},[288,2709,2347],{"class":300},[288,2711,2350],{"class":330},[288,2713,2353],{"class":304},[288,2715,2356],{"class":330},[288,2717,868],{"class":304},[288,2719,2720],{"class":290,"line":351},[288,2721,318],{"emptyLinePlaceholder":161},[288,2723,2724,2726,2729,2731,2733,2736,2739,2742],{"class":290,"line":357},[288,2725,2136],{"class":300},[288,2727,2728],{"class":527}," sitemap",[288,2730,570],{"class":300},[288,2732,2144],{"class":300},[288,2734,2735],{"class":330}," SitemapStream",[288,2737,2738],{"class":304},"({ hostname: ",[288,2740,2741],{"class":311},"'https://my-website.com/'",[288,2743,2744],{"class":304}," });\n",[288,2746,2747],{"class":290,"line":363},[288,2748,318],{"emptyLinePlaceholder":161},[288,2750,2751],{"class":290,"line":369},[288,2752,2753],{"class":294},"    // Add non nuxt content endpoints here\n",[288,2755,2756,2759,2762,2765,2768],{"class":290,"line":375},[288,2757,2758],{"class":304},"    sitemap.",[288,2760,2761],{"class":330},"write",[288,2763,2764],{"class":304},"({ url: ",[288,2766,2767],{"class":311},"'/'",[288,2769,2744],{"class":304},[288,2771,2772,2774,2776,2778,2781],{"class":290,"line":549},[288,2773,2758],{"class":304},[288,2775,2761],{"class":330},[288,2777,2764],{"class":304},[288,2779,2780],{"class":311},"'/blog'",[288,2782,2744],{"class":304},[288,2784,2785],{"class":290,"line":561},[288,2786,318],{"emptyLinePlaceholder":161},[288,2788,2789],{"class":290,"line":587},[288,2790,2791],{"class":294},"    // Dynamically generate routes for Nuxt markdown content\n",[288,2793,2794,2796,2798,2800,2802,2804,2806,2809,2811,2814,2817],{"class":290,"line":612},[288,2795,2367],{"class":304},[288,2797,2370],{"class":330},[288,2799,2373],{"class":304},[288,2801,2376],{"class":576},[288,2803,580],{"class":304},[288,2805,337],{"class":300},[288,2807,2808],{"class":304}," sitemap.",[288,2810,2761],{"class":330},[288,2812,2813],{"class":304},"({ url: article._path, changefreq: ",[288,2815,2816],{"class":311},"'monthly'",[288,2818,2819],{"class":304}," }));\n",[288,2821,2822,2824,2827],{"class":290,"line":617},[288,2823,2758],{"class":304},[288,2825,2826],{"class":330},"end",[288,2828,868],{"class":304},[288,2830,2831],{"class":290,"line":630},[288,2832,318],{"emptyLinePlaceholder":161},[288,2834,2835,2837,2839,2842,2845],{"class":290,"line":643},[288,2836,2533],{"class":300},[288,2838,573],{"class":304},[288,2840,2841],{"class":300},"await",[288,2843,2844],{"class":330}," streamToPromise",[288,2846,2847],{"class":304},"(sitemap));\n",[288,2849,2850],{"class":290,"line":648},[288,2851,992],{"class":304},[11,2853,2854,2855,2857,2858,2406],{},"And add the ",[56,2856,2559],{}," entry in your ",[56,2859,2563],{},[49,2861,2863],{"className":2037,"code":2862,"language":2039,"meta":58,"style":58},"nitro: {\n  prerender: {\n    routes: ['/sitemap.xml', '/atom']\n  }\n}\n",[56,2864,2865,2871,2877,2892,2896],{"__ignoreMap":58},[288,2866,2867,2869],{"class":290,"line":291},[288,2868,2555],{"class":330},[288,2870,2576],{"class":304},[288,2872,2873,2875],{"class":290,"line":144},[288,2874,2581],{"class":330},[288,2876,2576],{"class":304},[288,2878,2879,2881,2883,2886,2888,2890],{"class":290,"line":315},[288,2880,2588],{"class":330},[288,2882,2591],{"class":304},[288,2884,2885],{"class":311},"'/sitemap.xml'",[288,2887,767],{"class":304},[288,2889,2594],{"class":311},[288,2891,2597],{"class":304},[288,2893,2894],{"class":290,"line":321},[288,2895,372],{"class":304},[288,2897,2898],{"class":290,"line":343},[288,2899,2606],{"class":304},[1006,2901,2902],{},"html pre.shiki code .svObZ, html code.shiki .svObZ{--shiki-default:#B392F0}html pre.shiki code .sU2Wk, html code.shiki .sU2Wk{--shiki-default:#9ECBFF}html pre.shiki code .sDLfK, html code.shiki .sDLfK{--shiki-default:#79B8FF}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html pre.shiki code .snl16, html code.shiki .snl16{--shiki-default:#F97583}html pre.shiki code .s95oV, html code.shiki .s95oV{--shiki-default:#E1E4E8}html pre.shiki code .s9osk, html code.shiki .s9osk{--shiki-default:#FFAB70}html pre.shiki code .sAwPA, html code.shiki .sAwPA{--shiki-default:#6A737D}",{"title":58,"searchDepth":144,"depth":144,"links":2904},[2905,2906,2907],{"id":1363,"depth":144,"text":1364},{"id":1976,"depth":144,"text":1977},{"id":2609,"depth":144,"text":2610},[232],"2024-01-06T00:00:00.000Z","If you are a user of Nuxt Content and you wish to configure an RSS feed for your website, it's a surprisingly straight forward process! In this article, we will walk through the code changes required to host an RSS feed for both a statically generated, and Universal Nuxt application.",{"draft":1322,"cover_image":2912,"excerpt":2913},"/images/nuxt-content-rss-feed.jpg",{"type":8,"value":2914},[2915],[11,2916,1950,2917,1956],{},[17,2918,1955],{"href":1953,"rel":2919},[21],"/blog/nuxt-content-rss-feed",{"title":1945,"description":2910},"blog/nuxt-content-rss-feed",[1031,2924],"rss","BxAYRP7jxcLQd5IVitLxA67xMYTahrDsLDCBkNZr4XU",{"id":2927,"title":2928,"body":2929,"categories":3541,"date":3542,"description":3543,"extension":154,"img":155,"meta":3544,"navigation":161,"path":3550,"seo":3551,"stem":3552,"tags":3553,"__hash__":3556},"content/blog/fennel-initial-exploration.md","Impressions of Fennel with Hammerspoon",{"type":8,"value":2930,"toc":3535},[2931,2934,2954,2958,2967,2971,2988,3008,3015,3030,3147,3151,3168,3215,3253,3260,3431,3502,3509,3513,3516,3525,3532],[11,2932,2933],{},"A while back I read an introductory book on Lisp programming titled, \"The Little\nSchemer\". This book opened my mind to new (to me) programming paradigms, and left me\nwith a strong desire to find a way to incorporate Lisp programming into my every day\nlife. It took some time, but I believe I've found what I've been looking for: Fennel.",[11,2935,2936,2937,2942,2943,2948,2949,1360],{},"The ",[17,2938,2941],{"href":2939,"rel":2940},"https://fennel-lang.org/",[21],"Fennel"," programming language is a dialect of Lisp that boasts compatibility with\nLua, and it just so happens that two of my favorite applications are configured with\nexactly that language: ",[17,2944,2947],{"href":2945,"rel":2946},"https://www.hammerspoon.org/",[21],"Hammerspoon",", and ",[17,2950,2953],{"href":2951,"rel":2952},"https://neovim.io/",[21],"Neovim",[23,2955,2957],{"id":2956},"initial-observations","Initial Observations",[11,2959,2960,2961,2966],{},"To initially explore Fennel, I wanted to start small. My Hammerspoon configuration\nconsists of 7 ",[17,2962,2965],{"href":2963,"rel":2964},"https://github.com/cmpadden/dotfiles/tree/795749fa17e1310bb001bb7deaa22be8689f0027/hammerspoon/.hammerspoon/modules",[21],"modules"," that I use for operations such as: launching applications,\nmanaging windows, keeping my computer from going to sleep, and general operating system\nautomation. So the plan is to translate these modules into Fennel, while maintaining\nwithout breaking the existing functionality. However, at this point, I wasn't even sure\nhow to embed Fennel into my project...",[23,2968,2970],{"id":2969},"integrating-fennel-with-hammerspoon","Integrating Fennel with Hammerspoon",[11,2972,2973,2974,2979,2980,2983,2984,2987],{},"While official documentation exists describing how to ",[17,2975,2978],{"href":2976,"rel":2977},"https://fennel-lang.org/setup#embedding-fennel",[21],"embed fennel"," into your\nproject; it didn't provide me with enough clarity to know my next steps on integrating\nit with Hammerspoon. I found a few resources online demonstrating how to extend the\n",[56,2981,2982],{},"package.path"," and ",[56,2985,2986],{},"package.cpath"," properties in Lua, but I was unable to get this to\nwork.",[194,2989,2990,2996,3002],{},[197,2991,2992],{},[17,2993,2994],{"href":2994,"rel":2995},"https://blog.exupero.org/hammerspoon-with-fennel/",[21],[197,2997,2998],{},[17,2999,3000],{"href":3000,"rel":3001},"https://github.com/Hammerspoon/hammerspoon/issues/2377#issuecomment-636331435",[21],[197,3003,3004],{},[17,3005,3006],{"href":3006,"rel":3007},"https://github.com/agzam/spacehammer/blob/master/init.lua",[21],[11,3009,3010,3011,3014],{},"Ultimately, I opted to include the ",[56,3012,3013],{},"fennel.lua"," file to my Hammerspoon configuration,\nand while not ideal, it does make the configuration nicely self-contained. I'll leave it\nas a future task to include the module installed with LuaRocks.",[11,3016,3017,3018,3021,3022,3025,3026,3029],{},"With Fennel now included in my Hammerspoon configuration, all I need to do is configure\nthe ",[56,3019,3020],{},"fennel.path"," to point to the ",[56,3023,3024],{},"*.fnl"," files in the ",[56,3027,3028],{},".hammerspoon/"," directory, and\nttranslating these modules can begin!",[49,3031,3035],{"className":3032,"code":3033,"language":3034,"meta":58,"style":58},"language-lua shiki shiki-themes github-dark","-- init.lua\n\nlocal fennel = require('fennel')\n\nfennel.path = package.path .. \";\" .. os.getenv(\"HOME\") .. \"/.hammerspoon/?.fnl\"\n\ntable.insert(package.loaders or package.searchers, fennel.searcher)\n\nrequire 'main'\n","lua",[56,3036,3037,3042,3046,3067,3071,3107,3111,3135,3139],{"__ignoreMap":58},[288,3038,3039],{"class":290,"line":291},[288,3040,3041],{"class":294},"-- init.lua\n",[288,3043,3044],{"class":290,"line":144},[288,3045,318],{"emptyLinePlaceholder":161},[288,3047,3048,3051,3054,3056,3059,3061,3064],{"class":290,"line":315},[288,3049,3050],{"class":300},"local",[288,3052,3053],{"class":304}," fennel ",[288,3055,461],{"class":300},[288,3057,3058],{"class":527}," require",[288,3060,604],{"class":304},[288,3062,3063],{"class":311},"'fennel'",[288,3065,3066],{"class":304},")\n",[288,3068,3069],{"class":290,"line":321},[288,3070,318],{"emptyLinePlaceholder":161},[288,3072,3073,3076,3078,3080,3083,3086,3089,3092,3095,3097,3100,3102,3104],{"class":290,"line":343},[288,3074,3075],{"class":304},"fennel.",[288,3077,396],{"class":330},[288,3079,570],{"class":300},[288,3081,3082],{"class":527}," package.path",[288,3084,3085],{"class":300}," ..",[288,3087,3088],{"class":311}," \";\" ",[288,3090,3091],{"class":300},"..",[288,3093,3094],{"class":527}," os.getenv",[288,3096,604],{"class":304},[288,3098,3099],{"class":311},"\"HOME\"",[288,3101,580],{"class":304},[288,3103,3091],{"class":300},[288,3105,3106],{"class":311}," \"/.hammerspoon/?.fnl\"\n",[288,3108,3109],{"class":290,"line":351},[288,3110,318],{"emptyLinePlaceholder":161},[288,3112,3113,3116,3118,3121,3124,3127,3130,3133],{"class":290,"line":357},[288,3114,3115],{"class":527},"table.insert",[288,3117,604],{"class":304},[288,3119,3120],{"class":527},"package.loaders",[288,3122,3123],{"class":300}," or",[288,3125,3126],{"class":527}," package.searchers",[288,3128,3129],{"class":304},", fennel.",[288,3131,3132],{"class":330},"searcher",[288,3134,3066],{"class":304},[288,3136,3137],{"class":290,"line":363},[288,3138,318],{"emptyLinePlaceholder":161},[288,3140,3141,3144],{"class":290,"line":369},[288,3142,3143],{"class":527},"require",[288,3145,3146],{"class":311}," 'main'\n",[23,3148,3150],{"id":3149},"translating-lua-to-fennel","Translating Lua to Fennel",[11,3152,3153,3154,3159,3160,3163,3164,3167],{},"As a Fennel novice, I was happy to see that the Fennel project provides an online\ncross-compiler for Lua and Fennel called ",[17,3155,3158],{"href":3156,"rel":3157},"https://fennel-lang.org/see",[21],"anti-fennel",", and while it can generate some\nstrange-looking Fennel code, it was an extremely useful tool for me to get\nup-and-running right away. For example, by pasting the simple ",[56,3161,3162],{},"sleep"," function\nfrom the ",[56,3165,3166],{},"helpers"," module into the compiler:",[49,3169,3171],{"className":3032,"code":3170,"language":3034,"meta":58,"style":58},"function sleep(ms)\n    os.execute(\"sleep \" .. tonumber(ms) / 1000)\nend\n",[56,3172,3173,3184,3210],{"__ignoreMap":58},[288,3174,3175,3178,3181],{"class":290,"line":291},[288,3176,3177],{"class":300},"function",[288,3179,3180],{"class":330}," sleep",[288,3182,3183],{"class":304},"(ms)\n",[288,3185,3186,3189,3191,3194,3196,3199,3202,3205,3208],{"class":290,"line":144},[288,3187,3188],{"class":527},"    os.execute",[288,3190,604],{"class":304},[288,3192,3193],{"class":311},"\"sleep \" ",[288,3195,3091],{"class":300},[288,3197,3198],{"class":527}," tonumber",[288,3200,3201],{"class":304},"(ms) ",[288,3203,3204],{"class":300},"/",[288,3206,3207],{"class":527}," 1000",[288,3209,3066],{"class":304},[288,3211,3212],{"class":290,"line":315},[288,3213,3214],{"class":300},"end\n",[49,3216,3220],{"className":3217,"code":3218,"language":3219,"meta":58,"style":58},"language-lisp shiki shiki-themes github-dark","(fn sleep [ms]\n  (os.execute (.. \"sleep \" (/ (tonumber ms) 1000))))\n","lisp",[56,3221,3222,3232],{"__ignoreMap":58},[288,3223,3224,3227,3229],{"class":290,"line":291},[288,3225,3226],{"class":304},"(fn ",[288,3228,3162],{"class":527},[288,3230,3231],{"class":304}," [ms]\n",[288,3233,3234,3237,3240,3242,3244,3247,3250],{"class":290,"line":144},[288,3235,3236],{"class":304},"  (os.execute (.. ",[288,3238,3239],{"class":311},"\"sleep \"",[288,3241,573],{"class":304},[288,3243,3204],{"class":527},[288,3245,3246],{"class":304}," (tonumber ms) ",[288,3248,3249],{"class":527},"1000",[288,3251,3252],{"class":304},"))))\n",[11,3254,3255,3256,3259],{},"As another example, here is the output for my ",[217,3257,3258],{},"caffeine"," toggle:",[49,3261,3263],{"className":3032,"code":3262,"language":3034,"meta":58,"style":58},"hs.hotkey.bind(HYPER, \"0\", function()\n  hs.caffeinate.toggle(\"displayIdle\")\n  if hs.caffeinate.get(\"displayIdle\") then\n    helpers:show(\"Caffeine Enabled\", nil, helpers.styles.success, helpers.assets.check)\n  else\n    helpers:show(\"Caffeine Disabled\", nil, helpers.styles.error, helpers.assets.ban)\n  end\nend)\n",[56,3264,3265,3291,3311,3335,3378,3383,3420,3425],{"__ignoreMap":58},[288,3266,3267,3270,3273,3275,3278,3281,3284,3286,3288],{"class":290,"line":291},[288,3268,3269],{"class":304},"hs.",[288,3271,3272],{"class":330},"hotkey",[288,3274,1360],{"class":304},[288,3276,3277],{"class":527},"bind",[288,3279,3280],{"class":304},"(HYPER, ",[288,3282,3283],{"class":311},"\"0\"",[288,3285,767],{"class":304},[288,3287,3177],{"class":300},[288,3289,3290],{"class":304},"()\n",[288,3292,3293,3296,3299,3301,3304,3306,3309],{"class":290,"line":144},[288,3294,3295],{"class":304},"  hs.",[288,3297,3298],{"class":330},"caffeinate",[288,3300,1360],{"class":304},[288,3302,3303],{"class":527},"toggle",[288,3305,604],{"class":304},[288,3307,3308],{"class":311},"\"displayIdle\"",[288,3310,3066],{"class":304},[288,3312,3313,3316,3319,3321,3323,3326,3328,3330,3332],{"class":290,"line":315},[288,3314,3315],{"class":300},"  if",[288,3317,3318],{"class":304}," hs.",[288,3320,3298],{"class":330},[288,3322,1360],{"class":304},[288,3324,3325],{"class":527},"get",[288,3327,604],{"class":304},[288,3329,3308],{"class":311},[288,3331,580],{"class":304},[288,3333,3334],{"class":300},"then\n",[288,3336,3337,3340,3342,3345,3347,3350,3352,3355,3358,3361,3363,3366,3368,3371,3373,3376],{"class":290,"line":321},[288,3338,3339],{"class":330},"    helpers",[288,3341,2406],{"class":304},[288,3343,3344],{"class":527},"show",[288,3346,604],{"class":304},[288,3348,3349],{"class":311},"\"Caffeine Enabled\"",[288,3351,767],{"class":304},[288,3353,3354],{"class":527},"nil",[288,3356,3357],{"class":304},", helpers.",[288,3359,3360],{"class":330},"styles",[288,3362,1360],{"class":304},[288,3364,3365],{"class":330},"success",[288,3367,3357],{"class":304},[288,3369,3370],{"class":330},"assets",[288,3372,1360],{"class":304},[288,3374,3375],{"class":330},"check",[288,3377,3066],{"class":304},[288,3379,3380],{"class":290,"line":343},[288,3381,3382],{"class":300},"  else\n",[288,3384,3385,3387,3389,3391,3393,3396,3398,3400,3402,3404,3406,3409,3411,3413,3415,3418],{"class":290,"line":351},[288,3386,3339],{"class":330},[288,3388,2406],{"class":304},[288,3390,3344],{"class":527},[288,3392,604],{"class":304},[288,3394,3395],{"class":311},"\"Caffeine Disabled\"",[288,3397,767],{"class":304},[288,3399,3354],{"class":527},[288,3401,3357],{"class":304},[288,3403,3360],{"class":330},[288,3405,1360],{"class":304},[288,3407,3408],{"class":330},"error",[288,3410,3357],{"class":304},[288,3412,3370],{"class":330},[288,3414,1360],{"class":304},[288,3416,3417],{"class":330},"ban",[288,3419,3066],{"class":304},[288,3421,3422],{"class":290,"line":357},[288,3423,3424],{"class":300},"  end\n",[288,3426,3427,3429],{"class":290,"line":363},[288,3428,2826],{"class":300},[288,3430,3066],{"class":304},[49,3432,3434],{"className":3217,"code":3433,"language":3219,"meta":58,"style":58},"(hs.hotkey.bind HYPER :0\n  (fn [] (hs.caffeinate.toggle :displayIdle)\n    (if (hs.caffeinate.get :displayIdle)\n      (helpers:show \"Caffeine Enabled\" nil helpers.styles.success helpers.assets.check)\n      (helpers:show \"Caffeine Disabled\" nil helpers.styles.error helpers.assets.ban)))) \n",[56,3435,3436,3444,3454,3469,3487],{"__ignoreMap":58},[288,3437,3438,3441],{"class":290,"line":291},[288,3439,3440],{"class":304},"(hs.hotkey.bind HYPER ",[288,3442,3443],{"class":330},":0\n",[288,3445,3446,3449,3452],{"class":290,"line":144},[288,3447,3448],{"class":304},"  (fn [] (hs.caffeinate.toggle ",[288,3450,3451],{"class":330},":displayIdle",[288,3453,3066],{"class":304},[288,3455,3456,3459,3462,3465,3467],{"class":290,"line":315},[288,3457,3458],{"class":304},"    (",[288,3460,3461],{"class":300},"if",[288,3463,3464],{"class":304}," (hs.caffeinate.get ",[288,3466,3451],{"class":330},[288,3468,3066],{"class":304},[288,3470,3471,3474,3476,3479,3481,3484],{"class":290,"line":321},[288,3472,3473],{"class":304},"      (",[288,3475,3166],{"class":527},[288,3477,3478],{"class":304},":show ",[288,3480,3349],{"class":311},[288,3482,3483],{"class":527}," nil",[288,3485,3486],{"class":304}," helpers.styles.success helpers.assets.check)\n",[288,3488,3489,3491,3493,3495,3497,3499],{"class":290,"line":343},[288,3490,3473],{"class":304},[288,3492,3166],{"class":527},[288,3494,3478],{"class":304},[288,3496,3395],{"class":311},[288,3498,3483],{"class":527},[288,3500,3501],{"class":304}," helpers.styles.error helpers.assets.ban))))\n",[11,3503,3504,3505,3508],{},"This was especially helpful for more gnarly modules like the ",[56,3506,3507],{},"window"," module used for\nwindow management, and seeing the Lua and Fennel code side-by-side was a kick starter in\nlearning the language!",[23,3510,3512],{"id":3511},"next-steps","Next Steps",[11,3514,3515],{},"While my Fennel Hammerspoon configuration now works with parity to its Lua counterpart,\nI have not yet added new features or modules. I look forward to writing new Fennel code,\nand deepen my understanding of Lisp and the Fennel programming language.",[11,3517,3518,3519,3524],{},"Additionally, before beginning this endeavor, I was already aware of projects like\n",[17,3520,3523],{"href":3521,"rel":3522},"https://github.com/agzam/spacehammer",[21],"spacehammer","; a wildly impressive Hammerspoon configuration written in Fennel, but,\nI wanted to start small and learn the integration myself. However, with the basics out\nof the way, I hope to explore this project further, and seek lessons-learned for the\nconfiguration of my own.",[11,3526,3527,3528],{},"The full pull-request for translating my Lua Hammerspoon configuration to Fennel can be\nfound here: ",[17,3529,3530],{"href":3530,"rel":3531},"https://github.com/cmpadden/dotfiles/pull/19/files",[21],[1006,3533,3534],{},"html pre.shiki code .sAwPA, html code.shiki .sAwPA{--shiki-default:#6A737D}html pre.shiki code .snl16, html code.shiki .snl16{--shiki-default:#F97583}html pre.shiki code .s95oV, html code.shiki .s95oV{--shiki-default:#E1E4E8}html pre.shiki code .sDLfK, html code.shiki .sDLfK{--shiki-default:#79B8FF}html pre.shiki code .sU2Wk, html code.shiki .sU2Wk{--shiki-default:#9ECBFF}html pre.shiki code .svObZ, html code.shiki .svObZ{--shiki-default:#B392F0}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}",{"title":58,"searchDepth":144,"depth":144,"links":3536},[3537,3538,3539,3540],{"id":2956,"depth":144,"text":2957},{"id":2969,"depth":144,"text":2970},{"id":3149,"depth":144,"text":3150},{"id":3511,"depth":144,"text":3512},[3219],"2023-10-22T00:00:00.000Z","A while back I read an introductory book on Lisp programming titled, \"The Little\\nSchemer\". This book opened my mind to new (to me) programming paradigms, and left me\\nwith a strong desire to find a way to incorporate Lisp programming into my every day\\nlife. It took some time, but I believe I've found what I've been looking for: Fennel.",{"draft":1322,"cover_image":3545,"excerpt":3546},"/images/dall-e-fennel-hammer.jpeg",{"type":8,"value":3547},[3548],[11,3549,2933],{},"/blog/fennel-initial-exploration",{"title":2928,"description":2933},"blog/fennel-initial-exploration",[3219,3554,3555],"hammerspoon","fennel","jMjBjFRtP3rXJ3PfHT0giBHzh8-Vkdh6xVoegNc1RjM",{"id":3558,"title":3559,"body":3560,"categories":3941,"date":3943,"description":3944,"extension":154,"img":155,"meta":3945,"navigation":161,"path":3954,"seo":3955,"stem":3957,"tags":3958,"__hash__":3960},"content/blog/doctl.md","Exploring the Digital Ocean `doctl` Utility",{"type":8,"value":3561,"toc":3939},[3562,3573,3579,3617,3629,3650,3653,3696,3699,3754,3761,3791,3798,3817,3820,3892,3895,3912,3933,3936],[11,3563,3564,3565,3568,3569,3572],{},"I recently had the need to spool up a small ephemeral Linux instance, and wanted to try something new by exploring the Digital Ocean ",[56,3566,3567],{},"doctl"," command line utility.\nThis proved to be an ",[217,3570,3571],{},"extremely"," easy way to configure, create, connect, and destroy a Linux box, and I foresee myself using this service even more in the future.",[11,3574,3575,3576,1360],{},"To start things off, I had to install and setup authentication to Digital Ocean. Doing\nthis on my Mac machine, I opted to use ",[17,3577,1074],{"href":1072,"rel":3578},[21],[49,3580,3582],{"className":1078,"code":3581,"language":1080,"meta":58,"style":58},"# install `doctl`\nbrew install doctl\n\n# setup authentication\ndoctl auth init\n",[56,3583,3584,3589,3598,3602,3607],{"__ignoreMap":58},[288,3585,3586],{"class":290,"line":291},[288,3587,3588],{"class":294},"# install `doctl`\n",[288,3590,3591,3593,3595],{"class":290,"line":144},[288,3592,1472],{"class":330},[288,3594,1093],{"class":311},[288,3596,3597],{"class":311}," doctl\n",[288,3599,3600],{"class":290,"line":315},[288,3601,318],{"emptyLinePlaceholder":161},[288,3603,3604],{"class":290,"line":321},[288,3605,3606],{"class":294},"# setup authentication\n",[288,3608,3609,3611,3614],{"class":290,"line":343},[288,3610,3567],{"class":330},[288,3612,3613],{"class":311}," auth",[288,3615,3616],{"class":311}," init\n",[11,3618,3619,3620,3625,3626,1360],{},"While the online ",[17,3621,3624],{"href":3622,"rel":3623},"https://docs.digitalocean.com/reference/doctl/reference/compute/droplet/create/",[21],"documentation"," is fantastic, I instead found myself mostly referencing the outputs of ",[56,3627,3628],{},"--help",[49,3630,3632],{"className":1078,"code":3631,"language":1080,"meta":58,"style":58},"doctl compute droplet create --help\n",[56,3633,3634],{"__ignoreMap":58},[288,3635,3636,3638,3641,3644,3647],{"class":290,"line":291},[288,3637,3567],{"class":330},[288,3639,3640],{"class":311}," compute",[288,3642,3643],{"class":311}," droplet",[288,3645,3646],{"class":311}," create",[288,3648,3649],{"class":527}," --help\n",[11,3651,3652],{},"I had to find the image name of the version of Ubuntu I wanted to install:",[49,3654,3656],{"className":1078,"code":3655,"language":1080,"meta":58,"style":58},"doctl compute image list --public | grep ubuntu-22\n\n# 118857366    22.04 (LTS) x64    snapshot    Ubuntu    ubuntu-22-04-x64    true    7\n# 119383150    22.10 x64          snapshot    Ubuntu    ubuntu-22-10-x64    true    7\n",[56,3657,3658,3682,3686,3691],{"__ignoreMap":58},[288,3659,3660,3662,3664,3667,3670,3673,3676,3679],{"class":290,"line":291},[288,3661,3567],{"class":330},[288,3663,3640],{"class":311},[288,3665,3666],{"class":311}," image",[288,3668,3669],{"class":311}," list",[288,3671,3672],{"class":527}," --public",[288,3674,3675],{"class":300}," |",[288,3677,3678],{"class":330}," grep",[288,3680,3681],{"class":311}," ubuntu-22\n",[288,3683,3684],{"class":290,"line":144},[288,3685,318],{"emptyLinePlaceholder":161},[288,3687,3688],{"class":290,"line":315},[288,3689,3690],{"class":294},"# 118857366    22.04 (LTS) x64    snapshot    Ubuntu    ubuntu-22-04-x64    true    7\n",[288,3692,3693],{"class":290,"line":321},[288,3694,3695],{"class":294},"# 119383150    22.10 x64          snapshot    Ubuntu    ubuntu-22-10-x64    true    7\n",[11,3697,3698],{},"And also the slug of the compute size:",[49,3700,3702],{"className":1078,"code":3701,"language":1080,"meta":58,"style":58},"doctl compute size list\n\n# Slug                  Description    Memory    VCPUs    Disk    Price Monthly    Price Hourly\n# s-1vcpu-512mb-10gb    Basic          512       1        10      4.00             0.005950\n# s-1vcpu-1gb           Basic          1024      1        25      6.00             0.008930\n# s-1vcpu-1gb-amd       Basic AMD      1024      1        25      7.00             0.010420\n# s-1vcpu-1gb-intel     Basic Intel    1024      1        25      7.00             0.010420\n# s-1vcpu-2gb           Basic          2048      1        50      12.00            0.017860\n# s-1vcpu-2gb-amd       Basic AMD      2048      1        50      14.00            0.020830\n",[56,3703,3704,3715,3719,3724,3729,3734,3739,3744,3749],{"__ignoreMap":58},[288,3705,3706,3708,3710,3713],{"class":290,"line":291},[288,3707,3567],{"class":330},[288,3709,3640],{"class":311},[288,3711,3712],{"class":311}," size",[288,3714,1117],{"class":311},[288,3716,3717],{"class":290,"line":144},[288,3718,318],{"emptyLinePlaceholder":161},[288,3720,3721],{"class":290,"line":315},[288,3722,3723],{"class":294},"# Slug                  Description    Memory    VCPUs    Disk    Price Monthly    Price Hourly\n",[288,3725,3726],{"class":290,"line":321},[288,3727,3728],{"class":294},"# s-1vcpu-512mb-10gb    Basic          512       1        10      4.00             0.005950\n",[288,3730,3731],{"class":290,"line":343},[288,3732,3733],{"class":294},"# s-1vcpu-1gb           Basic          1024      1        25      6.00             0.008930\n",[288,3735,3736],{"class":290,"line":351},[288,3737,3738],{"class":294},"# s-1vcpu-1gb-amd       Basic AMD      1024      1        25      7.00             0.010420\n",[288,3740,3741],{"class":290,"line":357},[288,3742,3743],{"class":294},"# s-1vcpu-1gb-intel     Basic Intel    1024      1        25      7.00             0.010420\n",[288,3745,3746],{"class":290,"line":363},[288,3747,3748],{"class":294},"# s-1vcpu-2gb           Basic          2048      1        50      12.00            0.017860\n",[288,3750,3751],{"class":290,"line":369},[288,3752,3753],{"class":294},"# s-1vcpu-2gb-amd       Basic AMD      2048      1        50      14.00            0.020830\n",[11,3755,3756,3757,3760],{},"I've also configured a few SSH keys with Digital Ocean, and I can have the key (specified by ID) provisioned to the machine using the ",[56,3758,3759],{},"--ssh-keys"," flag.",[49,3762,3764],{"className":1078,"code":3763,"language":1080,"meta":58,"style":58},"doctl compute ssh-key list\n\n# ID      Name    FingerPrint\n# 1234    mini    \u003Credacted>\n",[56,3765,3766,3777,3781,3786],{"__ignoreMap":58},[288,3767,3768,3770,3772,3775],{"class":290,"line":291},[288,3769,3567],{"class":330},[288,3771,3640],{"class":311},[288,3773,3774],{"class":311}," ssh-key",[288,3776,1117],{"class":311},[288,3778,3779],{"class":290,"line":144},[288,3780,318],{"emptyLinePlaceholder":161},[288,3782,3783],{"class":290,"line":315},[288,3784,3785],{"class":294},"# ID      Name    FingerPrint\n",[288,3787,3788],{"class":290,"line":321},[288,3789,3790],{"class":294},"# 1234    mini    \u003Credacted>\n",[11,3792,3793,3794,3797],{},"Also, I wanted to install a few packages to the box upon creation, this can be done easily with the ",[56,3795,3796],{},"--user-data-file"," flag to run an initialization script.",[49,3799,3801],{"className":1078,"code":3800,"language":1080,"meta":58,"style":58},"echo 'apt install -y imagemagick zip' > bootstrap.sh\n",[56,3802,3803],{"__ignoreMap":58},[288,3804,3805,3808,3811,3814],{"class":290,"line":291},[288,3806,3807],{"class":527},"echo",[288,3809,3810],{"class":311}," 'apt install -y imagemagick zip'",[288,3812,3813],{"class":300}," >",[288,3815,3816],{"class":311}," bootstrap.sh\n",[11,3818,3819],{},"Putting it all together, here is the simple command for creating a small compute instance!",[49,3821,3823],{"className":1078,"code":3822,"language":1080,"meta":58,"style":58},"doctl compute droplet create \\\n    --image ubuntu-22-10-x64 \\\n    --size s-1vcpu-512mb-10gb \\\n    --region nyc1 \\\n    --ssh-keys 1234 \\\n    --user-data-file boostrap.sh \\\n    ephemeral\n",[56,3824,3825,3837,3847,3857,3867,3877,3887],{"__ignoreMap":58},[288,3826,3827,3829,3831,3833,3835],{"class":290,"line":291},[288,3828,3567],{"class":330},[288,3830,3640],{"class":311},[288,3832,3643],{"class":311},[288,3834,3646],{"class":311},[288,3836,1582],{"class":527},[288,3838,3839,3842,3845],{"class":290,"line":144},[288,3840,3841],{"class":527},"    --image",[288,3843,3844],{"class":311}," ubuntu-22-10-x64",[288,3846,1582],{"class":527},[288,3848,3849,3852,3855],{"class":290,"line":315},[288,3850,3851],{"class":527},"    --size",[288,3853,3854],{"class":311}," s-1vcpu-512mb-10gb",[288,3856,1582],{"class":527},[288,3858,3859,3862,3865],{"class":290,"line":321},[288,3860,3861],{"class":527},"    --region",[288,3863,3864],{"class":311}," nyc1",[288,3866,1582],{"class":527},[288,3868,3869,3872,3875],{"class":290,"line":343},[288,3870,3871],{"class":527},"    --ssh-keys",[288,3873,3874],{"class":527}," 1234",[288,3876,1582],{"class":527},[288,3878,3879,3882,3885],{"class":290,"line":351},[288,3880,3881],{"class":527},"    --user-data-file",[288,3883,3884],{"class":311}," boostrap.sh",[288,3886,1582],{"class":527},[288,3888,3889],{"class":290,"line":357},[288,3890,3891],{"class":311},"    ephemeral\n",[11,3893,3894],{},"Finally, I can connect, do my thing, and destroy the instance.",[49,3896,3898],{"className":1078,"code":3897,"language":1080,"meta":58,"style":58},"doctl compute ssh ephemeral\n",[56,3899,3900],{"__ignoreMap":58},[288,3901,3902,3904,3906,3909],{"class":290,"line":291},[288,3903,3567],{"class":330},[288,3905,3640],{"class":311},[288,3907,3908],{"class":311}," ssh",[288,3910,3911],{"class":311}," ephemeral\n",[49,3913,3915],{"className":1078,"code":3914,"language":1080,"meta":58,"style":58},"doctl compute droplet delete --force ephemeral\n",[56,3916,3917],{"__ignoreMap":58},[288,3918,3919,3921,3923,3925,3928,3931],{"class":290,"line":291},[288,3920,3567],{"class":330},[288,3922,3640],{"class":311},[288,3924,3643],{"class":311},[288,3926,3927],{"class":311}," delete",[288,3929,3930],{"class":527}," --force",[288,3932,3911],{"class":311},[11,3934,3935],{},"All-in-all, I was up and running in about 20 minutes. What a handy utility!",[1006,3937,3938],{},"html pre.shiki code .sAwPA, html code.shiki .sAwPA{--shiki-default:#6A737D}html pre.shiki code .svObZ, html code.shiki .svObZ{--shiki-default:#B392F0}html pre.shiki code .sU2Wk, html code.shiki .sU2Wk{--shiki-default:#9ECBFF}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html pre.shiki code .sDLfK, html code.shiki .sDLfK{--shiki-default:#79B8FF}html pre.shiki code .snl16, html code.shiki .snl16{--shiki-default:#F97583}",{"title":58,"searchDepth":144,"depth":144,"links":3940},[],[3942],"linux","2023-01-01T00:00:00.000Z","I recently had the need to spool up a small ephemeral Linux instance, and wanted to try something new by exploring the Digital Ocean doctl command line utility.\\nThis proved to be an extremely easy way to configure, create, connect, and destroy a Linux box, and I foresee myself using this service even more in the future.",{"excerpt":3946},{"type":8,"value":3947},[3948],[11,3949,3564,3950,3568,3952,3572],{},[56,3951,3567],{},[217,3953,3571],{},"/blog/doctl",{"title":3559,"description":3956},"I recently had the need to spool up a small ephemeral Linux instance, and wanted to try something new by exploring the Digital Ocean doctl command line utility.\nThis proved to be an extremely easy way to configure, create, connect, and destroy a Linux box, and I foresee myself using this service even more in the future.","blog/doctl",[3942,3959],"digital-ocean","aqH6rrmUP20x6T0pGJ7hhmKpBWch-vLXWtzrM1Fo8AI",{"id":3962,"title":3963,"body":3964,"categories":4026,"date":4028,"description":4029,"extension":154,"img":155,"meta":4030,"navigation":161,"path":4035,"seo":4036,"stem":4037,"tags":4038,"__hash__":4039},"content/blog/nuxt-v3-migration.md","This Website Has Been Migrated to Nuxt 3 🎉",{"type":8,"value":3965,"toc":4024},[3966,3969,3978,3985,3988,3991,4021],[11,3967,3968],{},"This website has been migrated to the latest version of the Nuxt web framework, and with it comes all of the exciting goodies that the Vue and Nuxt teams have been concocting over the past few years.\nNot to mention, all of the great plugins in the Vue ecosystem!",[11,3970,3971,3972,3977],{},"If you're curious what changes were required to make the migration, you can check out ",[17,3973,3976],{"href":3974,"rel":3975},"https://github.com/cmpadden/cmpadden.github.io/pull/3",[21],"pull request #3"," in the GitHub repository.",[11,3979,3980],{},[3981,3982],"img",{"alt":3983,"src":3984},"Screenshot of Nuxt Migration Pull Request","/images/nuxt-migration-pr.png",[11,3986,3987],{},"While the documentation for making this migration is great, there were many breaking changes, and the overall process was quite tedious.\nFor this reason, I opted to generate a new project entirely, and port existing code to this clean slate.\nI believe that this resulted in a project with a bit less cruft.",[11,3989,3990],{},"The most valuable resources for making these changes include:",[194,3992,3993,4000,4007,4014],{},[197,3994,3995],{},[17,3996,3999],{"href":3997,"rel":3998},"https://nuxt.com/docs/migration/overview",[21],"The Nuxt Migration Guide",[197,4001,4002],{},[17,4003,4006],{"href":4004,"rel":4005},"https://nuxt.com/docs/getting-started/introduction",[21],"The Nuxt Framework Guide",[197,4008,4009],{},[17,4010,4013],{"href":4011,"rel":4012},"https://tailwindcss.nuxt.dev/",[21],"Nuxt Tailwind Module Documentation",[197,4015,4016],{},[17,4017,4020],{"href":4018,"rel":4019},"https://content.nuxtjs.org/",[21],"Nuxt Content Module Documentation",[11,4022,4023],{},"Part of the delay for doing this upgrade was in waiting for module developers to support this major release.\nI'm super thankful for all of the hard work they've don, and I'm excited to explore all of the new features available!\nI just hope that the breaking changes in this release don't cause too much fracturing of the community, as it does feel like déjà vu of Python 2 and 3.",{"title":58,"searchDepth":144,"depth":144,"links":4025},[],[4027],"web","2022-12-31T00:00:00.000Z","This website has been migrated to the latest version of the Nuxt web framework, and with it comes all of the exciting goodies that the Vue and Nuxt teams have been concocting over the past few years.\\nNot to mention, all of the great plugins in the Vue ecosystem!",{"excerpt":4031},{"type":8,"value":4032},[4033],[11,4034,3968],{},"/blog/nuxt-v3-migration",{"title":3963,"description":3968},"blog/nuxt-v3-migration",[1031],"GchFZ97LF4i_zk_H7gRsztYCCNu45601Ekaz6U6WhnU",{"id":4041,"title":4042,"body":4043,"categories":4140,"date":4142,"description":4047,"extension":154,"img":155,"meta":4143,"navigation":161,"path":4148,"seo":4149,"stem":4150,"tags":4151,"__hash__":4154},"content/blog/migrate-truenas-from-core-to-scale.md","Migrate to TrueNAS Scale from TrueNAS Core",{"type":8,"value":4044,"toc":4138},[4045,4048,4055,4127,4130],[11,4046,4047],{},"TrueNAS Scale offers a variety of interesting features that are not supported in its TrueNAS Core counterpart. Most notably, because the base operating system is Debian Linux, opposed to FreeBSD, there is native support for Linux containers via Docker, and Kubernetes Pods! This post walks through the steps required to upgrade from TrueNAS Core to TrueNAS Scale.",[11,4049,4050,4051,4054],{},"Thankfully, the upgrade procedure to migrate from TrueNAS Core to TrueNAS Scale is relatively straight forward. All it requires is to create a bootable USB of the TrueNAS Scale image, boot the USB, and select ",[217,4052,4053],{},"Install/Upgrade"," in the installation wizard. But for the sake of being thorough, you can find instructions on how to backup system configurations and install the OS below.",[4056,4057,4058,4083,4099,4102,4115,4118],"ol",{},[197,4059,4060,4061],{},"Make a backup of your system’s configuration\n",[4056,4062,4063,4069],{},[197,4064,4065,4066],{},"Navigate to ",[56,4067,4068],{},"System > General",[197,4070,4071,4072,4075,4076,4079,4080],{},"Click ",[56,4073,4074],{},"Save Config",", check the ",[217,4077,4078],{},"Export Secret Seed"," box, and click ",[56,4081,4082],{},"Save",[197,4084,4085,4086],{},"Export dataset keys for the encrypted pools\n",[4056,4087,4088,4093],{},[197,4089,4065,4090],{},[56,4091,4092],{},"Storage > Pools",[197,4094,4095,4096],{},"Click the cog icon, and select ",[56,4097,4098],{},"Export Dataset Keys",[197,4100,4101],{},"Insert the TrueNAS Core bootable USB into the NAS",[197,4103,4104,4105,2983,4108,4111,4112],{},"From the Supermicro IPMI interface select ",[217,4106,4107],{},"Remote Control",[217,4109,4110],{},"iKVM/HTML5"," and select ",[217,4113,4114],{},"Reboot",[197,4116,4117],{},"Select the bootable USB as the boot device",[197,4119,4120,4121,4123,4124],{},"From the TrueNAS installation wizard, select ",[217,4122,4053],{},", select the drive that contains the TrueNAS installation, and select ",[217,4125,4126],{},"Upgrade Install",[11,4128,4129],{},"Reboot the device, and voila — you should be up-and-running! Give the system a quick rundown to validate that your settings and pools have transferred correctly, and then enjoy all the container goodness!",[11,4131,4132,4133,1360],{},"For a breakdown of the differences between TrueNAS Core, Enterprise, and Scale, you can reference ",[17,4134,4137],{"href":4135,"rel":4136},"https://www.truenas.com/help-me-choose/",[21],"this table",{"title":58,"searchDepth":144,"depth":144,"links":4139},[],[4141],"homelab","2021-12-28T00:00:00.000Z",{"excerpt":4144},{"type":8,"value":4145},[4146],[11,4147,4047],{},"/blog/migrate-truenas-from-core-to-scale",{"title":4042,"description":4047},"blog/migrate-truenas-from-core-to-scale",[4141,4152,4153],"supermicro","truenas","GanaRPCb7qHm5I6aZRMZQDMqDdt5OBe8mdAtRsztoN0",{"id":4156,"title":4157,"body":4158,"categories":4257,"date":4258,"description":4259,"extension":154,"img":155,"meta":4260,"navigation":161,"path":4265,"seo":4266,"stem":4267,"tags":4268,"__hash__":4269},"content/blog/reset-ipmi-password-from-host-os.md","Reset IPMI Credentials from the Host OS",{"type":8,"value":4159,"toc":4255},[4160,4163,4174,4181,4184,4190,4201,4207,4210,4213,4216,4222],[11,4161,4162],{},"If you ever find yourself locked out of the Intelligent Platform Management Interface (IPMI) of a server, these\ninstructions will guide your through the process of resetting the credentials to their default values from the host\noperating system.",[11,4164,4165,4166,4169,4170,4173],{},"If you are using an operating system like TrueNAS -- good news! It's possible to reset the IPMI password directly from\nthe web interface. This is done by navigating to ",[56,4167,4168],{},"Network > IPMI",", and simply entering a new value in the ",[217,4171,4172],{},"IPMI\nPassword Reset"," field.",[11,4175,4176,4177,4180],{},"If you are using some other OS that doesn't have this feature, you can achieve similar results by using the ",[56,4178,4179],{},"ipmitool","\ncommand-line utility.",[11,4182,4183],{},"First, you'll want to determine the user ID associated with the user for whom you'd like to reset the password.",[49,4185,4188],{"className":4186,"code":4187,"language":54},[52],"# ipmitool user list\nID  Name             Callin  Link Auth  IPMI Msg   Channel Priv Limit\n1                    true    false      false      Unknown (0x00)\n2   ADMIN            true    false      false      Unknown (0x00)\n",[56,4189,4187],{"__ignoreMap":58},[11,4191,4192,4193,4196,4197,4200],{},"In this case, we will be resetting the password for ",[217,4194,4195],{},"ADMIN"," who has a user ID of ",[217,4198,4199],{},"2",". Then we'll assign the new\npassword like so:",[49,4202,4205],{"className":4203,"code":4204,"language":54},[52],"# ipmitool user set password 2 \u003Cpassword>\n",[56,4206,4204],{"__ignoreMap":58},[11,4208,4209],{},"And you should be good to go!",[11,4211,4212],{},"...",[11,4214,4215],{},"Alternatively, if you'd like to factory reset the baseboard management controller (BMC), which will reset the IPMI\ncredentials to their default value, you can issue the following command.",[49,4217,4220],{"className":4218,"code":4219,"language":54},[52],"# ipmitool raw 0x3c 0x40\n",[56,4221,4219],{"__ignoreMap":58},[11,4223,4224,4225,4228,4229,4232,4233,4228,4236,4239,4240,2161,4245,4248,4249,4254],{},"Where ",[56,4226,4227],{},"0x3c"," is the ",[56,4230,4231],{},"\u003Cnetfn>"," argument, a.k.a. the network function code that defines the functional routing for\nmessages, and ",[56,4234,4235],{},"0x40",[56,4237,4238],{},"\u003Ccmd>",". According to section 5.1 of the ",[17,4241,4244],{"href":4242,"rel":4243},"https://www.intel.com/content/dam/www/public/us/en/documents/product-briefs/ipmi-second-gen-interface-spec-v2-rev1-1.pdf",[21],"IPMI interface\nspecification",[217,4246,4247],{},"netfn"," codes ranging from 0x30 to 0x3F are reserved for vendor specific functions. I searched around for some\nSupermicro references on these vendor specific network functions without much luck other than various ",[17,4250,4253],{"href":4251,"rel":4252},"https://www.supermicro.com/support/faqs/faq.cfm?faq=15448",[21],"support\nresponses"," on how to reset a device. Bummer!",{"title":58,"searchDepth":144,"depth":144,"links":4256},[],[4141],"2021-12-27T00:00:00.000Z","If you ever find yourself locked out of the Intelligent Platform Management Interface (IPMI) of a server, these\\ninstructions will guide your through the process of resetting the credentials to their default values from the host\\noperating system.",{"excerpt":4261},{"type":8,"value":4262},[4263],[11,4264,4162],{},"/blog/reset-ipmi-password-from-host-os",{"title":4157,"description":4162},"blog/reset-ipmi-password-from-host-os",[4141,4152,4153],"UYg9rg_o0BXP--Ur58vmmHbYwY1IC7a1p7ppAIQ0_qg",{"id":4271,"title":4272,"body":4273,"categories":4611,"date":4612,"description":4613,"extension":154,"img":155,"meta":4614,"navigation":161,"path":4621,"seo":4622,"stem":4624,"tags":4625,"__hash__":4626},"content/blog/quick-tip-rerunning-bash-commands.md","Tip: Re-running Bash Commands",{"type":8,"value":4274,"toc":4609},[4275,4282,4328,4341,4389,4392,4406,4468,4482,4514,4520,4542,4551,4575,4588,4590,4606],[11,4276,4277,4278,4281],{},"Do you ever find yourself having to re-run a Bash command? I often find this\nhappening to myself when I neglect to use ",[56,4279,4280],{},"sudo"," for a command that requires\nroot privileges.",[49,4283,4285],{"className":1395,"code":4284,"language":1397,"meta":58,"style":58},"$ pacman -Syu\nerror: you cannot perform this operation unless you are root.\n",[56,4286,4287,4297],{"__ignoreMap":58},[288,4288,4289,4291,4294],{"class":290,"line":291},[288,4290,1087],{"class":330},[288,4292,4293],{"class":311}," pacman",[288,4295,4296],{"class":527}," -Syu\n",[288,4298,4299,4302,4305,4308,4311,4314,4317,4320,4322,4325],{"class":290,"line":144},[288,4300,4301],{"class":330},"error:",[288,4303,4304],{"class":311}," you",[288,4306,4307],{"class":311}," cannot",[288,4309,4310],{"class":311}," perform",[288,4312,4313],{"class":311}," this",[288,4315,4316],{"class":311}," operation",[288,4318,4319],{"class":311}," unless",[288,4321,4304],{"class":311},[288,4323,4324],{"class":311}," are",[288,4326,4327],{"class":311}," root.\n",[11,4329,4330,4331,4334,4335,4337,4338,4340],{},"Well, I have good news for you -- you can easily re-issue a command with the\n",[56,4332,4333],{},"!!"," designator! Simply type ",[56,4336,4280],{}," followed by ",[56,4339,4333],{}," and you're good to go.",[49,4342,4344],{"className":1395,"code":4343,"language":1397,"meta":58,"style":58},"$ sudo !!\nsudo pacman -Syu\n[sudo] password for colton:\n:: Synchronizing package databases...\n",[56,4345,4346,4356,4364,4375],{"__ignoreMap":58},[288,4347,4348,4350,4353],{"class":290,"line":291},[288,4349,1087],{"class":330},[288,4351,4352],{"class":311}," sudo",[288,4354,4355],{"class":311}," !!\n",[288,4357,4358,4360,4362],{"class":290,"line":144},[288,4359,4280],{"class":330},[288,4361,4293],{"class":311},[288,4363,4296],{"class":527},[288,4365,4366,4369,4372],{"class":290,"line":315},[288,4367,4368],{"class":304},"[sudo] password ",[288,4370,4371],{"class":300},"for",[288,4373,4374],{"class":304}," colton:\n",[288,4376,4377,4380,4383,4386],{"class":290,"line":321},[288,4378,4379],{"class":527},"::",[288,4381,4382],{"class":311}," Synchronizing",[288,4384,4385],{"class":311}," package",[288,4387,4388],{"class":311}," databases...\n",[11,4390,4391],{},"--",[11,4393,4394,4395,4397,4398,4401,4402,4405],{},"Commands that are prefixed with a bang, ",[56,4396,119],{},", are considered ",[217,4399,4400],{},"Event\nDesignators,"," and are references to your command-line history. You can take a\nlook at your history with the ",[56,4403,4404],{},"history"," command.",[49,4407,4409],{"className":1395,"code":4408,"language":1397,"meta":58,"style":58},"$ history\n 1021  touch hello_world.txt\n 1022  ls\n 1023  echo \"Here we go again!\"\n 1024  find . -name *.py\n",[56,4410,4411,4418,4429,4437,4448],{"__ignoreMap":58},[288,4412,4413,4415],{"class":290,"line":291},[288,4414,1087],{"class":330},[288,4416,4417],{"class":311}," history\n",[288,4419,4420,4423,4426],{"class":290,"line":144},[288,4421,4422],{"class":330}," 1021",[288,4424,4425],{"class":311},"  touch",[288,4427,4428],{"class":311}," hello_world.txt\n",[288,4430,4431,4434],{"class":290,"line":315},[288,4432,4433],{"class":330}," 1022",[288,4435,4436],{"class":311},"  ls\n",[288,4438,4439,4442,4445],{"class":290,"line":321},[288,4440,4441],{"class":330}," 1023",[288,4443,4444],{"class":311},"  echo",[288,4446,4447],{"class":311}," \"Here we go again!\"\n",[288,4449,4450,4453,4456,4459,4462,4465],{"class":290,"line":343},[288,4451,4452],{"class":330}," 1024",[288,4454,4455],{"class":311},"  find",[288,4457,4458],{"class":311}," .",[288,4460,4461],{"class":527}," -name",[288,4463,4464],{"class":527}," *",[288,4466,4467],{"class":311},".py\n",[11,4469,4470,4471,4473,4474,4477,4478,4481],{},"There are many ways to use ",[56,4472,119],{}," in your shell. For example, if you wanted to\nre-issue a specific command in your history, you could use ",[56,4475,4476],{},"!n"," where ",[56,4479,4480],{},"n"," is\nthe number next to the command in your history.",[49,4483,4485],{"className":1395,"code":4484,"language":1397,"meta":58,"style":58},"$ !1023\necho \"Here we go again!\"\nHere we go again!\n",[56,4486,4487,4494,4500],{"__ignoreMap":58},[288,4488,4489,4491],{"class":290,"line":291},[288,4490,1087],{"class":330},[288,4492,4493],{"class":311}," !1023\n",[288,4495,4496,4498],{"class":290,"line":144},[288,4497,3807],{"class":527},[288,4499,4447],{"class":311},[288,4501,4502,4505,4508,4511],{"class":290,"line":315},[288,4503,4504],{"class":330},"Here",[288,4506,4507],{"class":311}," we",[288,4509,4510],{"class":311}," go",[288,4512,4513],{"class":311}," again!\n",[11,4515,4516,4517,1360],{},"Or... if you wanted to run the command you issued 4-commands ago, you can use\n",[56,4518,4519],{},"!-4",[49,4521,4523],{"className":1395,"code":4522,"language":1397,"meta":58,"style":58},"$ !-4\nls\nhello_world.txt\n",[56,4524,4525,4532,4537],{"__ignoreMap":58},[288,4526,4527,4529],{"class":290,"line":291},[288,4528,1087],{"class":330},[288,4530,4531],{"class":311}," !-4\n",[288,4533,4534],{"class":290,"line":144},[288,4535,4536],{"class":330},"ls\n",[288,4538,4539],{"class":290,"line":315},[288,4540,4541],{"class":330},"hello_world.txt\n",[11,4543,4544,4545,4547,4548,1360],{},"Or... if you wanted to run the last command that started with the string\n",[217,4546,2356],{},", you can use ",[56,4549,4550],{},"!find",[49,4552,4554],{"className":1395,"code":4553,"language":1397,"meta":58,"style":58},"$ !find\nfind . -name *.py\n",[56,4555,4556,4563],{"__ignoreMap":58},[288,4557,4558,4560],{"class":290,"line":291},[288,4559,1087],{"class":330},[288,4561,4562],{"class":311}," !find\n",[288,4564,4565,4567,4569,4571,4573],{"class":290,"line":144},[288,4566,2356],{"class":330},[288,4568,4458],{"class":311},[288,4570,4461],{"class":527},[288,4572,4464],{"class":527},[288,4574,4467],{"class":311},[11,4576,4577,4578,4581,4582,2556,4584,4587],{},"Be sure to check out the ",[217,4579,4580],{},"Event Designators"," section of the ",[56,4583,1397],{},[56,4585,4586],{},"man"," pages\nfor more information!",[11,4589,4391],{},[11,4591,4592,4593,4598,4599,4602,4603,4605],{},"As an aside, for even faster command-line history navigation, be sure to check\nout the excellent ",[17,4594,4597],{"href":4595,"rel":4596},"https://github.com/junegunn/fzf",[21],"fzf"," utility by ",[217,4600,4601],{},"junegunn.","\nOne of the many features of ",[56,4604,4597],{}," is browsing and re-issuing commands from your\ncommand-line history with a fuzzy-finder!",[1006,4607,4608],{},"html pre.shiki code .svObZ, html code.shiki .svObZ{--shiki-default:#B392F0}html pre.shiki code .sU2Wk, html code.shiki .sU2Wk{--shiki-default:#9ECBFF}html pre.shiki code .sDLfK, html code.shiki .sDLfK{--shiki-default:#79B8FF}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html pre.shiki code .s95oV, html code.shiki .s95oV{--shiki-default:#E1E4E8}html pre.shiki code .snl16, html code.shiki .snl16{--shiki-default:#F97583}",{"title":58,"searchDepth":144,"depth":144,"links":4610},[],[1318],"2021-09-22T00:00:00.000Z","Do you ever find yourself having to re-run a Bash command? I often find this\\nhappening to myself when I neglect to use sudo for a command that requires\\nroot privileges.",{"draft":1322,"excerpt":4615},{"type":8,"value":4616},[4617],[11,4618,4277,4619,4281],{},[56,4620,4280],{},"/blog/quick-tip-rerunning-bash-commands",{"title":4272,"description":4623},"Do you ever find yourself having to re-run a Bash command? I often find this\nhappening to myself when I neglect to use sudo for a command that requires\nroot privileges.","blog/quick-tip-rerunning-bash-commands",[1515,1397],"Tc-7Ek8UYMojeBc0Zmy6c_bMsZwZCaUhNq--jJMiRNE",{"id":4628,"title":4629,"body":4630,"categories":4991,"date":4993,"description":4994,"extension":154,"img":155,"meta":4995,"navigation":161,"path":5000,"seo":5001,"stem":5002,"tags":5003,"__hash__":5008},"content/blog/unit-testing-micropython-with-mocks.md","Unit Testing in MicroPython with Mocks",{"type":8,"value":4631,"toc":4988},[4632,4635,4640,4643,4647,4658,4752,4764,4833,4843,4956,4970,4974,4985],[11,4633,4634],{},"Unit testing code for embedded systems can be challenging. While it's possible\nto leverage emulators, write side-effect free code, or run tests on the\nhardware itself, it's often easiest to unit test the code on your personal\ncomputer with mocked hardware functionality.",[4636,4637,4639],"h1",{"id":4638},"mocking","Mocking",[11,4641,4642],{},"Mocks allow us to replace the hardware interfacing functionality under-the-hood\nwith predefined results and side-effects. For example, if there is a piece of\nlogic that retrieves values from an accelerometer to get a device's\norientation, it would be possible to mock the returned values of the\naccelerometer -- allowing us to run the unit tests on a device that does not\nhave an accelerometer sensor installed.",[4636,4644,4646],{"id":4645},"a-micropython-mocking-example","A MicroPython Mocking Example",[11,4648,4649,4650,4653,4654,4657],{},"In this example, we will be unit testing a module named ",[56,4651,4652],{},"time_logger",", that\ndepends on the MicroPython library ",[56,4655,4656],{},"utime"," to log the most recent Epoch time to\na file.",[49,4659,4663],{"className":4660,"code":4661,"language":4662,"meta":58,"style":58},"language-python shiki shiki-themes github-dark","# time_logger.py\n\nclass TimeLogger(object):\n\n    def save_time(self):\n        \"\"\" Overwrite a file with the most recent Epoch timestamp from `utime`\n        \"\"\"\n        with open(\"LAST_KNOWN_TIME\", \"w+\") as f:\n            f.write(str(utime.time()))\n","python",[56,4664,4665,4670,4674,4690,4694,4705,4710,4715,4741],{"__ignoreMap":58},[288,4666,4667],{"class":290,"line":291},[288,4668,4669],{"class":294},"# time_logger.py\n",[288,4671,4672],{"class":290,"line":144},[288,4673,318],{"emptyLinePlaceholder":161},[288,4675,4676,4679,4682,4684,4687],{"class":290,"line":315},[288,4677,4678],{"class":300},"class",[288,4680,4681],{"class":330}," TimeLogger",[288,4683,604],{"class":304},[288,4685,4686],{"class":527},"object",[288,4688,4689],{"class":304},"):\n",[288,4691,4692],{"class":290,"line":321},[288,4693,318],{"emptyLinePlaceholder":161},[288,4695,4696,4699,4702],{"class":290,"line":343},[288,4697,4698],{"class":300},"    def",[288,4700,4701],{"class":330}," save_time",[288,4703,4704],{"class":304},"(self):\n",[288,4706,4707],{"class":290,"line":351},[288,4708,4709],{"class":311},"        \"\"\" Overwrite a file with the most recent Epoch timestamp from `utime`\n",[288,4711,4712],{"class":290,"line":357},[288,4713,4714],{"class":311},"        \"\"\"\n",[288,4716,4717,4720,4723,4725,4728,4730,4733,4735,4738],{"class":290,"line":363},[288,4718,4719],{"class":300},"        with",[288,4721,4722],{"class":527}," open",[288,4724,604],{"class":304},[288,4726,4727],{"class":311},"\"LAST_KNOWN_TIME\"",[288,4729,767],{"class":304},[288,4731,4732],{"class":311},"\"w+\"",[288,4734,580],{"class":304},[288,4736,4737],{"class":300},"as",[288,4739,4740],{"class":304}," f:\n",[288,4742,4743,4746,4749],{"class":290,"line":369},[288,4744,4745],{"class":304},"            f.write(",[288,4747,4748],{"class":527},"str",[288,4750,4751],{"class":304},"(utime.time()))\n",[11,4753,4754,4755,4757,4758,4760,4761,4763],{},"First, because the ",[56,4756,4656],{}," module is not installed on the machine that the unit\ntests on, we must mock ",[56,4759,4656],{}," module before importing ",[56,4762,4652],{}," in our\nunit test file.",[49,4765,4767],{"className":4660,"code":4766,"language":4662,"meta":58,"style":58},"# test_time_logger.py\n\nimport unittest\n\nfrom unittest.mock import MagicMock\n\nsys.modules['utime'] = MagicMock()\nfrom time_logger import TimeLogger\n",[56,4768,4769,4774,4778,4785,4789,4801,4805,4821],{"__ignoreMap":58},[288,4770,4771],{"class":290,"line":291},[288,4772,4773],{"class":294},"# test_time_logger.py\n",[288,4775,4776],{"class":290,"line":144},[288,4777,318],{"emptyLinePlaceholder":161},[288,4779,4780,4782],{"class":290,"line":315},[288,4781,301],{"class":300},[288,4783,4784],{"class":304}," unittest\n",[288,4786,4787],{"class":290,"line":321},[288,4788,318],{"emptyLinePlaceholder":161},[288,4790,4791,4793,4796,4798],{"class":290,"line":343},[288,4792,308],{"class":300},[288,4794,4795],{"class":304}," unittest.mock ",[288,4797,301],{"class":300},[288,4799,4800],{"class":304}," MagicMock\n",[288,4802,4803],{"class":290,"line":351},[288,4804,318],{"emptyLinePlaceholder":161},[288,4806,4807,4810,4813,4816,4818],{"class":290,"line":357},[288,4808,4809],{"class":304},"sys.modules[",[288,4811,4812],{"class":311},"'utime'",[288,4814,4815],{"class":304},"] ",[288,4817,461],{"class":300},[288,4819,4820],{"class":304}," MagicMock()\n",[288,4822,4823,4825,4828,4830],{"class":290,"line":363},[288,4824,308],{"class":300},[288,4826,4827],{"class":304}," time_logger ",[288,4829,301],{"class":300},[288,4831,4832],{"class":304}," TimeLogger\n",[11,4834,4835,4836,4839,4840,1360],{},"Then, we can write a test that patches the ",[56,4837,4838],{},"utime.time"," functionality so that\nit returns a value of our choosing -- in this case, ",[56,4841,4842],{},"1234",[49,4844,4846],{"className":4660,"code":4845,"language":4662,"meta":58,"style":58},"class TestTimeLogger(unittest.TestCase):\n\n    def test_save_time(self):\n        \"\"\" Verify that the Epoch time is written to file\n        \"\"\"\n        with unittest.mock.patch(\"utime.time\", return_value=1234):\n            t = TimeLogger()\n            t.save_time()\n            with open(\"LAST_KNOWN_TIME\") as f:\n                self.assertEqual(\"1234\", f.read())\n",[56,4847,4848,4867,4871,4880,4885,4889,4910,4920,4925,4942],{"__ignoreMap":58},[288,4849,4850,4852,4855,4857,4860,4862,4865],{"class":290,"line":291},[288,4851,4678],{"class":300},[288,4853,4854],{"class":330}," TestTimeLogger",[288,4856,604],{"class":304},[288,4858,4859],{"class":330},"unittest",[288,4861,1360],{"class":304},[288,4863,4864],{"class":330},"TestCase",[288,4866,4689],{"class":304},[288,4868,4869],{"class":290,"line":144},[288,4870,318],{"emptyLinePlaceholder":161},[288,4872,4873,4875,4878],{"class":290,"line":315},[288,4874,4698],{"class":300},[288,4876,4877],{"class":330}," test_save_time",[288,4879,4704],{"class":304},[288,4881,4882],{"class":290,"line":321},[288,4883,4884],{"class":311},"        \"\"\" Verify that the Epoch time is written to file\n",[288,4886,4887],{"class":290,"line":343},[288,4888,4714],{"class":311},[288,4890,4891,4893,4896,4899,4901,4904,4906,4908],{"class":290,"line":351},[288,4892,4719],{"class":300},[288,4894,4895],{"class":304}," unittest.mock.patch(",[288,4897,4898],{"class":311},"\"utime.time\"",[288,4900,767],{"class":304},[288,4902,4903],{"class":576},"return_value",[288,4905,461],{"class":300},[288,4907,4842],{"class":527},[288,4909,4689],{"class":304},[288,4911,4912,4915,4917],{"class":290,"line":357},[288,4913,4914],{"class":304},"            t ",[288,4916,461],{"class":300},[288,4918,4919],{"class":304}," TimeLogger()\n",[288,4921,4922],{"class":290,"line":363},[288,4923,4924],{"class":304},"            t.save_time()\n",[288,4926,4927,4930,4932,4934,4936,4938,4940],{"class":290,"line":369},[288,4928,4929],{"class":300},"            with",[288,4931,4722],{"class":527},[288,4933,604],{"class":304},[288,4935,4727],{"class":311},[288,4937,580],{"class":304},[288,4939,4737],{"class":300},[288,4941,4740],{"class":304},[288,4943,4944,4947,4950,4953],{"class":290,"line":375},[288,4945,4946],{"class":527},"                self",[288,4948,4949],{"class":304},".assertEqual(",[288,4951,4952],{"class":311},"\"1234\"",[288,4954,4955],{"class":304},", f.read())\n",[11,4957,4958,4959,4962,4963,4966,4967,4969],{},"Now, when the ",[56,4960,4961],{},"save_time"," method gets the latest time from ",[56,4964,4965],{},"utime.time()",", the\nvalue will be patched to return ",[56,4968,4842],{},". That value will be written to a file,\nand our unit test will pass!",[23,4971,4973],{"id":4972},"references","References",[4056,4975,4976],{},[197,4977,4978],{},[17,4979,4982,4984],{"href":4980,"rel":4981},"https://docs.python.org/3/library/unittest.html",[21],[56,4983,4859],{}," — Unit testing framework",[1006,4986,4987],{},"html pre.shiki code .sAwPA, html code.shiki .sAwPA{--shiki-default:#6A737D}html pre.shiki code .snl16, html code.shiki .snl16{--shiki-default:#F97583}html pre.shiki code .svObZ, html code.shiki .svObZ{--shiki-default:#B392F0}html pre.shiki code .s95oV, html code.shiki .s95oV{--shiki-default:#E1E4E8}html pre.shiki code .sDLfK, html code.shiki .sDLfK{--shiki-default:#79B8FF}html pre.shiki code .sU2Wk, html code.shiki .sU2Wk{--shiki-default:#9ECBFF}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html pre.shiki code .s9osk, html code.shiki .s9osk{--shiki-default:#FFAB70}",{"title":58,"searchDepth":144,"depth":144,"links":4989},[4990],{"id":4972,"depth":144,"text":4973},[4662,4992],"embedded","2020-02-07T00:00:00.000Z","Unit testing code for embedded systems can be challenging. While it's possible\\nto leverage emulators, write side-effect free code, or run tests on the\\nhardware itself, it's often easiest to unit test the code on your personal\\ncomputer with mocked hardware functionality.",{"draft":1322,"excerpt":4996},{"type":8,"value":4997},[4998],[11,4999,4634],{},"/blog/unit-testing-micropython-with-mocks",{"title":4629,"description":4634},"blog/unit-testing-micropython-with-mocks",[5004,5005,5006,5007],"micropython","testing","mocks","tutorial","JYw5jpUa71qliby7GLbr0qne8ADWi4zldmVsc8ovYXs",{"id":5010,"title":5011,"body":5012,"categories":5784,"date":5785,"description":5786,"extension":154,"img":155,"meta":5787,"navigation":161,"path":5792,"seo":5793,"stem":5794,"tags":5795,"__hash__":5797},"content/blog/persistent-archlinux-usb.md","Create a Persistent Arch Linux Bootable USB with Vagrant",{"type":8,"value":5013,"toc":5773},[5014,5017,5019,5044,5046,5050,5061,5080,5087,5102,5133,5190,5197,5207,5362,5366,5374,5379,5394,5467,5471,5481,5504,5518,5538,5542,5574,5612,5616,5622,5628,5634,5648,5654,5657,5660,5664,5681,5700,5702,5770],[11,5015,5016],{},"When installing a linux distribution, it is common for the instructions to have\nthe user create a bootable USB, boot from the device, and proceed with the\ninstallation procedure from that live medium. However, this blog post will\noutline an alternative approach where a virtual machine created with Vagrant\nwill be used in favor of the live medium.",[4636,5018,1364],{"id":1363},[11,5020,5021,5022,5025,5026,5043],{},"The original intention was to use Docker for this process -- leveraging the\n",[56,5023,5024],{},"--device"," flag and mounting the target USB device in the Docker container,\nbut the underlying hypervisor in Docker Desktop for Mac does not support this.\n",[5027,5028,5029,2556,5034,2556,5038],"sup",{},[17,5030,5033],{"href":5031,"rel":5032},"https://docs.docker.com/docker-for-mac/docker-toolbox/",[21],"1",[17,5035,4199],{"href":5036,"rel":5037},"https://github.com/moby/hyperkit",[21],[17,5039,5042],{"href":5040,"rel":5041},"https://github.com/docker/for-mac/issues/900",[21],"3"," While there are workarounds using Docker\nMachine, Vagrant felt like the path of least resistance.",[4636,5045,1977],{"id":1976},[23,5047,5049],{"id":5048},"create-an-arch-linux-virtual-machine-with-vagrant","Create an Arch Linux Virtual Machine with Vagrant",[11,5051,5052,5053,5060],{},"Get the latest Arch Linux image ",[5027,5054,5055],{},[17,5056,5059],{"href":5057,"rel":5058},"https://app.vagrantup.com/archlinux/boxes/archlinux",[21],"4"," from the Vagrant Cloud Box\nCatalog.",[49,5062,5064],{"className":1395,"code":5063,"language":1397,"meta":58,"style":58},"vagrant box add archlinux/archlinux\n",[56,5065,5066],{"__ignoreMap":58},[288,5067,5068,5071,5074,5077],{"class":290,"line":291},[288,5069,5070],{"class":330},"vagrant",[288,5072,5073],{"class":311}," box",[288,5075,5076],{"class":311}," add",[288,5078,5079],{"class":311}," archlinux/archlinux\n",[11,5081,5082,5083,5086],{},"Determine the USB vendor information for the thumb-drive that we will\npass-through to the virtual machine. Using the ",[56,5084,5085],{},"VBoxManage"," utility that comes\nwith Virtual Box, list the devices, and make note of the Vendor and Product ID.",[49,5088,5090],{"className":1395,"code":5089,"language":1397,"meta":58,"style":58}," VBoxManage list usbhost\n",[56,5091,5092],{"__ignoreMap":58},[288,5093,5094,5097,5099],{"class":290,"line":291},[288,5095,5096],{"class":330}," VBoxManage",[288,5098,3669],{"class":311},[288,5100,5101],{"class":311}," usbhost\n",[11,5103,5104,5105,5108,5109,5112,5113,5125,5126,5129,5130,5132],{},"Create a ",[56,5106,5107],{},"Vagrantfile"," with ",[56,5110,5111],{},"archlinx/archlinux"," as the target box, and the USB\ndevice information that is passed through. ",[5027,5114,5115,2556,5120],{},[17,5116,5119],{"href":5117,"rel":5118},"https://antonyjepson.wordpress.com/2012/01/26/quickly-attaching-usb-devices-to-virtualbox-guests-using-vboxmanage/",[21],"5",[17,5121,5124],{"href":5122,"rel":5123},"https://gist.github.com/dscape/7d829c0c116ef419f963",[21],"6"," Vagrant\noffers a handy customization parameter ",[56,5127,5128],{},"vb.customize"," that calls the\n",[56,5131,5085],{}," command under-the-hood, allowing one to enable the guest machine\nto access the host machine's USB devices.",[49,5134,5136],{"className":1246,"code":5135,"language":1248,"meta":58,"style":58},"# -*- mode: ruby -*-\n# vi: set ft=ruby :\n\nVagrant.configure(\"2\") do |config|\n  config.vm.box = \"archlinux/archlinux\"\n  config.vm.provider \"virtualbox\" do |vb|\n    vb.name = \"archlinux\"\n    vb.customize ['modifyvm', :id, '--usb', 'on']\n    vb.customize ['usbfilter', 'add', '1', '--target', :id, '--name', 'SanDisk Ultra Fit', '--vendorid', '0x0781', '--productid', '0x5583']\n  end\nend\n",[56,5137,5138,5143,5148,5152,5157,5162,5167,5172,5177,5182,5186],{"__ignoreMap":58},[288,5139,5140],{"class":290,"line":291},[288,5141,5142],{},"# -*- mode: ruby -*-\n",[288,5144,5145],{"class":290,"line":144},[288,5146,5147],{},"# vi: set ft=ruby :\n",[288,5149,5150],{"class":290,"line":315},[288,5151,318],{"emptyLinePlaceholder":161},[288,5153,5154],{"class":290,"line":321},[288,5155,5156],{},"Vagrant.configure(\"2\") do |config|\n",[288,5158,5159],{"class":290,"line":343},[288,5160,5161],{},"  config.vm.box = \"archlinux/archlinux\"\n",[288,5163,5164],{"class":290,"line":351},[288,5165,5166],{},"  config.vm.provider \"virtualbox\" do |vb|\n",[288,5168,5169],{"class":290,"line":357},[288,5170,5171],{},"    vb.name = \"archlinux\"\n",[288,5173,5174],{"class":290,"line":363},[288,5175,5176],{},"    vb.customize ['modifyvm', :id, '--usb', 'on']\n",[288,5178,5179],{"class":290,"line":369},[288,5180,5181],{},"    vb.customize ['usbfilter', 'add', '1', '--target', :id, '--name', 'SanDisk Ultra Fit', '--vendorid', '0x0781', '--productid', '0x5583']\n",[288,5183,5184],{"class":290,"line":375},[288,5185,3424],{},[288,5187,5188],{"class":290,"line":549},[288,5189,3214],{},[11,5191,5192,5193,5196],{},"When virtual machine is brought up, the ",[56,5194,5195],{},"usbfilter"," is applied, and the guest\nis able to access to the host machine's USB device that was specified in the\nfilter.",[11,5198,5199,5200,5202,5203,5206],{},"Start the machine, ",[56,5201,1306],{}," into the guest, and list the devices to confirm that\nthe USB device is available (see: ",[56,5204,5205],{},"/dev/sdb",").",[49,5208,5210],{"className":1395,"code":5209,"language":1397,"meta":58,"style":58},"$ vagrant up\n$ vagrant ssh\n[vagrant@archlinux ~]$ lsblk\nNAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT\nsda      8:0    0   20G  0 disk\n├─sda1   8:1    0  1.9G  0 part [SWAP]\n└─sda2   8:2    0 18.1G  0 part /\nsdb      8:16   1 28.7G  0 disk\n└─sdb1   8:17   1    8G  0 part\n",[56,5211,5212,5222,5231,5242,5265,5285,5306,5326,5344],{"__ignoreMap":58},[288,5213,5214,5216,5219],{"class":290,"line":291},[288,5215,1087],{"class":330},[288,5217,5218],{"class":311}," vagrant",[288,5220,5221],{"class":311}," up\n",[288,5223,5224,5226,5228],{"class":290,"line":144},[288,5225,1087],{"class":330},[288,5227,5218],{"class":311},[288,5229,5230],{"class":311}," ssh\n",[288,5232,5233,5236,5239],{"class":290,"line":315},[288,5234,5235],{"class":304},"[vagrant@archlinux ",[288,5237,5238],{"class":300},"~",[288,5240,5241],{"class":304},"]$ lsblk\n",[288,5243,5244,5247,5250,5253,5256,5259,5262],{"class":290,"line":321},[288,5245,5246],{"class":330},"NAME",[288,5248,5249],{"class":311},"   MAJ:MIN",[288,5251,5252],{"class":311}," RM",[288,5254,5255],{"class":311},"  SIZE",[288,5257,5258],{"class":311}," RO",[288,5260,5261],{"class":311}," TYPE",[288,5263,5264],{"class":311}," MOUNTPOINT\n",[288,5266,5267,5270,5273,5276,5279,5282],{"class":290,"line":343},[288,5268,5269],{"class":330},"sda",[288,5271,5272],{"class":311},"      8:0",[288,5274,5275],{"class":527},"    0",[288,5277,5278],{"class":311},"   20G",[288,5280,5281],{"class":527},"  0",[288,5283,5284],{"class":311}," disk\n",[288,5286,5287,5290,5293,5295,5298,5300,5303],{"class":290,"line":351},[288,5288,5289],{"class":330},"├─sda1",[288,5291,5292],{"class":311},"   8:1",[288,5294,5275],{"class":527},[288,5296,5297],{"class":311},"  1.9G",[288,5299,5281],{"class":527},[288,5301,5302],{"class":311}," part",[288,5304,5305],{"class":304}," [SWAP]\n",[288,5307,5308,5311,5314,5316,5319,5321,5323],{"class":290,"line":357},[288,5309,5310],{"class":330},"└─sda2",[288,5312,5313],{"class":311},"   8:2",[288,5315,5275],{"class":527},[288,5317,5318],{"class":311}," 18.1G",[288,5320,5281],{"class":527},[288,5322,5302],{"class":311},[288,5324,5325],{"class":311}," /\n",[288,5327,5328,5331,5334,5337,5340,5342],{"class":290,"line":363},[288,5329,5330],{"class":330},"sdb",[288,5332,5333],{"class":311},"      8:16",[288,5335,5336],{"class":527},"   1",[288,5338,5339],{"class":311}," 28.7G",[288,5341,5281],{"class":527},[288,5343,5284],{"class":311},[288,5345,5346,5349,5352,5354,5357,5359],{"class":290,"line":369},[288,5347,5348],{"class":330},"└─sdb1",[288,5350,5351],{"class":311},"   8:17",[288,5353,5336],{"class":527},[288,5355,5356],{"class":311},"    8G",[288,5358,5281],{"class":527},[288,5360,5361],{"class":311}," part\n",[23,5363,5365],{"id":5364},"install-arch-linux-on-the-usb-drive","Install Arch Linux on the USB Drive",[11,5367,2936,5368,5373],{},[17,5369,5372],{"href":5370,"rel":5371},"https://wiki.archlinux.org/index.php/Installation_guide",[21],"Arch Linux Installation Guide"," outlines the installation procedure in\ngreat detail -- the following steps follow this closely with a few alteration\ndue to installing onto removable media.",[5375,5376,5378],"h3",{"id":5377},"partition-the-disk-uefi-with-gpt","Partition the Disk (UEFI with GPT)",[49,5380,5382],{"className":1395,"code":5381,"language":1397,"meta":58,"style":58},"[root@archlinux ~]# fdisk /dev/sdb\n",[56,5383,5384],{"__ignoreMap":58},[288,5385,5386,5389,5391],{"class":290,"line":291},[288,5387,5388],{"class":304},"[root@archlinux ",[288,5390,5238],{"class":300},[288,5392,5393],{"class":304},"]# fdisk /dev/sdb\n",[49,5395,5397],{"className":1246,"code":5396,"language":1248,"meta":58,"style":58},"Command (m for help): p\nDisk /dev/sdb: 28.66 GiB, 30752636928 bytes, 60063744 sectors\nDisk model: Ultra Fit\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: gpt\nDisk identifier: E1D6C445-1B79-AB4D-A442-FA4AD6DF4ECC\n\nDevice       Start      End  Sectors  Size Type\n/dev/sdb1     2048  1050623  1048576  512M EFI System\n/dev/sdb2  1050624 60063710 59013087 28.1G Linux filesystem\n\nFilesystem/RAID signature on partition 1 will be wiped.\n",[56,5398,5399,5404,5409,5414,5419,5424,5429,5434,5439,5443,5448,5453,5458,5462],{"__ignoreMap":58},[288,5400,5401],{"class":290,"line":291},[288,5402,5403],{},"Command (m for help): p\n",[288,5405,5406],{"class":290,"line":144},[288,5407,5408],{},"Disk /dev/sdb: 28.66 GiB, 30752636928 bytes, 60063744 sectors\n",[288,5410,5411],{"class":290,"line":315},[288,5412,5413],{},"Disk model: Ultra Fit\n",[288,5415,5416],{"class":290,"line":321},[288,5417,5418],{},"Units: sectors of 1 * 512 = 512 bytes\n",[288,5420,5421],{"class":290,"line":343},[288,5422,5423],{},"Sector size (logical/physical): 512 bytes / 512 bytes\n",[288,5425,5426],{"class":290,"line":351},[288,5427,5428],{},"I/O size (minimum/optimal): 512 bytes / 512 bytes\n",[288,5430,5431],{"class":290,"line":357},[288,5432,5433],{},"Disklabel type: gpt\n",[288,5435,5436],{"class":290,"line":363},[288,5437,5438],{},"Disk identifier: E1D6C445-1B79-AB4D-A442-FA4AD6DF4ECC\n",[288,5440,5441],{"class":290,"line":369},[288,5442,318],{"emptyLinePlaceholder":161},[288,5444,5445],{"class":290,"line":375},[288,5446,5447],{},"Device       Start      End  Sectors  Size Type\n",[288,5449,5450],{"class":290,"line":549},[288,5451,5452],{},"/dev/sdb1     2048  1050623  1048576  512M EFI System\n",[288,5454,5455],{"class":290,"line":561},[288,5456,5457],{},"/dev/sdb2  1050624 60063710 59013087 28.1G Linux filesystem\n",[288,5459,5460],{"class":290,"line":587},[288,5461,318],{"emptyLinePlaceholder":161},[288,5463,5464],{"class":290,"line":612},[288,5465,5466],{},"Filesystem/RAID signature on partition 1 will be wiped.\n",[5375,5468,5470],{"id":5469},"format-the-partitions","Format the Partitions",[11,5472,5473,5474],{},"The UEFI specification mandates support for FAT file-systems, and FAT32 is\nrecommended for removable media. ",[5027,5475,5476],{},[17,5477,5480],{"href":5478,"rel":5479},"https://wiki.archlinux.org/index.php/EFI_system_partition#Format_the_partition",[21],"7",[49,5482,5484],{"className":1395,"code":5483,"language":1397,"meta":58,"style":58},"[root@archlinux ~]# pacman -Sy dosfstools\n[root@archlinux ~]# mkfs.fat -F32 /dev/sdb1\n",[56,5485,5486,5495],{"__ignoreMap":58},[288,5487,5488,5490,5492],{"class":290,"line":291},[288,5489,5388],{"class":304},[288,5491,5238],{"class":300},[288,5493,5494],{"class":304},"]# pacman -Sy dosfstools\n",[288,5496,5497,5499,5501],{"class":290,"line":144},[288,5498,5388],{"class":304},[288,5500,5238],{"class":300},[288,5502,5503],{"class":304},"]# mkfs.fat -F32 /dev/sdb1\n",[11,5505,5506,5507,5510,5511],{},"As for the root partition, it is recommended to use ",[56,5508,5509],{},"ext4"," without a journal to\nreduce the reads and writes to the file-system as this is detrimental to the\nflash-based USB drive. ",[5027,5512,5513],{},[17,5514,5517],{"href":5515,"rel":5516},"https://wiki.archlinux.org/index.php/Install_Arch_Linux_on_a_USB_key#Installation_tweaks",[21],"8",[49,5519,5521],{"className":1395,"code":5520,"language":1397,"meta":58,"style":58},"[root@archlinux ~]# mkfs.ext4 -O \"^has_journal\" /dev/sdb2\n",[56,5522,5523],{"__ignoreMap":58},[288,5524,5525,5527,5529,5532,5535],{"class":290,"line":291},[288,5526,5388],{"class":304},[288,5528,5238],{"class":300},[288,5530,5531],{"class":304},"]# mkfs.ext4 -O ",[288,5533,5534],{"class":311},"\"^has_journal\"",[288,5536,5537],{"class":304}," /dev/sdb2\n",[5375,5539,5541],{"id":5540},"mount-the-partitions-and-bootstrap-the-environment","Mount the Partitions and Bootstrap the Environment",[49,5543,5545],{"className":1395,"code":5544,"language":1397,"meta":58,"style":58},"[root@archlinux ~]# mount /dev/sdb2 /mnt\n[root@archlinux ~]# mkdir -p /mnt/boot/efi\n[root@archlinux ~]# mount /dev/sdb1 /mnt/boot/efi\n",[56,5546,5547,5556,5565],{"__ignoreMap":58},[288,5548,5549,5551,5553],{"class":290,"line":291},[288,5550,5388],{"class":304},[288,5552,5238],{"class":300},[288,5554,5555],{"class":304},"]# mount /dev/sdb2 /mnt\n",[288,5557,5558,5560,5562],{"class":290,"line":144},[288,5559,5388],{"class":304},[288,5561,5238],{"class":300},[288,5563,5564],{"class":304},"]# mkdir -p /mnt/boot/efi\n",[288,5566,5567,5569,5571],{"class":290,"line":315},[288,5568,5388],{"class":304},[288,5570,5238],{"class":300},[288,5572,5573],{"class":304},"]# mount /dev/sdb1 /mnt/boot/efi\n",[49,5575,5577],{"className":1395,"code":5576,"language":1397,"meta":58,"style":58},"[root@archlinux ~]# pacman -S arch-install-scripts\n[root@archlinux ~]# pacstrap /mnt base linux linux-firmware\n[root@archlinux ~]# genfstab -U /mnt >> /mnt/etc/fstab\n",[56,5578,5579,5588,5597],{"__ignoreMap":58},[288,5580,5581,5583,5585],{"class":290,"line":291},[288,5582,5388],{"class":304},[288,5584,5238],{"class":300},[288,5586,5587],{"class":304},"]# pacman -S arch-install-scripts\n",[288,5589,5590,5592,5594],{"class":290,"line":144},[288,5591,5388],{"class":304},[288,5593,5238],{"class":300},[288,5595,5596],{"class":304},"]# pacstrap /mnt base linux linux-firmware\n",[288,5598,5599,5601,5603,5606,5609],{"class":290,"line":315},[288,5600,5388],{"class":304},[288,5602,5238],{"class":300},[288,5604,5605],{"class":304},"]# genfstab -U /mnt ",[288,5607,5608],{"class":300},">>",[288,5610,5611],{"class":304}," /mnt/etc/fstab\n",[5375,5613,5615],{"id":5614},"configure-the-new-environment","Configure the New Environment",[49,5617,5620],{"className":5618,"code":5619,"language":54},[52],"[root@archlinux ~]# arch-chroot /mnt\n",[56,5621,5619],{"__ignoreMap":58},[49,5623,5626],{"className":5624,"code":5625,"language":54},[52],"[root@archlinux /]# ln -sf /usr/share/zoneinfo/US/Eastern /etc/localtime\n[root@archlinux /]# hwclock --systohc\n[root@archlinux /]# sed -i 's/#en_US.UTF-8/en_US.UTF-8/' /etc/locale.gen\n[root@archlinux /]# locale-gen\n[root@archlinux /]# echo \"LANG=en_US.UTF-8\" > /etc/locale.conf\n",[56,5627,5625],{"__ignoreMap":58},[49,5629,5632],{"className":5630,"code":5631,"language":54},[52],"[root@archlinux /]# hostnamectl set-hostname usb\n[root@archlinux /]# echo \"127.0.0.1        localhost\" >> /etc/hosts\n[root@archlinux /]# echo \"::1              localhost\" >> /etc/hosts\n",[56,5633,5631],{"__ignoreMap":58},[11,5635,5636,5637,5640,5641],{},"Note, one difference here from a standard installation is that the\n",[56,5638,5639],{},"--removable"," flag is specified when installing the GRUB bootloader.\n",[5027,5642,5643],{},[17,5644,5647],{"href":5645,"rel":5646},"https://wiki.archlinux.org/index.php/GRUB#UEFI_systems",[21],"10",[49,5649,5652],{"className":5650,"code":5651,"language":54},[52],"[root@archlinux /]# pacman -S grub\n[root@archlinux /]# grub-install --target=x86_64-efi --efi-directory=/boot/efi  --removable --recheck\n[root@usb /]# grub-mkconfig -o /boot/grub/grub.cfg\n",[56,5653,5651],{"__ignoreMap":58},[11,5655,5656],{},"Shutdown the virtual machine, restart the host machine, and boot the newly\ncreated Arch Linux thumb-drive!",[11,5658,5659],{},"🎉",[23,5661,5663],{"id":5662},"side-note","Side-note",[11,5665,5666,5667,5670,5671,5673,5674],{},"It was attempted to use the ",[56,5668,5669],{},"controlvm usbattach"," command to pass the USB\ndevice to the guest machine, but this did not work as it expects the virtual\nmachine to already be running, and the ",[56,5672,5128],{}," option runs prior to\nbooting the machine. ",[5027,5675,5676],{},[17,5677,5680],{"href":5678,"rel":5679},"https://www.vagrantup.com/docs/virtualbox/configuration.html#vboxmanage-customizations",[21],"11",[49,5682,5684],{"className":1246,"code":5683,"language":1248,"meta":58,"style":58},"Command: [\"controlvm\", \"060a716b-1965-49e2-bc56-12beed5df716\", \"usbattach36fc9e60-c465-11cf-8056-444553540000\"]\n\nStderr: VBoxManage.exe: error: Machine '060a716b-1965-49e2-bc56-12beed5df716' is not currently running.\n",[56,5685,5686,5691,5695],{"__ignoreMap":58},[288,5687,5688],{"class":290,"line":291},[288,5689,5690],{},"Command: [\"controlvm\", \"060a716b-1965-49e2-bc56-12beed5df716\", \"usbattach36fc9e60-c465-11cf-8056-444553540000\"]\n",[288,5692,5693],{"class":290,"line":144},[288,5694,318],{"emptyLinePlaceholder":161},[288,5696,5697],{"class":290,"line":315},[288,5698,5699],{},"Stderr: VBoxManage.exe: error: Machine '060a716b-1965-49e2-bc56-12beed5df716' is not currently running.\n",[23,5701,4973],{"id":4972},[4056,5703,5704,5710,5716,5722,5728,5734,5740,5746,5752,5758,5764],{},[197,5705,5706],{},[17,5707,5709],{"href":5031,"rel":5708},[21],"Docker Desktop on Mac vs. Docker Toolbox",[197,5711,5712],{},[17,5713,5715],{"href":5036,"rel":5714},[21],"GitHub - HyperKit",[197,5717,5718],{},[17,5719,5721],{"href":5040,"rel":5720},[21],"GitHub - Docker for Mac - Issue #900",[197,5723,5724],{},[17,5725,5727],{"href":5057,"rel":5726},[21],"Vagrant Cloud - Arch Linux",[197,5729,5730],{},[17,5731,5733],{"href":5117,"rel":5732},[21],"Attaching USB Devices to VirtualBox Guests using VBoxManage",[197,5735,5736],{},[17,5737,5739],{"href":5122,"rel":5738},[21],"GitHub Gist - Vagrant USB Filter",[197,5741,5742],{},[17,5743,5745],{"href":5478,"rel":5744},[21],"Arch Linux Wiki - EFI System Partition - Format Partitions",[197,5747,5748],{},[17,5749,5751],{"href":5515,"rel":5750},[21],"Arch Linux Wiki - Arch Linux on USB - Installation Tweaks",[197,5753,5754],{},[17,5755,5757],{"href":5370,"rel":5756},[21],"Arch Linux Wiki - Installation Guide",[197,5759,5760],{},[17,5761,5763],{"href":5645,"rel":5762},[21],"Arch Linux Wiki - GRUB - UEFI Systems",[197,5765,5766],{},[17,5767,5769],{"href":5678,"rel":5768},[21],"Vagrant VBoxManage Customizations ",[1006,5771,5772],{},"html pre.shiki code .svObZ, html code.shiki .svObZ{--shiki-default:#B392F0}html pre.shiki code .sU2Wk, html code.shiki .sU2Wk{--shiki-default:#9ECBFF}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html pre.shiki code .s95oV, html code.shiki .s95oV{--shiki-default:#E1E4E8}html pre.shiki code .snl16, html code.shiki .snl16{--shiki-default:#F97583}html pre.shiki code .sDLfK, html code.shiki .sDLfK{--shiki-default:#79B8FF}",{"title":58,"searchDepth":144,"depth":144,"links":5774},[5775,5776,5782,5783],{"id":5048,"depth":144,"text":5049},{"id":5364,"depth":144,"text":5365,"children":5777},[5778,5779,5780,5781],{"id":5377,"depth":315,"text":5378},{"id":5469,"depth":315,"text":5470},{"id":5540,"depth":315,"text":5541},{"id":5614,"depth":315,"text":5615},{"id":5662,"depth":144,"text":5663},{"id":4972,"depth":144,"text":4973},[3942],"2020-01-09T00:00:00.000Z","When installing a linux distribution, it is common for the instructions to have\\nthe user create a bootable USB, boot from the device, and proceed with the\\ninstallation procedure from that live medium. However, this blog post will\\noutline an alternative approach where a virtual machine created with Vagrant\\nwill be used in favor of the live medium.",{"draft":1322,"excerpt":5788},{"type":8,"value":5789},[5790],[11,5791,5016],{},"/blog/persistent-archlinux-usb",{"title":5011,"description":5016},"blog/persistent-archlinux-usb",[5070,5796],"archlinux","TVXFsaO_wBOiXZdyemSXh3nPdnm0bbeXECKigtoJlY8",{"id":5799,"title":5800,"body":5801,"categories":5914,"date":5915,"description":5916,"extension":154,"img":155,"meta":5917,"navigation":161,"path":5922,"seo":5923,"stem":5924,"tags":5925,"__hash__":5928},"content/blog/docker-selinux-volumes.md","Docker Volume Permissions with SELinux",{"type":8,"value":5802,"toc":5912},[5803,5806,5815,5818,5860,5871,5877,5880,5888,5893,5909],[11,5804,5805],{},"Unfamiliar with running Docker on a SELinux enabled system, I found myself\nrunning into a bunch of file permission errors while creating volumes.",[49,5807,5809],{"className":1246,"code":5808,"language":1248,"meta":58,"style":58},"mkdir: can't create directory '/data': Permission denied\n",[56,5810,5811],{"__ignoreMap":58},[288,5812,5813],{"class":290,"line":291},[288,5814,5808],{},[5816,5817],"hr",{},[49,5819,5821],{"className":1395,"code":5820,"language":1397,"meta":58,"style":58},"$ docker info --format '{{json .SecurityOptions}}'\n[\n  \"name=seccomp,profile=/etc/docker/seccomp.json\",\n  \"name=selinux\"\n]\n",[56,5822,5823,5839,5844,5851,5856],{"__ignoreMap":58},[288,5824,5825,5827,5830,5833,5836],{"class":290,"line":291},[288,5826,1087],{"class":330},[288,5828,5829],{"class":311}," docker",[288,5831,5832],{"class":311}," info",[288,5834,5835],{"class":527}," --format",[288,5837,5838],{"class":311}," '{{json .SecurityOptions}}'\n",[288,5840,5841],{"class":290,"line":144},[288,5842,5843],{"class":304},"[\n",[288,5845,5846,5849],{"class":290,"line":315},[288,5847,5848],{"class":311},"  \"name=seccomp,profile=/etc/docker/seccomp.json\"",[288,5850,2161],{"class":304},[288,5852,5853],{"class":290,"line":321},[288,5854,5855],{"class":311},"  \"name=selinux\"\n",[288,5857,5858],{"class":290,"line":343},[288,5859,2597],{"class":304},[11,5861,5862,5863,5866,5867,5870],{},"It turns out that this can be resolved by appending the ",[56,5864,5865],{},":z"," flag to the volume\nmappings in the ",[56,5868,5869],{},"docker-compose.yml"," file, indicating that the volume content\nis shared.",[49,5872,5875],{"className":5873,"code":5874,"language":54},[52],"services:\n  server:\n    volumes:\n      - ./data:/data:z\n",[56,5876,5874],{"__ignoreMap":58},[11,5878,5879],{},"From the Docker documentation:",[1062,5881,5882],{},[11,5883,2936,5884,5887],{},[56,5885,5886],{},"z"," option tells Docker that two containers share the volume content. As\na result, Docker labels the content with a shared content label. Shared\nvolume labels allow all containers to read/write content.",[11,5889,5890],{},[5891,5892,4973],"strong",{},[194,5894,5895,5902],{},[197,5896,5897],{},[17,5898,5901],{"href":5899,"rel":5900},"https://docs.docker.com/engine/reference/commandline/info/",[21],"Docker Docs: Docker Info",[197,5903,5904],{},[17,5905,5908],{"href":5906,"rel":5907},"https://docs.docker.com/engine/reference/commandline/run/#mount-volumes-from-container---volumes-from",[21],"Docker Docs: Mounting Volumes",[1006,5910,5911],{},"html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html pre.shiki code .svObZ, html code.shiki .svObZ{--shiki-default:#B392F0}html pre.shiki code .sU2Wk, html code.shiki .sU2Wk{--shiki-default:#9ECBFF}html pre.shiki code .sDLfK, html code.shiki .sDLfK{--shiki-default:#79B8FF}html pre.shiki code .s95oV, html code.shiki .s95oV{--shiki-default:#E1E4E8}",{"title":58,"searchDepth":144,"depth":144,"links":5913},[],[3942],"2019-12-26T00:00:00.000Z","Unfamiliar with running Docker on a SELinux enabled system, I found myself\\nrunning into a bunch of file permission errors while creating volumes.",{"draft":1322,"excerpt":5918},{"type":8,"value":5919},[5920],[11,5921,5805],{},"/blog/docker-selinux-volumes",{"title":5800,"description":5805},"blog/docker-selinux-volumes",[5926,5927],"docker","selinux","SCQvnQEISwjINi5QaiXjF9hX1oDSiiMHXsxxtSR4MuA",{"id":5930,"title":5931,"body":5932,"categories":6087,"date":6088,"description":6089,"extension":154,"img":155,"meta":6090,"navigation":161,"path":6100,"seo":6101,"stem":6103,"tags":6104,"__hash__":6107},"content/blog/apu2-firmware-upgrade.md","Upgrading the Firmware on the PCEngines APU2",{"type":8,"value":5933,"toc":6085},[5934,5943,5946,5949,5955,5970,5998,6005,6020,6023,6047,6052,6082],[11,5935,5936,5937,5942],{},"I've had a ",[17,5938,5941],{"href":5939,"rel":5940},"https://pcengines.ch/apu2.htm",[21],"PCEngines APU2"," gathering dust for a\nfew years, and have recently decided to dust it off.",[11,5944,5945],{},"Since the last time the device has been powered on, there have been many great\nimprovements to the firmware, and it was very-much due for an upgrade. The\nfollowing steps outline how the firmware was upgraded on the APU from the\nalready-installed operating system -- CentOS.",[11,5947,5948],{},"First, we will connect to the device over the serial port",[49,5950,5953],{"className":5951,"code":5952,"language":54},[52],"screen /dev/tty.usbserial 115200\n",[56,5954,5952],{"__ignoreMap":58},[11,5956,5957,5958,5961,5962,5965,5966,5969],{},"Then, we will install the ",[56,5959,5960],{},"flashrom"," utility that is needed to update the\nfirmware. Because it is not available in the default ",[56,5963,5964],{},"yum"," repositories, we\nwill enable the ",[217,5967,5968],{},"Extra Packages for Enterprise Linux"," (EPEL) repository before\ninstallation.",[49,5971,5973],{"className":1395,"code":5972,"language":1397,"meta":58,"style":58},"sudo yum install epel-release\nsudo yum install flashrom\n",[56,5974,5975,5987],{"__ignoreMap":58},[288,5976,5977,5979,5982,5984],{"class":290,"line":291},[288,5978,4280],{"class":330},[288,5980,5981],{"class":311}," yum",[288,5983,1093],{"class":311},[288,5985,5986],{"class":311}," epel-release\n",[288,5988,5989,5991,5993,5995],{"class":290,"line":144},[288,5990,4280],{"class":330},[288,5992,5981],{"class":311},[288,5994,1093],{"class":311},[288,5996,5997],{"class":311}," flashrom\n",[11,5999,6000,6001,1360],{},"Next, we will download the latest version of the firmware that is compatible\nwith the APU2 device from the PC Engines release website:\n",[17,6002,6003],{"href":6003,"rel":6004},"https://pcengines.github.io/",[21],[49,6006,6008],{"className":1395,"code":6007,"language":1397,"meta":58,"style":58},"curl -O https://3mdeb.com/open-source-firmware/pcengines/apu2/apu2_v4.11.0.1.rom\n",[56,6009,6010],{"__ignoreMap":58},[288,6011,6012,6015,6017],{"class":290,"line":291},[288,6013,6014],{"class":330},"curl",[288,6016,1179],{"class":527},[288,6018,6019],{"class":311}," https://3mdeb.com/open-source-firmware/pcengines/apu2/apu2_v4.11.0.1.rom\n",[11,6021,6022],{},"And finally, we will flash the firmware...",[49,6024,6026],{"className":1395,"code":6025,"language":1397,"meta":58,"style":58},"sudo flashrom -w apu2_v4.11.0.1.rom -p internal:boardmismatch=force\n",[56,6027,6028],{"__ignoreMap":58},[288,6029,6030,6032,6035,6038,6041,6044],{"class":290,"line":291},[288,6031,4280],{"class":330},[288,6033,6034],{"class":311}," flashrom",[288,6036,6037],{"class":527}," -w",[288,6039,6040],{"class":311}," apu2_v4.11.0.1.rom",[288,6042,6043],{"class":527}," -p",[288,6045,6046],{"class":311}," internal:boardmismatch=force\n",[11,6048,6049],{},[5891,6050,6051],{},"References:",[194,6053,6054,6059,6064,6070,6076],{},[197,6055,6056],{},[17,6057,5939],{"href":5939,"rel":6058},[21],[197,6060,6061],{},[17,6062,6003],{"href":6003,"rel":6063},[21],[197,6065,6066],{},[17,6067,6068],{"href":6068,"rel":6069},"https://github.com/pcengines/apu2-documentation/blob/master/docs/firmware_flashing.md",[21],[197,6071,6072],{},[17,6073,6074],{"href":6074,"rel":6075},"https://github.com/pcengines/apu2-documentation/blob/master/docs/cold_reset.md",[21],[197,6077,6078],{},[17,6079,6080],{"href":6080,"rel":6081},"https://github.com/elad/openbsd-apu2",[21],[1006,6083,6084],{},"html pre.shiki code .svObZ, html code.shiki .svObZ{--shiki-default:#B392F0}html pre.shiki code .sU2Wk, html code.shiki .sU2Wk{--shiki-default:#9ECBFF}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html pre.shiki code .sDLfK, html code.shiki .sDLfK{--shiki-default:#79B8FF}",{"title":58,"searchDepth":144,"depth":144,"links":6086},[],[3942],"2019-12-21T00:00:00.000Z","I've had a PCEngines APU2 gathering dust for a\\nfew years, and have recently decided to dust it off.",{"draft":1322,"excerpt":6091},{"type":8,"value":6092},[6093,6098],[11,6094,5936,6095,5942],{},[17,6096,5941],{"href":5939,"rel":6097},[21],[11,6099,5945],{},"/blog/apu2-firmware-upgrade",{"title":5931,"description":6102},"I've had a PCEngines APU2 gathering dust for a\nfew years, and have recently decided to dust it off.","blog/apu2-firmware-upgrade",[6105,6106],"pcengine","apu","aKx8mPKH5GJhE3SyFGBgFhaj7ZxjSdzUmhxBOcJxdPM",1761759640104]